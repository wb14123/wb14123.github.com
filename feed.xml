<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://www.binwang.me/feed.xml" rel="self" type="application/atom+xml" /><link href="https://www.binwang.me/" rel="alternate" type="text/html" /><updated>2025-07-01T11:07:22-04:00</updated><id>https://www.binwang.me/feed.xml</id><title type="html">Bin Wang - My Personal Blog</title><subtitle>This is my personal blog about computer science, technology and my life.</subtitle><entry><title type="html">Use OpenAPI Instead of MCP for LLM Tools</title><link href="https://www.binwang.me/2025-04-27-Use-OpenAPI-Instead-of-MCP-for-LLM-Tools.html" rel="alternate" type="text/html" title="Use OpenAPI Instead of MCP for LLM Tools" /><published>2025-04-27T00:00:00-04:00</published><updated>2025-04-27T00:00:00-04:00</updated><id>https://www.binwang.me/Use-OpenAPI-Instead-of-MCP-for-LLM-Tools</id><content type="html" xml:base="https://www.binwang.me/2025-04-27-Use-OpenAPI-Instead-of-MCP-for-LLM-Tools.html"><![CDATA[<p><a href="https://modelcontextprotocol.io/introduction">Module Context Protocol (MCP)</a> is adopted by more and more people as a way to integrate tools to LLMs easily. However, I find it unintuitive and unnecessarily complex. So in this article, I’ll explore how to use existing <a href="https://www.openapis.org/">OpenAPI</a> servers as tools of LLMs instead of writing the functions in a completely new protocol. This can potentially become a simpler standard that only needs implementation an additional authentication flow (if authentication is needed).</p>

<p>For the people who are not familar with OpenAPI, it’s a formal way to descrit HTTP APIs. You may heard of Swagger which is basically the same thing. Lots of HTTP framework support it so that you can generate structured document in JSON or YAML format, and view it in tools like <a href="https://editor.swagger.io/">Swagger Editor</a>. Because of this structured document, it’s perfect to be feeded into LLM as tool definations.</p>

<p>The final result is in the repo <a href="https://github.com/wb14123/ai-tool-proto-experiment">ai-tool-proto-experiment</a>. It’s a single file Scala script with less than 300 lines of code.
It doesn’t use any LLM SDK, just simple HTTP calls to the LLM providers. It doesn’t use any advance API either. Only chat completion API with structured output is needed.</p>

<h2 id="goals-and-non-goals">Goals and Non-Goals</h2>

<p>Tool server is only part of MCP. It has more like prompts and resources. Personally I don’t see much benefit to include so many use cases in a single protocol.</p>

<p>For example, prompts are just a server API that you can get all the pre-defined prompts. That’s very easy to implement with any protocol and there is really no need to combine it with the LLM tool protocol.</p>

<p>So in this article, we will only explore how to integrate other services as tools of LLM, without caring about the other parts of MCP like prompts and resources.</p>

<p>There are also some other things that MCP doesn’t resolve, like security. <a href="https://elenacross7.medium.com/%EF%B8%8F-the-s-in-mcp-stands-for-security-91407b33ed6b">This post</a> summarized lots of security problems in MCP, and I don’t think there is an easy way around that even if we use existing protocols like OpenAPI. So the goal in this experiment is only use trusted OpenAPI servers, without worrying about attacks like tool shadowing. With that said, authentication is still necessary to the OpenAPI server, which is a protect of the server instead of the client. MCP only added authentication into the spec recently. As you can see later, the authentication workflow I tried here is much more simpler and generic.</p>

<p>At last, use as little LLM API as possible is also a goal, so that it’s easier to port the implementation to other LLM providers.</p>

<h2 id="the-implementation">The Implementation</h2>

<p>Using something like OpenAPI is not a new idea. I’ve seen multiple people mentioned it on places like HackerNews. And during my implementation, I also found <a href="https://github.com/open-webui/open-webui">Open WebUI</a>, a tool I self hosted and used daily also added support to use OpenAPI servers as tools. Nevertheless, I still try to experiment my own implementation because I want to keep it as simple as possible, and also learn more details about the capability of such approach.</p>

<p>In the experiment, I tried both a simple <a href="https://github.com/open-webui/openapi-servers/tree/main/servers/weather">open source weather OpenAPI server</a>, and my own project <a href="https://www.rssbrain.com/">RSS Brain</a>. I’ll try to explain how it is implemented and talk about an experiment result at the end.</p>

<h2 id="define-the-tool-calling-structure">Define the Tool Calling Structure</h2>

<p>Lots of LLM providers support tool calling APIs. We will avoid to use those APIs just to keep things simpler and make it more general available for other LLMs, including the self hosted ones. So instead, we define our own JSON schema that we want the LLM to follow and feed it as part of the system prompt, also use structured output API to enforce the LLM response follow the JSON schema. I said in the beginning that I want to use as little feature as possible, but I think structured output is an important enough feature I need to use in addition to the basic chat completion. Fortunately lots of other LLMs including the local ones like Ollama also support this feature.</p>

<p>Here are the response structure we want, in the format of Scala class definition:</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">case</span> <span class="k">class</span> <span class="nc">ToolParam</span><span class="o">(</span>
    <span class="n">httpRequestEndpoint</span><span class="k">:</span> <span class="kt">String</span><span class="o">,</span>
    <span class="n">httpRequestPath</span><span class="k">:</span> <span class="kt">String</span><span class="o">,</span>
    <span class="n">httpRequestHeaders</span><span class="k">:</span> <span class="kt">Option</span><span class="o">[</span><span class="kt">Map</span><span class="o">[</span><span class="kt">String</span>, <span class="kt">String</span><span class="o">]],</span>
    <span class="n">httpRequestMethod</span><span class="k">:</span> <span class="kt">String</span><span class="o">,</span>
    <span class="nc">HttpPostBody</span><span class="k">:</span> <span class="kt">Option</span><span class="o">[</span><span class="kt">String</span><span class="o">],</span>
<span class="o">)</span>

<span class="k">case</span> <span class="k">class</span> <span class="nc">ChatResponse</span><span class="o">(</span>
    <span class="n">callTool</span><span class="k">:</span> <span class="kt">Option</span><span class="o">[</span><span class="kt">ToolParam</span><span class="o">]</span> <span class="k">=</span> <span class="nc">None</span><span class="o">,</span>
    <span class="n">toUser</span><span class="k">:</span> <span class="kt">Option</span><span class="o">[</span><span class="kt">String</span><span class="o">]</span> <span class="k">=</span> <span class="nc">None</span><span class="o">,</span>
<span class="o">)</span>
</code></pre></div></div>

<p>The LLM should either response to the user directly using <code class="language-plaintext highlighter-rouge">toUser</code> field, or ask the agent to call a HTTP API with <code class="language-plaintext highlighter-rouge">callTool</code> field. You can see the <code class="language-plaintext highlighter-rouge">ToolParam</code> definition is pretty generic: it can basically do any HTTP call.</p>

<p>For OpenAI, the structured output API only accept a subset of JSON schema definition. So instead of converting the structure to a JSON schema with a single line of Scala code, I need to manually write the OpenAI compatible one.</p>

<p>I also find OpenAI models, gpt-4o-last at least, often failed to generate response that meet the structure requirement even structured output is enabled. You still need to include the JSON schema into the system prompt to get the best chance.</p>

<p>Overall, here is the system prompt to let the system use the tools:</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">systemPrompt</span><span class="k">:</span> <span class="kt">String</span> <span class="o">=</span> <span class="o">{</span>
  <span class="k">val</span> <span class="nv">timeStr</span> <span class="k">=</span> <span class="nv">ZonedDateTime</span><span class="o">.</span><span class="py">now</span><span class="o">().</span><span class="py">format</span><span class="o">(</span><span class="nv">DateTimeFormatter</span><span class="o">.</span><span class="py">ISO_ZONED_DATE_TIME</span><span class="o">)</span>
  <span class="n">s</span><span class="s">"""You are a helpful assistant.
     |
     |The current time is $timeStr.
     |
     |You have many tools to use by sending a http request to some API servers. Your response must be Json that
     |follows the Json schema definition:
     |
     |$chatResponseSchemaStr
     |
     |Either request a call to one of the APIs with `callTool` field, or
     |response to user directly with `toUser` field if there is no need to request to any tool or you need more
     |information from the user.
     |
     |Each tool has an optional authUrl that you can ask the user to open in the browser. If you get authentication
     | related errors when calling a tool, ask the user to open the authUrl in browser and copy the instruction back,
     | then use the instruction to try authentication again.
     |
     |Important:
     |
     |* Response only the JSON body. Never quote the response in something like json```...```.
     |* Never response to user directly without using the `toUser` field with a Json response.
     |* Only one of `callTool` and `toUser` field should be filled.
     |* Always include the `http` or `https` part for the `httpRequestEndpoint` field.
     |
     |"""</span><span class="o">.</span><span class="py">stripMargin</span>
<span class="o">}</span>
</code></pre></div></div>

<p>You can see there are some extra points at the end, which are the cases I find the model hiccups very often.</p>

<h2 id="feed-the-tool-information-into-llm">Feed the Tool Information Into LLM</h2>

<p>Since OpenAPI can generate a structured document for the API server, either in JSON or YAML, we can feed the document directly into the LLM. In addition to the doc endpoint, we also need to provide the endpoint of the API servers, also an optional <code class="language-plaintext highlighter-rouge">authUrl</code> we will talk about later. Here is the definition of the tool in Scala classes, with the prompts:</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">case</span> <span class="k">class</span> <span class="nc">ToolDef</span><span class="o">(</span>
    <span class="n">httpEndpoint</span><span class="k">:</span> <span class="kt">String</span><span class="o">,</span>
    <span class="n">openAPIPath</span><span class="k">:</span> <span class="kt">String</span><span class="o">,</span>
    <span class="n">authUrl</span><span class="k">:</span> <span class="kt">Option</span><span class="o">[</span><span class="kt">String</span><span class="o">]</span> <span class="k">=</span> <span class="nc">None</span><span class="o">,</span>
<span class="o">)</span> <span class="o">{</span>
  <span class="k">def</span> <span class="nf">prompt</span><span class="k">:</span> <span class="kt">String</span> <span class="o">=</span> <span class="o">{</span>
    <span class="k">val</span> <span class="nv">authUrlPrompt</span> <span class="k">=</span> <span class="nv">authUrl</span><span class="o">.</span><span class="py">map</span><span class="o">(</span><span class="n">url</span> <span class="k">=&gt;</span> <span class="n">s</span><span class="s">"Tool login URL: $url\n"</span><span class="o">).</span><span class="py">getOrElse</span><span class="o">(</span><span class="s">""</span><span class="o">)</span>
    <span class="n">s</span><span class="s">"""----
       |Tool server endpoint: $httpEndpoint
       |
       |$authUrlPrompt
       |Tool's OpenAPI definition:
       |$openAPIDef
       |
       |----
       |
       |"""</span><span class="o">.</span><span class="py">stripMargin</span>
  <span class="o">}</span>

  <span class="k">private</span> <span class="k">def</span> <span class="nf">openAPIDef</span><span class="k">:</span> <span class="kt">String</span> <span class="o">=</span> <span class="o">{</span>
    <span class="nv">requests</span><span class="o">.</span><span class="py">get</span><span class="o">(</span><span class="n">httpEndpoint</span> <span class="o">+</span> <span class="n">openAPIPath</span><span class="o">).</span><span class="py">text</span><span class="o">()</span>
  <span class="o">}</span>
<span class="o">}</span>
</code></pre></div></div>

<p>After system prompt, the tools prompt is sent as the first chat message to the LLM with a role of <code class="language-plaintext highlighter-rouge">developer</code>. I find it works better than put it into the system prompt, maybe because of the tool definition sometimes can be too long:</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">tools</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span>
  <span class="nc">ToolDef</span><span class="o">(</span><span class="n">httpEndpoint</span> <span class="k">=</span> <span class="s">"https://grpc-gateway.rssbrain.com"</span><span class="o">,</span> <span class="n">openAPIPath</span> <span class="k">=</span> <span class="s">"/swagger.json"</span><span class="o">,</span>
    <span class="n">authUrl</span> <span class="k">=</span> <span class="nc">Some</span><span class="o">(</span><span class="s">"http://app.rssbrain.com/login?redirect_url=/llm_auth"</span><span class="o">)),</span>
<span class="o">)</span>
<span class="k">val</span> <span class="nv">toolsPrompt</span> <span class="k">=</span> <span class="nv">tools</span><span class="o">.</span><span class="py">map</span><span class="o">(</span><span class="nv">_</span><span class="o">.</span><span class="py">prompt</span><span class="o">).</span><span class="py">mkString</span><span class="o">(</span><span class="s">"\n"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">req</span> <span class="k">=</span> <span class="nc">ChatRequest</span><span class="o">(</span>
  <span class="n">messages</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span>
    <span class="nc">ChatMessage</span><span class="o">(</span><span class="n">role</span> <span class="k">=</span> <span class="s">"system"</span><span class="o">,</span> <span class="n">content</span> <span class="k">=</span> <span class="n">systemPrompt</span><span class="o">),</span>
    <span class="nc">ChatMessage</span><span class="o">(</span><span class="n">role</span> <span class="k">=</span> <span class="s">"developer"</span><span class="o">,</span> <span class="n">content</span> <span class="k">=</span>
      <span class="n">s</span><span class="s">"""
        |
        |Here are the OpenAPI definition of the tools:
        |
        |$toolsPrompt
        |
        |"""</span><span class="o">.</span><span class="py">stripMargin</span><span class="o">),</span>
  <span class="o">),</span>
<span class="o">)</span>
<span class="nf">loop</span><span class="o">(</span><span class="n">req</span><span class="o">,</span> <span class="nc">None</span><span class="o">,</span> <span class="n">waitForUser</span> <span class="k">=</span> <span class="kc">true</span><span class="o">)</span>
</code></pre></div></div>

<h2 id="authentication">Authentication</h2>

<p>As you can see from the system prompt above:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Each tool has an optional authUrl that you can ask the user to open in the browser. If you get authentication
related errors when calling a tool, ask the user to open the authUrl in browser and copy the instruction back,
then use the instruction to try authentication again.
</code></pre></div></div>

<p>We actually take advantage of the flexible of LLMs for our authentication flow: we define a <code class="language-plaintext highlighter-rouge">authUrl</code> for a tool server, which user can open in the browser. The URL will do necessary authentication flow, then return a nature language description about credentials and how to use it to do authentications with the APIs.</p>

<p>Ideally, the nature language instruction should be passed to the client in a secure way, for example, through callback to a local URL that the client serves. But for the simplicity of the experiment, I just ask the user the copy the instruction back to the conversation.</p>

<p>So here is what it looks like in the example below:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>User input: Get all my RSS folders
Calling tool https://grpc-gateway.rssbrain.com//rss.FolderAPI/GetMyFolders ...
</code></pre></div></div>

<p>The user asks for the RSS folders, so LLM response with a <code class="language-plaintext highlighter-rouge">callTool</code> action. When trying to call the http API, it returns an error about authentication. We feed the result back to the LLM, then it responses to the user:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Assistant: It seems like your request for fetching RSS folders requires authentication. Please log in to your RSS Brain account and provide the token to proceed. You can open [this login page](http://app.rssbrain.com/login?redirect_url=/llm_auth) to login and obtain the necessary token.
</code></pre></div></div>

<p>You can see the LLM is asking the user to open a URL in the browser. When user open this URL in the browser, the service will prompt the user to login and redirect the user to a page with nature language instruction for LLM. The user copy the instruction back to the chat:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>User input: Use `token` param in the APIs to do authentication. Your current token is `XXXXX`.
</code></pre></div></div>

<p>After added the user input to the LLM, LLM now knows how to fill in <code class="language-plaintext highlighter-rouge">callToo</code> params with necessary authentication info and the call finally succeed:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Calling tool https://grpc-gateway.rssbrain.com//rss.FolderAPI/GetMyFolders ...
Assistant: Here are your RSS folders:
...
</code></pre></div></div>

<p>The authentication flow makes it very flexible: the tool server can basically implement any kinds of authentication method as long as it provides a URL that contains the authentication instruction along credentials. You can even create a third party auth server if the original OpenAPI server doesn’t provide this auth workflow, so that you can integrate any OpenAPI service with authentication.</p>

<h2 id="results">Results</h2>

<p>Okay, everything is ready now. Let’s try to use it. Follow the <a href="https://github.com/wb14123/ai-tool-proto-experiment">readme</a> to install the dependencies and run the script.</p>

<p>Here is a real world example of using RSS Brain as one of the tool server:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>-&gt; ./ai-tool.sc
Compiling /home/wangbin/hobbi_source/ai-tool-proto-experiment/ai-tool.sc
User input: Hi
Assistant: Hello! How can I assist you today?
User input: Get all my RSS folders
Calling tool https://grpc-gateway.rssbrain.com//rss.FolderAPI/GetMyFolders ...
Assistant: It seems like your request for fetching RSS folders requires authentication. Please log in to your RSS Brain account and provide the token to proceed. You can open [this login page](http://app.rssbrain.com/login?redirect_url=/llm_auth) to login and obtain the necessary token.
User input: Use `token` param in the APIs to do authentication. Your current token is `XXXXX`.
Calling tool https://grpc-gateway.rssbrain.com//rss.FolderAPI/GetMyFolders ...
Assistant: Here are your RSS folders:

1. **Default Folder:**
   - Name: Default
   - Description: user default folder
   - Layout: LIST
   - Order: TIME

2. **news-local:**
   - Description: N/A
   - Layout: LIST
   - Order: TIME

3. **local-forum:**
   - Description: N/A
   - Layout: LIST
   - Order: SCORE

4. **news-cn:**
   - Description: N/A
   - Layout: LIST
   - Order: TIME

5. **cn-podcast:**
   - Description: N/A
   - Layout: LIST
   - Order: TIME

6. **cn-media:**
   - Description: N/A
   - Layout: GRID
   - Order: TIME

7. **news:**
   - Description: News around world
   - Layout: LIST
   - Order: TIME

8. **news-Ukraine:**
   - Description: N/A
   - Search Term: "Ukraine" AND "Russia"
   - Layout: LIST
   - Order: TIME

9. **blogs:**
   - Description: N/A
   - Layout: LIST
   - Order: TIME

10. **tech-blogs:**
    - Description: N/A
    - Layout: LIST
    - Order: TIME

11. **tech-news:**
    - Description: N/A
    - Layout: LIST
    - Order: TIME

... (and more)

For a complete list or details about any specific folder, please let me know!
User input: What happened today based on articles in local-news?    
Calling tool https://grpc-gateway.rssbrain.com//rss.ArticleAPI/GetArticlesByFolderWithUserMarking ...
Assistant: Here are some notable articles from today based on the 'local-news' folder:

1. **A short history of airport gold heists (because Toronto's isn't the first)**
   - **Source:** Canada - CBC News
   - **Description:** Reflection on Toronto's Pearson International Airport's gold heist and similar historical events.
   - [Read more](https://www.cbc.ca/news/world/airport-gold-heists-history-1.6817567)

2. **Family of Nunavut woman says she was used to get Ontario twins Inuit status**
   - **Source:** Canada - CBC News
   - **Description:** A story about a family's reaction after a woman is allegedly used in a fraud to gain Inuit status for twins.
   - [Read more](https://www.cbc.ca/news/canada/north/ontaro-twins-inuit-status-claims-1.6814782)

3. **CBC partners with Markham Library to offer youth Radio Camp**
   - **Source:** Toronto - CBC News
   - **Description:** A creative initiative by CBC for youth in Markham, involving sound exploration and radio production.
   - [Read more](https://www.cbc.ca/news/canada/toronto/community/cbc-partners-with-markham-library-to-offer-youth-radio-camp-1.6806360)

4. **Federal government says it will restore funding to Hockey Canada — with conditions**
   - **Source:** Canada - CBC News
   - **Description:** Funding for Hockey Canada is restored with stipulations after controversy over handling of claims.
   - [Read more](https://www.cbc.ca/news/politics/hockey-canada-federal-government-funding-restored-1.6812492)

5. **Man dies after being hit by tow truck in York Region industrial accident, police say**
   - **Source:** Toronto - CBC News
   - **Description:** Tragic incident of a man being fatally struck by a tow truck, with ongoing investigation.
   - [Read more](https://www.cbc.ca/news/canada/toronto/industrial-accident-york-region-tow-truck-death-1.6780204)

For more details, you can click on the links provided with each summary.
User input: Summarize the first article
Assistant: The first article is titled **"A short history of airport gold heists (because Toronto's isn't the first)"** from "Canada - CBC News". It discusses a recent heist that took place
 at Toronto's Pearson International Airport, where $20 million worth of gold and other valuables were stolen. This event is compared to similar high-profile historical heists at airports, highlighting
 recurring vulnerabilities in airport security regarding valuable shipments. The article provides context and details on how such heists have occurred before in different parts of the world.

</code></pre></div></div>

<p>Since it’s pretty expensive when including the OpenAPI doc, I didn’t try it much. But there are a few things learnt:</p>

<ul>
  <li>Good document is really important. LLM doesn’t include some parameters if you don’t clarify on why it’s needed. I think it’s actually a good thing, since good document is not only for machines, but also for other people.</li>
  <li>Structure output is not always forced. The json schema also needs to be in the system prompt to make it more reliable.</li>
  <li>APIs need to be designed around the potential use cases. For example, the get articles from a feed API doesn’t have a time range since the UI of RSS Brain is infinite scroll. So it’s hard for LLM to get the articles in a specific time range, for example, last day.</li>
</ul>

<p>But overall, I think it’s safe to say with the additional authentication flow that can be added by third party, it’s easy to integrate any OpenAPI server as a tool to LLM agent without needing any new protocol.</p>

<h2 id="more-about-protocol">More About Protocol</h2>

<p>I want to add more details about choosing OpenAPI as the protocol. The obvious reason is it has been around for a long time and lots of tools and frameworks support it. But for RSS Brain, I only have a gRPC server. I implemented the gRPC server with my own library <a href="https://github.com/wb14123/scala2grpc">scala2grpc</a> and really liked it. However, a downside of gRPC is the serialized message is not human readable. So it’s hard to define a generic call tool structure. Also it’s more difficult to call the API without generated gRPC code. So at the end, I used <a href="https://github.com/grpc-ecosystem/grpc-gateway/tree/main">grpc-gateway</a> to proxy the gRPC server into an OpenAPI server. The code is released in <a href="https://github.com/wb14123/rss_brain_grpc_gateway">Github</a>.</p>

<p>grpc-gateway has a tool to auto generate OpenAPI structured document, if you have the necessary comments in the gRPC protobuf files. So I added the feature in scala2grpc to add comments based on Scaladoc and it turned out wonderfully.</p>

<p>With all that said, I still think gRPC has its advantage because of the ability of bi-directional streaming. The proto definition is also easier to understand for human, which is a plus for LLMs. Maybe with some more work and leverage things like <a href="https://grpc.io/docs/guides/reflection/">gRPC reflection</a>, we can also define a generic tool calling action with gRPC in the agent.</p>

<h2 id="future-work">Future Work</h2>

<p>This is only an experiment, so there are lots of work left to do to make it better.</p>

<p>The first one is to have a better authentication flow, so that the auth URL can give the instructions to LLM agent without user copying it. This is not a hard thing to do but makes it much more secure.</p>

<p>Another thing to try is to not include all the OpenAPI doc in the prompt at first. Instead, only include a summarization or description of it, and only gives more details when LLM agent asks for it. It should be able to save lots of cost.</p>

<p>And there can be more validations for security purpose, for example, when calling a tool or let user open an auth URL in the browser, verify the hostname matches what we have defined in the tools.</p>

<p>It also worth trying other protocols like gRPC since it supports bi directional stream, which may works better in some use cases.</p>]]></content><author><name></name></author><category term="machine learning" /><category term="LLM" /><category term="MCP" /><category term="OpenAPI" /><category term="gRPC" /><summary type="html"><![CDATA[Module Context Protocol (MCP) is adopted by more and more people as a way to integrate tools to LLMs easily. However, I find it unintuitive and unnecessarily complex. So in this article, I’ll explore how to use existing OpenAPI servers as tools of LLMs instead of writing the functions in a completely new protocol. This can potentially become a simpler standard that only needs implementation an additional authentication flow (if authentication is needed).]]></summary></entry><entry><title type="html">Travel Back To China: 2025 Edition</title><link href="https://www.binwang.me/2025-02-28-Travel-Back-To-China-2025.html" rel="alternate" type="text/html" title="Travel Back To China: 2025 Edition" /><published>2025-02-28T00:00:00-05:00</published><updated>2025-02-28T00:00:00-05:00</updated><id>https://www.binwang.me/Travel-Back-To-China-2025</id><content type="html" xml:base="https://www.binwang.me/2025-02-28-Travel-Back-To-China-2025.html"><![CDATA[<p>As I mentioned in the <a href="/2025-01-13-A-2-Year-Reflection.html">last year-end retrospective blog</a>, I traveled back to China again this year (to be more accurate, at the end of 2024). I migrated to Canada just before the Covid, which is why I only started to go back since <a href="/2024-03-19-Travel-Back-to-China.html">last year</a> after the Covid measurements were all lifted. I think it’s worth a blog post every time I go back there since China, as a country I spent most of my life, not only made what I am today, but also still has so many connections with me. Most of my friends and extended family members are still there. I also find going back every year instead of living there all the time makes me a better observer. I can notice the changes easier since I’m comparing the things from year to year instead of from day to day. I can notice the things that may already get used to for the people living there all the time. I also have more motivation to observe since the short time of visiting is so valuable to me. So here it is, the 2025 edition of travelling back to China.</p>

<h2 id="toronto">Toronto</h2>

<p>My wife and I planned the travel dates in October. We decided to go back during the Christmas and new year’s holiday instead of Chinese New Year. Mostly because I can take advantage of some public holidays so I don’t need to take that many days off, and it’s also easier to coordinate with co-workers since most people are not there so it’s hard to do projects any way. However, the flights are really expensive during the holiday season. Most of the tickets need multiple stopovers. Then we thought, why not take the opportunity to visit some places on the way? We stopped in Tokyo for a few days last year when we travelled back, so why not do something similar? We’ve always wanted to visit Europe. So this time, we went big with our plan to stay in London on the way to China, and Paris on the way back to Toronto. So the whole trip is like: Toronto -&gt; New York -&gt; London (stay) -&gt; Shanghai -&gt; Zhengzhou -&gt; My Hometown. Then for the return trip: My hometown -&gt; Beijing -&gt; Paris (stay) -&gt; New York -&gt; Toronto. Crazy, right? But travel to Europe with only additional expense of hotels is such an attractive idea, and the travel last year gives us lots of confidence of travelling with a baby.</p>

<p>Before I went back, I had just finished reading <em>Other River</em> by Peter Hessler. Then I started to read <em>Country Driving</em> again, another book of his written more than 10 years ago. Peter Hessler, as an American, most of his books are about his experience when staying in China, which I absolutely love reading. It’s an interesting coincident that his coverage of China happens to fill the gaps of my own experience: he started his China experience from 1996, about 4 years after I was born. Then he left China in 2010, one year after I started my University life and started to experience and think about the Chinese society by myself. In 2019, the year I moved to Canada, he went back to China again, so his recordings helped me to fill the gap since then. It’s a shame he needed to leave China again in 2021 (or lucky I guess, considering the Covid measurements in China after that). It’s really refreshing to read the perspective of someone from a different culture. Like I said above, it makes the person a better observer. His books also inspired me to write blogs like this to record things in China. Reading the books, it feels China is changing so fast. Even for his newest book <em>Other River</em>, it only covers the early stages of China’s Covid measurements, which seems already outdated after only 2 years. It seems to be impossible to grasp China as a whole. On that level, there is no difference for my blogs: it’s just some observation of a snapshot of China by a person.</p>

<p>Other than reading the books, I didn’t really have much plan for the trip. The work was busy because I needed to wrap up things before leaving for vacation. It’s flu season and combined with vaccines, my daughter gave a hard time to the whole family. We only started to pack before two days of leaving, and only had a very rough plan for the travel in London. But that’s enough: a detailed plan is mostly useless when travelling with a baby. It’s better to adjust based on the situation and plan accordingly, which I’m already very good at.</p>

<h2 id="london">London</h2>

<p>After transferring through New York, we arrived in London in the morning. I was very excited since it’s my first time to be in Europe. We booked the hotel to be in the core of London, so that we can walk to most of the destinations. We took the train from Airport to the hotel. The train stopped before reaching our destination, which was annoying but understandable to me: I know the idea that some trains don’t run the full range and go back early. We took the next train coming, only to find out it’s a different line. Turned out it is really a train station instead of a subway station, which can serve trains to multiple directions. When we realized it after one station, I overheard someone else also took the wrong train, who is also the first time came to London.</p>

<p>Anyway, with this small bump, we still arrived the hotel very early in the morning and my daughter has already slept in the stroller. While it’s not time for check-in yet, we left the luggages at hotel and headed to British Museum. We planned to visit the museum on the first day since the time spent there can be flexible: we know it’s impossible to see the whole collection in a single day, so we just take whatever time is available. Luckily my daughter slept the whole morning, and we ate some (awful) food in the museum after she woke up. It’s really a rare opportunity to be able to see so many valuable collections, especially the ones from very early civilizations like Egypt and Assyria, which I always fancied, as well as some rare collections from China. Without realizing it, we spent much more time than we had planned, until it felt like a rabbit hole and it’s impossible to see all the things I want to see.</p>

<p>There were not so many people on the way when we walked from the hotel to the museum, and I thought that’s just how London is. However, when we went back, we found the streets were packed with people. The shops, restaurants, malls, trees, streets, basically everything, all had very beautiful decorations. The holiday spirit was really magical. I’ve never seen anything like that. Especially with the European style narrow roads, the whole city was like a gigantic Christmas market. At night, we walked in the main shopping areas and the lights are so gorgeous. It felt really magical and unreal.</p>

<p>Other than the holiday vibe, I also enjoyed the culture very much. There are so many civilizations that has long history in the world, but the only ones I’m very familiar with is the Chinese culture and its influences in East Asia. I’ve been to some other countries like US and New Zealand, not to mention Canada, but those countries are all colonies where the new comers don’t have a long history there while the native people’s culture has been long shadowed. But in London, I got the opportunity to experience another totally different culture that has a long history and had great influence to the world. I visited places like Tower of London, Buckingham Palace, National Gallery and so on. But I had the most stunning experience at Westminster Abbey: I didn’t do much research for the travel, so before I went there, I just knew the architecture is beautiful and it’s one of the must see sites in London. But when I entered there, I was shocked to know the burial site is actually <strong>in</strong> the abbey, just under and beside your steps. This burial style is unthinkable in Chinese culture. The sculptures are beautiful and gorgeous. It felt strange that there are so many great names buried in such a small space. It makes the grand church felt crowded. It’s like walk into a Hollywood party with all kinds of stars, except the people there are magnificently more famous and important: the kings, queens, scientists, writers and so on. The building truly represents the country’s culture and glory: the custom, the history, the religion, the art, and the people.</p>

<p>We hit another similar bump on the way back: we took the wrong train again when we went to the airport. There were so many people in the airport and it’s a total mess. Fortunately we left early for the airport and were able to take some priority line with my daughter, so we didn’t miss our flight. With that and a really long trip, we finally arrived China.</p>

<h2 id="hometown">Hometown</h2>

<p>Nothing reminds you how fast time passes more than a baby’s growth: last year when we went back, our daughter couldn’t even crawling. This year, she is running all over the places and speak so many words. Watching her learn new things everyday, trying to talk and interact with all the family members brings so much joy to everyone. However, things were not so smooth at the beginning: when we first arrived, my daughter had a mild fever. Nothing too bad and she recovered just after one day. But when we took her to my mother’s place, she was still very tired from the disturbed sleep schedule and jet lag. It took her some serious cry before we could put her to sleep. The crying made my mother and my grand parents very worried. It also made me wonder if it’s worth spending so much time, effort and money to go back just to stay for less than 3 weeks. But after my daughter had enough rest and wake up, she played with the family so happily. On each of the visits, she tried to remember and bubble the words that represent everyone, like grandmother and so on. During one of the visits, my grandfather told us that my uncle, who is in the US, cancelled the plan to go back this year. He said that with anger, which is normal since he is a serious man with a bad tamper. But there was also sadness on his face that he tried to hide but failed to do so. It’s that moment I decided I would go back every year as long as there are no events like a pandemic or a war.</p>

<p>Talking about a war seems exaggerated. But look at Ukraine and Palestine: this is the world we are living in. During my time there, a possible war between China and Taiwan has been brought up as a chat topic multiple times at different occasions. Even when I took a taxi, the driver was watching a video on Douyin (Chinese version of Tiktok) about attacking Taiwan (what’s wrong with the people nowadays that watch videos when driving??). The creator said in a very exited tone that if China attacks Taiwan, the war must be finished in one week no matter what the cost is, otherwise China will be screwed. The taxi driver agreed after watching the video, then out of blue, started to criticize Xi, talking about Xi’s bad education background and how his constitution amendment will make him infamous forever. Anyway, I think Xi wouldn’t start a war as long as he has strong control of China’s politic power. After all, why would he risk the power? It would only happen when the economic is so bad that there is civil unrest, or there is strong challengers to his rule (no one is on the horizon right now), or his old age blinds his judgement. But I also heard the rumor that says the war will happen before 2027, which is the 100th birthday of the Chinese PLA, which made me less certain about my thoughts. After all, it wouldn’t be the first irrational decision Xi has made. That’s how it works in China: without trustworthy media and transparency politic practise, the information is transferred through rumour and the discussion is done with guess.</p>

<p>Most of the conversations like this happened at the dinning table. I had high expectations about the food before I went back. Some food in my hometown are very hard to find in Toronto or even in other places of China, and they are so delicious in my memory. However, the food has been underwhelming this time. Maybe the expectation was too high. Back then when I was in high school, the same street had two high schools with less than 500 meters apart. The schools had a tight schedule: the classes starts before 8:00 in the morning and ends at about 9:00 at night. There is a larger gap in the noon because Chinese students usually take a nap during the noon. But there is a very small gap between afternoon and evening. So naturally, the street become a place that has lots of small restaurants and street food. It was packed with students when the afternoon classes were over, and the food stalls would occupy the roadway. It’s a mix of chaos and relaxing, which is so hard to forget. I spent almost every dinner there during the 3 years of my high school life. I would buy some video game magazines after dinner, or rent some books, or skip the dinner all together and spend the time to play video games in an Internet cafe.</p>

<p>It’s telling that all those industries about my after dinner activities have (almost) vanished. Let’s first address the weird thing if you’ve never heard of it: book rental. Yes, it was a very popular industry on that street back then. It’s very like movie rental. The books were mostly pirated novels from the Internet. The quality varies but usually on the lower side. It’s perfect for spending time during boring classes, which I did endlessly. But once the mobile phones are popularized in students, all the book rental stores are just gone: since the most popular books in those stores are on the Internet any way. Internet cafes are not so popular anymore but are not totally vanished: even with everyone has their own computer nowadays, it’s still useful for some friends play video games together. Video magazine is mostly the same story: there is less business but they are not totally gone. But the one I read the most in the past had closed the business. I only found it out many years later and it made me very sad.</p>

<p>Actually, not only the after dinner activities have vanished, even my high school was vanished all together as well: it’s moved to a suburb like location and the students must live there. The original site became a middle school.</p>

<p>On the other side, street food has lasted much longer. So like before, I went there again but only found the food stalls were all hidden in a nearby street. Curiously, I asked one of them why, and they told me there is an inspection from government for the award of “clean city”. This is typical campaign style governance: when an event like this happens, there will be a campaign across the city to make very absurd policies that makes normal life very inconvenient. The policies are also unsustainable, which is reverted soon after the events passed. It happened so many times in the past so I didn’t feel surprised. But I also found there was no high school student buying the food, which is kind of strange since it’s the time when afternoon classes were over. I asked again and was told the remaining high school adopted “military style management”, so the students were not allowed to go out during the rest anymore.</p>

<p>“Military style” school is trending in my hometown now. I really hate it. I think it’s just many parents don’t want to have the responsibility to raise the kids, and just throwing them into the school with strict rules. Chinese people value education very much. But a lot of them just like buying education, and think that’s enough. Like if they’ve spent enough money for the kids and the kids still didn’t turn out to be good, they’ve done everything they can and it’s not the parents’ fault. However, they don’t realise that parents are a big part of the education and no money can buy that part. And their standard of “good kids” are simple: have good scores in tests and be obedience. This explains why military style schools are so popular: the students spend little time at home so that the parents feel like they have less responsibility, and it sure sounds effective for raising obedience kids. Not all schools adopted that approach, so the business for after school classes are also popular even after the government abruptly banned the practise a few years ago. I even saw some “AI study room”, which is the most weird AI hype business I’ve ever seen, and one of them spells “AI” as “Ai”. I asked my friends what it’s about, and apparently it’s just a place that the parents can drop the kids after school, so that someone can monitor them to finish the homework. Education is surely one of reasons of my immigration to Canada: I don’t want my children to experience the kind of education I’ve had, which somehow even managed to get worse.</p>

<p>I also noticed the security for the schools seems to be leveled up. There are some barriers and police present in front of the school gate when parents picking up kids after school.  Maybe partly because of some random attacks happened across China not long before, with some cases targeted students.</p>

<p>After I started the hobby of retro computing, I started to buy more from Chinese used market since it’s much cheaper. This time I traveled with Thinkpad X220 instead of Thinkpad X1 Extreme, mainly want to test how it works when travelling, but also as an opportunity to buy some parts for it. I upgraded it with more RAM and bought a new battery for it. It turned out great: not only it can handle everyday tasks like Internet browsing without any problem, I can also play some light games on Steam. The small size of it makes it very easy to use on the road. Like I said in the last blog post about year end retrospective, I’ll write a more detailed blog about this laptop.</p>

<h2 id="beijing">Beijing</h2>

<p>Last year when I went back, I only stayed in Beijing for one night. This time, I went there for a slightly longer time of one day. I took the high speed train to Beijing, which is very common in China. It’s fast, cheap and much more comfortable than plane. I really wish Canada can build some high speed trains so that we don’t need to go to the airport just for a one hour flight.</p>

<p>I was able to meet with my cousin and some friends there. The lunch I had with my cousin was unexpected: we found a hotpot place where the brand is supposed to be a very popular one which both of us had multiple times in Beijing. But after ordered the food, we found out it’s a knock off: instead of XX Hotpot, it’s actually <strong>Authentic</strong> XX Hotpot. Unsurprisingly, the food was terrible. Which is a shame because I don’t have much opportunity to have food in Beijing anymore. But it’s also hilarious that two people that each stayed in Beijing for almost a decade can still fall in to that kind of scam.</p>

<p>Like me, my cousin started to hate staying in Beijing after a few years. I think it’s a common thing between people in Beijing. Unlike southern China, no city in northern China is near the level of Beijing. So naturally, lots of people in northern China go to there for opportunities. However, like I said in the last year’s travel back to China blog, Beijing is a city that don’t care about normal people and can suck the energy out of the people. Because I got to stay in Beijing for longer this time, I experienced it more: after I left Beijing, I sometimes wondered, why I didn’t visit more places in Beijing when I was there, especially I worked from home during my last two years there. The visit to Beijing this time reminds me why: Beijing is a city that is so large and places so separated out. It has excellent subway. So people use it most of time. My day there was mostly spent underground in subway, where you cannot really see the city. Daily life like this makes people feel like they are just a part of a big machine. After many years in Beijing, the city was still like fragments to me. Only after I started to commute by bike not long before I left Beijing, I started to piece together the fragments and had a better sense of the city.</p>

<p>Subway maybe the most used transportation method in Beijing. So there is no surprise security checks happened a lot in the stations. Other than mandatory security checks at the entrance, police also check IDs randomly from time to time, which I encountered just after I arrived Beijing. I ignored them and just passed around when they were checking someone else’s ID and nobody seemed to care. I also encountered two security check points on the road, in a short distance taxi trip I took. One is on the inner city highway, which took a full lane. Another one is on the exit and blocked all the cars. It was evening rush hour, but the security checkpoints didn’t seem to care about the congestion it caused or worsened.</p>

<p>The gap of lifestyles in Beijing can be dramatic. Inside the second ring road, there are lots of ancient and traditional buildings left. The import government institutions are also in there. This is the Beijing when most of the people from other places think about it. However, in real world, there is little people live inside the second ring road. There are lots of companies and universities between 3rd and 5th ring road, which lacks some characters but more like a modern big city. Lots of the people live outside the fifth ring road. From a glance, many places there have no difference from an average small town in northern China. There is usually a big mall around for shopping and eating. Other than that, you mostly need to take subways for destinations. I read the awarding winning sci-fi novel <em>Folding Beijing</em> back when I was in Beijing. It tells a fiction society where three classes are strictly separated. I didn’t have much thought when I read it. But visiting Beijing again, taking subways underground all the day, I suddenly remembered it and found its fiction is so real on so many levels.</p>

<p>The night in Beijing was still cold during the winter. But it’s nice to have dinner with old friends. We met at a place that used to be the heart of China’s IT industrial. The IT companies have moved to a very remote place since then, and lots of big malls occupied the area. I remember the place as a lively area but it was kind of quite that night. Maybe it’s because of the weekday. I was told Covid also hit the commercials big. After dinner, I slept over at a friend’s place, who owns a home but is renting now because his wife was transferred to another location temporarily for work. It reminds me the time when I was renting in Beijing. During my first months in Beijing, I was searching a place to live with a friend. We took the subway to a potential place that is very rural like. When my friend heard the landlord would pick us up from the subway station with a van, the kind that is usually seen in movies used by kidnappers, he was so afraid and tried to convince me to turn back. Nevertheless, we rented that place at the end. When another friend first came to Beijing, I was going to move away so I gave him the place. He said it was so remote that he felt like he already left Beijing just after the moment he arrived. I still have fond memory about the subway station there: standing in a rural place with dirts, grasses, strong wind, and snow sometimes, without any obstacles, you can see the elliptical shaped station from very far away. It is elevated high above the ground with the subway track going through it. The station is very new and shinny. It’s spacious and bright inside. During the early morning and late night, with the track and bridge hidden in the dark, the only thing you can see is the illuminated station floating in the air, with trains flying in and out slowly. It’s really like a space station in a newly developed planet. It’s the magic node connecting this area to the outside. People rushed in in the morning, packed the train so full that sometimes the subway station staff need to push people onto the train. Then people rushed out during the evening, when the moon took over the sky and climbed above the station. When I had dinner with the friend again and talked about it, he told me that place has been developed so much. There are lots of new buildings and commercials. Partially because the IT industrial in Beijing has moved to that direction. I wondered if the station can still be seen from far away.</p>

<h2 id="paris">Paris</h2>

<p>Time is so fast in China and it’s time to leave before we even adjusted. We planned Paris as the detour during the way back. I always knew Paris is a nice city, and France has so many influences to the world: its art, fashion, food, culture, politics and so on. But not until I saw lots of the city scenes of Paris when I watched Olympic games last year , I started to have the desire of actually visiting it someday. I’ve never thought the day would come so soon.</p>

<p>With the experience in London, we carefully looked up the train we needed to take from the airport to the city. This time we didn’t take the wrong train, but instead, witnessed a scam/robbery: when the train was approaching a station, there were three men wanted to get off. I stood with the stroller where my daughter was sleeping, and they squeezed pass me. In retrospective, I felt something was not so right because they were kind of rude. But this is another country so I didn’t know what is normal. There was a couple, maybe in their sixties, stood not far away from me. When one of the men passed the couple, he dropped a coin and started to look it up by lifting their suitcases, with the other two men joined to help. Soon the train stopped at the station and the door opened. Suddenly, the men started to grab the bags and suitcases by force. Luckily, the couple protected their luggages well. Before the robbers could grab anything, it started to attract attentions so they were forced to give up and started to run. Just after the moment I realized what happened, they were already at the door. I thought: “Shit! My suitcase is at the door!” But maybe the suitcase was too big and didn’t seem to worth much, they just glanced at it and escaped without a second thought.</p>

<p>I’ve heard Paris has petty crime problem, but witness one just after arrived shocked me and really let my guard up. Luckily we didn’t have much trouble to get to our hotel. And we only saw another similar accident once in the following days, when two police men chasing another men near Eiffel Tower.</p>

<p>Our hotel is at prime location: just across the Seine river from Notre-Dame. We took the similar plan as we were in London: visited Louvre Museum on the first day. It’s hard to not compare it with the British Museum. Even though I heard the British Museum had much more collections than Louvre Museum, no one can argue the architecture of Louvre is much more majestic. I would say the building itself is one of its most amazing collections.</p>

<p>The weather was not so good there. It was raining on the first day we arrived, then turned very cold on the second day. We visited Notre-Dame very early in the second morning, and just after we went out, it started to rain very heavily. The wind was so strong that it broke my umbrella. I was wet very soon without the umbrella. Despair and frustrated, it suddenly started to snow! I almost wanted to give up the day and went back to the hotel. But the rain and snow stopped pretty soon, so we continued the plan to walk in the city. After we’ve reached Arc de Triomphe and found a place to eat lunch, the sun started to came out. We headed to Eiffel Tower after lunch. The cloud soon cleared up and the city was so bright. The good weather continued through the day. When we walked across Seine river during the evening, the sunset was so beautiful: the water reflected the red sun, with rosy gold color on all the grand buildings nearby: The Conciergerie, Sainte-Chapelle, Notre-Dame and so on. Then we heard a soft song from a street singer on the bridge. At that moment, I thought Paris is really the capital of romantic.</p>

<p>Paris is truly beautiful. In the days there, the amazement only increased when I explored more and more of the city. I’ve never seen such a large area that has so many beautiful architectures in such a consistent style. It’s like being thrown into a totally different world and it’s really a dream like experience. Yet it has so much history. When I visited Chinese cities, I can associate lots of history events and figures to the places I visited, which gave me a much deeper feeling. Few foreign cities had that effect on me (maybe I would count Kyoto as one of them). But in Paris, even I have very limited knowledge of France, I can still associate lots of history events and figures to the places I visited, because there are just so many of them and it’s hard to not know, or at least heard some of them as long as you’ve studied basic history and literature in the middle school. That along makes the city so much richer than just a “beautiful city”.</p>

<p>Overall the experience in Paris is very positive even considering the accidents I witnessed. The food is also surprisingly good. Somewhat like its history, the rich of the tastes is something I rarely got from the non Chinese food. The only thing I wish could be better is how long I stayed there: three and a half days are just so little for a city like Paris. But it’s already what we could do for a vacation with such packed schedule. And considering it’s only a detour, which means we didn’t pay more for the flights compared to go back directly, we couldn’t ask for more.</p>

<h2 id="new-york">New York</h2>

<p>We transferred through New York again when we flew from Paris to Toronto. We spent lots of time in Paris airport because the check-in agent couldn’t figure out our complex passports, visas and routes. The plane was also late for a little bit so the time left for transferring in New York is very tight. I’ve had so many connecting flights but this time it’s different: we needed to go out of the boarding area when the plane arrived, and do security checks again to enter. More than one bags alerted during the security checks, maybe because of the baby food and snacks we brought. So I was asked to do a full body check, which certainly didn’t help with the tight time. I was asked multiple questions for the consensual, only to find out it’s the kind of the search that is very common in some Chinese airports and train stations, which almost every passenger need to do.</p>

<p>After packing the bags again following the search, I was very tired after such a long trip that I miscalculated the time zones, and thought we could barely make the next flight. So we ran to the gate only to find out there is an additional one hour. We didn’t pick up checked in luggages, because those are usually carried to the final destination with the planes.  But it turned out we needed to do so for this transfer. We only knew that after we’ve arrived Toronto when couldn’t find our luggages. I filled out a form to have them be shipped to my home the next day, and went back without those suitcases.</p>

<p>I was so tired after came back, and still dreamed Paris for a few days after. However, the trip turned out very good and it makes me more determined to travel back every year. And I got some good rest and was able to get the time to write this blog post. Thinking about the travel, it’s almost like living two life styles: in Canada, the time is slow, long and peaceful. I spend most of the time on work, research and my own small family instead of socializing. While in China, the time is fast. I spend almost all the time to connect with my extended family and friends, eating outside, traveling on the way and so on. Hopefully I can continue to go back and record it every year in the foreseeable future.</p>]]></content><author><name></name></author><category term="China" /><category term="travel" /><category term="life" /><category term="Paris" /><category term="London" /><summary type="html"><![CDATA[As I mentioned in the last year-end retrospective blog, I traveled back to China again this year (to be more accurate, at the end of 2024). I migrated to Canada just before the Covid, which is why I only started to go back since last year after the Covid measurements were all lifted. I think it’s worth a blog post every time I go back there since China, as a country I spent most of my life, not only made what I am today, but also still has so many connections with me. Most of my friends and extended family members are still there. I also find going back every year instead of living there all the time makes me a better observer. I can notice the changes easier since I’m comparing the things from year to year instead of from day to day. I can notice the things that may already get used to for the people living there all the time. I also have more motivation to observe since the short time of visiting is so valuable to me. So here it is, the 2025 edition of travelling back to China.]]></summary></entry><entry><title type="html">Replace A Dead Node in My High Available Cluster</title><link href="https://www.binwang.me/2025-02-01-Replace-A-Dead-Node-in-My-High-Avaliable-Cluster.html" rel="alternate" type="text/html" title="Replace A Dead Node in My High Available Cluster" /><published>2025-02-01T00:00:00-05:00</published><updated>2025-02-01T00:00:00-05:00</updated><id>https://www.binwang.me/Replace-A-Dead-Node-in-My-High-Avaliable-Cluster</id><content type="html" xml:base="https://www.binwang.me/2025-02-01-Replace-A-Dead-Node-in-My-High-Avaliable-Cluster.html"><![CDATA[<p>In my previous blogs <a href="/2023-03-13-Infrastructure-Setup-for-High-Availability.html">[1]</a><a href="/2023-11-28-Introduce-K3s-CephFS-and-MetalLB-to-My-High-Avaliable-Cluster.html">[2]</a>, I’ve introduced my high available cluster setup. It works really well: when 1 of the 3 nodes is down, the service either continue to be online, or can be recovered rather quickly (in the case I set service replica to 1 to not wasting the resource). However, in the beginning of this year, one node is down not because of regular updates or temporary shutdown for maintenance, but because its system disk is dead. While it’s annoying to replace the disk and bring it back, it’s actually a good opportunity to verify a dead node can be replaced in my setup. So I will note the steps down in this article. This will be a short one but it shows how easy it is.</p>

<h2 id="what-has-lost">What Has Lost?</h2>

<p>The dead disk is the system disk. It has the OS, but also has the data for CockroachDB and ElasticSearch. However, since the data for CockroachDB and ElasticSearch is replicated across the cluster, it can be recovered from other machines.</p>

<p>The machine also has a separate disk for CephFS but that disk is not lost. The data in CephFS is also replicated so should be able to recover from other machines as well even if it’s dead. But it may need additional setup, like changing the disk uuid in Rook’s Kubernetes manifests.</p>

<h2 id="why-not-recover-from-backup">Why Not Recover From Backup?</h2>

<p>First of all, I don’t backup that often because I don’t feel the need considering the data is replicated. Another reason is, I setup this machine based on the usage of <a href="/2021-09-19-Personal-ZFS-Offsite-Online-Backup-Solution.html">offsite online backup</a>. Then I repurposed it to use in this HA cluster. I want to change the secure boot setup because the threat model is different so it doesn’t need such complex boot setup, which is not supported very well by mainstream Linux without TPM 2.0.</p>

<p>Since the data can all be recovered from other machines automatically, it would be easier to just install a fresh OS and some basic infrastructure so that all the service deployments and data can be auto recovered. This also simulates a dead node situation, so that I have more confidence for recovering from such failures in the future.</p>

<h2 id="how-to-recover">How to Recover?</h2>

<p>Okay, here we are for the actual recovery steps. It’s very simple:</p>

<p>First, install the OS. Configure basic things like network IP address, ssh, etc. Install things like <code class="language-plaintext highlighter-rouge">prometheus-node-exporter</code> if you are using it on other machines.</p>

<p>Next step is to let the node to join our Kubernetes cluster. Before that, we can remove the old dead node in the Kubernetes cluster by using the command <code class="language-plaintext highlighter-rouge">kubectl delete node ...</code>.</p>

<p>Then install k3s: Copy the config file under <code class="language-plaintext highlighter-rouge">/etc/rancher/k3s/config.yaml</code> from another machine and adjust the node IP and network interface config. Make sure the config has something like <code class="language-plaintext highlighter-rouge">server: https://...:6443</code> so it will join the existing cluster instead of creating a new cluster. Check the k3s versions on other machines by using <code class="language-plaintext highlighter-rouge">kubectl get nodes -o wide</code>. Then install it with <code class="language-plaintext highlighter-rouge">curl -sfL https://get.k3s.io | INSTALL_K3S_VERSION=v1.31.1+k3s1 sh -</code> assuming <code class="language-plaintext highlighter-rouge">v1.31.1+k3s1</code> is the version.</p>

<p>After k3s is installed, the k3s service should be enabled by default and the node should join our cluster automatically. If the hostname and IP address are the same as the dead machine, the Kubernetes cluster should automatically reschedule the services on to this machine. If there are some failed containers, check the log to see if it’s because the local directory for the storage is missing. In my case, I need to create the local directory for CockroachDB and ElasticSearch, and set the owner to 1000 for ElasticSearch.</p>

<p>At last, we need to make sure CephFS is working. Make sure <code class="language-plaintext highlighter-rouge">ceph</code> and <code class="language-plaintext highlighter-rouge">rbd</code> can be loaded with <code class="language-plaintext highlighter-rouge">modprobe</code>. If so, add them to <code class="language-plaintext highlighter-rouge">/etc/modules-load.d</code> to load on boot:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>cat /etc/modules-load.d/ceph.conf
ceph
cat /etc/modules-load.d/rbd.conf
rbd
</code></pre></div></div>]]></content><author><name></name></author><category term="Kubernetes" /><category term="infrastructure" /><category term="high availability" /><summary type="html"><![CDATA[In my previous blogs [1][2], I’ve introduced my high available cluster setup. It works really well: when 1 of the 3 nodes is down, the service either continue to be online, or can be recovered rather quickly (in the case I set service replica to 1 to not wasting the resource). However, in the beginning of this year, one node is down not because of regular updates or temporary shutdown for maintenance, but because its system disk is dead. While it’s annoying to replace the disk and bring it back, it’s actually a good opportunity to verify a dead node can be replaced in my setup. So I will note the steps down in this article. This will be a short one but it shows how easy it is.]]></summary></entry><entry><title type="html">A 2-Year Reflection for 2023 and 2024</title><link href="https://www.binwang.me/2025-01-13-A-2-Year-Reflection.html" rel="alternate" type="text/html" title="A 2-Year Reflection for 2023 and 2024" /><published>2025-01-13T00:00:00-05:00</published><updated>2025-01-13T00:00:00-05:00</updated><id>https://www.binwang.me/A-2-Year-Reflection</id><content type="html" xml:base="https://www.binwang.me/2025-01-13-A-2-Year-Reflection.html"><![CDATA[<p>Here is another new year! I didn’t write any retrospective for 2023, so I’d like to combine it with 2024 together in this one since 2023 is a very important year for me. I planned to write it after came back from <a href="/2024-03-19-Travel-Back-to-China.html">China’s travel</a> but never got the time. When I finally got the time it was already too late to write a year-end review. I’m staying in China again now (when I first started this article but I’ve been back when publishing it). While there is no work related thing to worry about when on vacation, I can use this time to review what happened in the past 2 years so it won’t slip through again.</p>

<h2 id="a-new-life">A New Life</h2>

<p>The most significant event happened in the past 2 years is that I have a daughter. Having a baby changed my life so much that it felt overwhelming at first. I always tried to keep my life simple and predictable, but a baby is the contrary of that. Before having the baby, I thought raising a baby is a science. While it is true on some level, it is also a kind of art. In theory, it’s about meet the baby’s need by observing, like feeding the baby, changing the diaper and so on. But in reality, there are lots of guess work about what the baby needs when she is crying, and it’s very stressful if you cannot figure it out. And sometimes she just cry for no reason (e.g. baby colic). Also sometimes you know what needs to be done, but it takes so much energy to do it. For example, in the first months, it’s really hard to get any good sleep and it takes a big troll on everyday life and the mental health.</p>

<p>However, after a few months, especially once the baby is more than 1 year old, it’s really awarding. Once she can bubble words, run all over the place, and express her cares about me, I feel everything is worth it. It’s such a special feeling that knowing you are raising a new life and be responsible for it. Because of that, I feel like my life is more meaningful and I value it much more than before.</p>

<h2 id="the-old-project-rss-brain">The Old Project: RSS Brain</h2>

<p>On the other hand, my old project <a href="https://rssbrain.com">RSS Brain</a> continue to get improvements. I’m so happy about this project because I can put theory into real world after I learned something. And I continue to use it everyday to get information from the Internet. Now I cannot imagine my Internet browsing without it. The feature set and backend is mostly stable in 2023. At the beginning of 2024, I started to refactor the frontend from Flutter to web tech. Mainly using htmx and Alpine.js with Scala to generate the html code from backend. This is such an important decision for this project and it turned out perfectly. Not only it feels native on web platform, the code is also much cleaner since it’s mostly Scala now – the same as the backend. The performance is also much better since most of the html is rendered from the server so the client needs little power compared to a Flutter one. On the way I also developed some frontend libraries for the project’s needs and wrote some blogs.</p>

<p>In the middle of 2024, I started to release the code of this project on a regular basis: I feel like the project is so cool that it’s a shame if only I can see the source code. There is still room of improvement on that side since there are still lots of doc missing, and it uses some other of my open source libraries that may not be released very properly. It would be great to clean it up so it’s easier to build and run on a fresh machine.</p>

<p>There are also some UI and life of quality features that can be continue improved. This would still be a project I continue to work on and release on a regular basis. Sometimes working on these small features is more like gardening, which makes me peace and relaxing when too many other things are happening in the life.</p>

<p>I may also add more AI features. I know AI is kind of a hype word now but that was the plan from the beginning. The name RSS Brain is meant to have some analysis features for the feeds so you can have more insights from them. The features it has now like search filters, related articles are like this. With the advance of the LLM, more things are possible and I’m pretty exited about. But before that, I need to find some proper infrastructure to do that, which will be discussed in the following sections about databases.</p>

<h2 id="distributed-system-infrastructure">Distributed System Infrastructure</h2>

<p>With RSS Brain as a use case, I try to setup my own infrastructure for a high available system. It took shape in 2023 and the final version can be found in <a href="/2023-11-28-Introduce-K3s-CephFS-and-MetalLB-to-My-High-Avaliable-Cluster.html">this blog post</a>. It works really good that I didn’t change much things in 2024. However there is a very important part that’s still missing: the upgrade of the system components. Since the services and even some infrastructure like CephFS are running in containers, there is no single command you can run to upgrade all the packages. Some images can be very outdated that there are some security risks. I meant to write some tools for upgrades but didn’t find the time for it. I suspect I wouldn’t have time for that in the coming year either but just list it here so that I don’t forget.</p>

<h2 id="in-search-of-databases">In Search of Databases</h2>

<p>There are 2 things motivated me to search for a new database: the license change of CockroachDB and the needs of vector similarity search. This work took lots of my time in the second half of 2024. For the first point, I talked it briefly in the blog post <a href="/2024-12-02-PostgreSQL-High-Availability-Solutions-Part-1.html">Jepsen Test on Patroni</a>, which I’m very proud of. I may write another blog post about it too so I will save the details for the future.</p>

<p>For the vector database, I think anyone that follows the AI trend recently would be all too familiar with that. There are 2 use cases for my projects: recommendation for RSS Brain using embeddings, and general RAG for LLMs.</p>

<p>I talked about the recommendation use case in the blog post <a href="/2023-11-14-Update-On-RSS-Brain-to-Find-Related-Articles-with-Machine-Learning.html">Update on RSS Brain to Find Related Articles with Machine Learning</a>: it’s now using Elastic Search for vector similarity search, but the performance is not so good with my less powerful cluster. So I’m searching for some other solutions that has lower memory footprint. And if possible, use it for full text search as well so that I don’t need to run Elastic Search at all.</p>

<p>About general RAG for LLMs, I’ve been interested in neural network based machine learning back in 2015. In my <a href="/2018-01-02-The-Year-of-2017.html">2017 retrospective</a>, I talked about the AI project I was working on. That’s when I read the paper <em>Attention is All You Need</em>, which is the foundation of the nowadays LLMs. I always wanted to develop some RPG game with human like AI and it seems finally to be technically possible. Along with some other tools I want to develop with LLMs in the coming year, a database that is capable for vector search is a must have. I’ve already did lots of research on that area but didn’t feel like I reached to a point to share it. So I’ll save it for a future blog post as well.</p>

<h2 id="blog-posts">Blog Posts</h2>

<p>In 2023, I <a href="/2023-11-10-Index-Sidebar-on-My-Blog.html">added an index sidebar to my blog</a>. It works really well. The blog posts in the past 2 years not only has better structure, but the quality is also better. My perspective has changed when I write a new blog post: instead of an one-off writing and maybe something I’ll not read again so much, the index structure makes me feel like I’m filling some holes in my knowledge graph, and it’s a forever ongoing project so I take more care about it. And like I mentioned in the previous blog post above, the structure also makes me aware what areas I’m focusing on so that I can adjust it if it’s not consistent with my goal.</p>

<h2 id="retro-hardware">Retro Hardware</h2>

<p>I always liked the aesthetic of some old hardware. The mechanical parts instead of a flat block with touch screen makes the design much more interesting and fun to use. In the past two years, I bought some retro hardware and it became a hobby:</p>

<p>In the first months of having my daughter, she had reflux so I need to hold her to sleep very often to avoid spitting up milk. In order to make the time easier, I bought a retro mini handheld game console <a href="https://officialmiyoomini.com/product/miyoo-mini-plus-v2-official-store-sale">Miyoo Mini+</a> so I can play games while holding her to sleep. It can simulate lots of games up to PS2 era. It opened a new world to me because there are so many great games in the past that are still fun to to play nowadays. In the past, I’ve already realised good games are not only good graphics. If we read classical books from many years ago, why shouldn’t we treat classic games like that? After flesh the custom ROM <a href="https://github.com/OnionUI/Onion">OnionUI</a>, I can also write some modern retro games for myself with platforms like <a href="https://tic80.com/">TIC-80</a>. The only complain is it doesn’t have bluetooth built in so I cannot use my Airpods (another device I bought to make the time of holding the baby easier) with it.</p>

<p>Another big part of the retro hardware is related to radio: I bought some AM/FM analog radios, wider brand digital radios, as well as software defined radio devices. I got interested in it after read the book <a href="https://www.goodreads.com/book/show/18114087-the-knowledge">The Knowledge: How to Rebuild Our World from Scratch</a>. It just feels so fun with the idea that you can send and capture information through the air. Technically the modern techs like mobile network and WIFI is still sending info through air, but the digital signal and too many layers added makes it less fun. Additionally, when it’s easy to find specific thing you want to consume nowadays, it’s very relaxing to consume passively like the old time TV channels. That’s kind of the idea I described in the blog <a href="/2024-06-03-Random-Video-Playlists-for-Self-Hosted-Videos.html">Random Playlists for Self Hosted Videos</a>. But even more relaxing with radios because you don’t even need to watch anything.</p>

<p>I also bought a second hand Nokia phone <a href="https://en.wikipedia.org/wiki/Nokia_5730_XpressMusic">Nokia 5730</a>. It’s very similar to my first phone Nokia 5320, but with a slide out keyboard. I wanted to play some old Symbian or Java mobile games but didn’t get much chance. It may stay in the drawer for a longer time because I have lots of other retro plans in the new year.</p>

<p>At last, I got a Thinkpad X220. This may worth a blog post on it’s own (again) so I will just be brief here. This is the laptop I always wanted since graduated (X200 before that). The company I was working for gave us Macbooks, which you cannot really complain. In the following years, I also bought Macbook as my personal laptop because it’s very hard to find the same level screen on other laptops. In recent years, there are multiple times I wanted to buy a used one for various reasons, but didn’t do that mainly because of the price. I finally did it in the last year since I found the second hand market in China is much cheaper than the ones in north America. So I got one pretty cheap and I’m surprised how capable it still is. I meant to play some old Windows game on it but it seems to be such a waste so I installed Linux on it. It works so well that I’m actually taking it for the travel instead my Thinkpad X1 Extreme (gen1).</p>

<p>About old PC gaming, I dual booted Windows on the Thinkpad X220. But then I found my old Thinkpad E40 at my parents’ place. So I will use the Thinkpad E40 for the purpose instead, which is pretty appropriate since it’s the first laptop I had. I played many games on it and there is no better device if I want to play more games from that era.</p>

<h2 id="conclusion">Conclusion</h2>

<p>Overall the life is more structured even with a new baby in my life. One factor may be I’ve moved to Toronto for a while and I’m used to the routine. The end of Covid is another big factor to make not only me but a lot of other people’s life back on track. I think a sentence in <a href="https://mastodon.binwang.me/@wangbin/112794830887081984">one of my poems</a> encapsulated my past 2 years pretty well but it’s hard to translate to English:</p>

<blockquote>
  <p>抱朴寻微末，结庐草太玄。</p>
</blockquote>

<p>“抱朴” (Bao Pu) is referred to the classical Taoist text <a href="https://en.wikipedia.org/wiki/Baopuzi">抱朴子</a>. Literally, it means “hug the simplicity”. “太玄” (Tai Xuan) is another famous text in Chinese history <a href="https://en.wikipedia.org/wiki/Taixuanjing">太玄经</a>. Literally, 太 means “too”, “supreme” or “great”. 玄 is a very special word in Taoist, which means mysterious, profound or difficult to understand. The author Yang Xiong spent lots of time to write it but it doesn’t really has any practice use and his work was not very mainstream in his era. So the sentence above can be roughly translated into:</p>

<blockquote>
  <p>Embracing the simplicity, I seek the profound and subtle.</p>

  <p>In a humble hut, I write Tai Xuan in solitude.</p>
</blockquote>]]></content><author><name></name></author><category term="life" /><summary type="html"><![CDATA[Here is another new year! I didn’t write any retrospective for 2023, so I’d like to combine it with 2024 together in this one since 2023 is a very important year for me. I planned to write it after came back from China’s travel but never got the time. When I finally got the time it was already too late to write a year-end review. I’m staying in China again now (when I first started this article but I’ve been back when publishing it). While there is no work related thing to worry about when on vacation, I can use this time to review what happened in the past 2 years so it won’t slip through again.]]></summary></entry><entry><title type="html">Jepsen Test on Patroni: A PostgreSQL High Availability Solution</title><link href="https://www.binwang.me/2024-12-02-PostgreSQL-High-Availability-Solutions-Part-1.html" rel="alternate" type="text/html" title="Jepsen Test on Patroni: A PostgreSQL High Availability Solution" /><published>2024-12-02T00:00:00-05:00</published><updated>2024-12-02T00:00:00-05:00</updated><id>https://www.binwang.me/PostgreSQL-High-Availability-Solutions---Part-1</id><content type="html" xml:base="https://www.binwang.me/2024-12-02-PostgreSQL-High-Availability-Solutions-Part-1.html"><![CDATA[<p><em>Note: code used in this article can be found on the Github repo <a href="https://github.com/wb14123/jepsen-postgres-ha">jepsen-postgres-ha</a>.</em></p>

<p>I’ve used Cockroach DB for a few of my side projects. I enjoyed it overall. But since it <a href="https://www.cockroachlabs.com/enterprise-license-update/">announced license change</a> and require mandatory telemetry collection for free version, I started to look for alternatives. The most nature choice is to just use the plain old PostgreSQL since my data size is not that big and even a less powerful machine can handle it without any problem. One of my important requirements for the database is to have good high availability setup so that I can just shutdown a machine for maintenance from time to time. This series of blog posts will focus on PostgreSQL’s HA solutions instead of why do we need that. Not saying why is not important enough but I’ll save that discussion for another blog post out of this series.</p>

<p>PostgreSQL doesn’t come with native high availability solution. Instead, it has features like replication to support you build your own HA solution. But we all know distributed system is hard to build and error-prone. So I’m planning to test different solutions before I trust my data with them: mainly using <a href="https://jepsen.io">Jepsen</a> to test the correctness at first and if it passes the test, benchmark it to make sure it’s usable in real world.</p>

<p>In the first part of this series, I’ll introduce the basic Jepsen test setup. Then use my early test result from <a href="https://github.com/patroni/patroni">Patroni</a>, a very popular PostgreSQL HA solution, as an example. In the test with Patroni, I’m able to:</p>

<ul>
  <li>Reproduce a known issue that causes violation of read committed isolation. This is related to a fundamental flaw in PostgreSQL’s replication implementation.</li>
  <li>Observe the cluster failed to recover with 1 node lose out of 3 nodes in total.</li>
</ul>

<p>Ideally I would like to do more tests and deeper digging into it, but I may not have enough free time in the coming 1 or 2 months so I’d like to record some result here and maybe have some updates later.</p>

<h2 id="jepsen-test-setup">Jepsen Test Setup</h2>

<p>The tool used in the tests is Jepsen. For the ones who are not familiar with it, it’s a tool to test the correctness of distributed systems. I highly recommend anyone interested in distributed systems to read its <a href="https://jepsen.io/analyses">analyses</a>, which have found bugs in almost every system it has tested, including <a href="https://jepsen.io/analyses/postgresql-12.3">PostgreSQL 12.3 with single machine setup</a>. On a high level, it runs queries and check if the data is consistent at the end, at the same time it has many built-in failures (nemesis in Jepsen’s term) can be introduced during the query, like node crash, network partition, network slowdown and so on. The analyses of PostgreSQL 12.3 already does an excellent job to explain how Jepsen tests PostgreSQL, so I’ll not repeat it here. I borrowed the append and read workload from that test but with 2 differences on other parts :</p>

<ol>
  <li>The database is setup in a different way. In the original test, it only tests a single machine PostgreSQL but the bugs are already fixed. So we are going to test a HA setup.</li>
  <li>In the original test, it was able to find bugs without import any failures. But since that bug has been fix, we are going to enable different built-in failures like node crash and network slowness to test if the PostgreSQL cluster can still behave correctly or not.</li>
</ol>

<p>To be more specific, I use <a href="https://www.vagrantup.com/">Vagrant</a> to create a 3 nodes virtual machine cluster and install Kubernetes (with <a href="https://k3s.io/">k3s</a>)on it. The Vagrantfile is <a href="https://github.com/wb14123/jepsen-postgres-ha/blob/master/cluster/Vagrantfile">here</a>. It’s mostly from a previous project I created to test k3s, as described in the blog post <a href="/2023-11-28-Introduce-K3s-CephFS-and-MetalLB-to-My-High-Avaliable-Cluster.html">Introduce K3s, CephFS and MetalLB to My High Avaliable Cluster</a>. This setup makes future tests for different HA solutions convenient since most of them supports Kubernetes, so that I can just create yaml files for different systems, while only need to implement Jepsen’s interface once to define database setup, tear down, kill and recover:</p>

<ul>
  <li>For setup, just use <code class="language-plaintext highlighter-rouge">kubectl create -f &lt;manifest.yaml&gt;</code>.</li>
  <li>For tear down, just use <code class="language-plaintext highlighter-rouge">kubectl delete -f</code> to delete the whole thing.</li>
  <li>To kill the db, find the root k3s process and <code class="language-plaintext highlighter-rouge">kill -9</code> it along with all its children process. Make sure to also stop the systemd service so it will not be automatically started again.</li>
  <li>To recover the db, simply start the k3s service again so that the pods will be scheduled on the node again. It just makes sure the k3s service is started. More health checks are needed if really want to wait for the db to be really recovered but it’s good for now.</li>
</ul>

<p>Related code is at <a href="https://github.com/wb14123/jepsen-postgres-ha/blob/3f5690f15cb34fdc196067786a48004dceae7ca8/src/jepsen/postgres_db.clj#L122">here</a>.</p>

<p>The code is meant to support any HA setup as long as it can be defined with a Kubernetes manifest. It supports <code class="language-plaintext highlighter-rouge">--cluster</code> flag so that can specify which manifest to test. I created a single node PostgreSQL setup and a Patroni setup for now. But in reality, Patroni has some special things that need to be taken care of, like delete PV and endpoints. I’ll clean those things up when my focus is moved to other HA solutions.</p>

<p>For the introduced failures, ideally we should test all the supported failures combined randomly. But the state space is large and need a long time to run. So I just created a specific combination to reproduce a known issue.</p>

<h2 id="a-known-issue-of-postgresql-replication">A Known Issue of PostgreSQL Replication</h2>

<p>When I searched for PostgreSQL HA solutions and whether any of them is tested by Jepsen, I found some <a href="https://news.ycombinator.com/item?id=23499611">comments on Hackernews</a> that says Patroni doesn’t guarantee consistency under some scenarios, which lead me to <a href="https://twitter.com/cyberdemn/status/1265710557006630913">the Twitter discussion</a>, which stated there is a fundamental flaw in PostgreSQL’s replication that makes it really hard to implement HA without data lose.</p>

<p>Here is the problem: usually with synced replication, a transaction should only be committed and visible after the replica db has persisted the transaction. So that if the primary db failed over to replica, there will be no data lose. But in a special scenario, where the query is cancelled after client sent commit command, PostgreSQL will consider it as committed even the transaction is not replicated yet. So when a failover happens at this time, this “committed data” will be lost from clients’ point of view. Here is an example:</p>

<table>
  <thead>
    <tr>
      <th>Time</th>
      <th>Node 1</th>
      <th>Node 2</th>
      <th>C1</th>
      <th>C2</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>1</td>
      <td>Role: Primary<br />Visible data: k -&gt; [1]</td>
      <td>Role: Replica<br />Visible data: k -&gt; [ 1 ]</td>
      <td> </td>
      <td> </td>
    </tr>
    <tr>
      <td>2</td>
      <td>Role: Primary<br />Visible data: k -&gt; [1]</td>
      <td> </td>
      <td>T1 start</td>
      <td> </td>
    </tr>
    <tr>
      <td>3</td>
      <td>Role: Primary<br />Visible data: k -&gt; [1]</td>
      <td> </td>
      <td>T1 append 2 to k</td>
      <td> </td>
    </tr>
    <tr>
      <td>4</td>
      <td>Role: Primary<br />Visible data: k -&gt; [1]</td>
      <td> </td>
      <td>T1 commit</td>
      <td> </td>
    </tr>
    <tr>
      <td>5</td>
      <td>T1 replication started</td>
      <td> </td>
      <td> </td>
      <td> </td>
    </tr>
    <tr>
      <td>6</td>
      <td> </td>
      <td> </td>
      <td>T1 aborted(conn close? client kill?)</td>
      <td> </td>
    </tr>
    <tr>
      <td>7</td>
      <td>T1 replication not finished, but T1 is visible to other clients<br /><br />Role: Primary<br />Visible data: k -&gt; [1,2]</td>
      <td>Role: Replica<br />Visible data: k -&gt; [ 1]</td>
      <td> </td>
      <td>T2 read k, result = [1,2]</td>
    </tr>
    <tr>
      <td>8</td>
      <td>Node crash</td>
      <td>Role: Primary<br />Visible data: k -&gt; [1]</td>
      <td> </td>
      <td> </td>
    </tr>
    <tr>
      <td>9</td>
      <td> </td>
      <td> </td>
      <td> </td>
      <td>T3 read k,<br />result = [1]</td>
    </tr>
    <tr>
      <td>10</td>
      <td> </td>
      <td> </td>
      <td>T4 append 3 to k</td>
      <td> </td>
    </tr>
    <tr>
      <td>11</td>
      <td> </td>
      <td>Role: Primary<br />Visible data: k -&gt; [1,3]</td>
      <td> </td>
      <td> </td>
    </tr>
    <tr>
      <td>12</td>
      <td> </td>
      <td> </td>
      <td> </td>
      <td>T5 read k,<br />result = [1, 3]</td>
    </tr>
  </tbody>
</table>

<p>In the example above, the value of <code class="language-plaintext highlighter-rouge">k</code> is <code class="language-plaintext highlighter-rouge">[1]</code> at the beginning. C1 will append monotonically increasing values to <code class="language-plaintext highlighter-rouge">k</code>. (It tracks the value locally instead of query <code class="language-plaintext highlighter-rouge">k</code> every time). T1 is aborted before it’s replicated. But even so, the primary node still treat this transaction as committed. So when C2 queries with T2, it get results with <code class="language-plaintext highlighter-rouge">[1, 2]</code>. Then at time 8, the primary is failed over from node 1 to node 2, so when T3 queries <code class="language-plaintext highlighter-rouge">k</code>, it returns <code class="language-plaintext highlighter-rouge">[1]</code> instead of <code class="language-plaintext highlighter-rouge">[1,2]</code>. This is an obvious data lose in our point of view because we know exactly the order of events. But one can argue it miss linearizable guarantee since technically, T3 can be ordered before T2 or even T1, and it will produce a consistent history, thus violates linearizable but not serializable. However, with T5 that has the result of <code class="language-plaintext highlighter-rouge">[1,3]</code>, it creates a situation that conflict with T2:</p>

<ul>
  <li>If T2 is before T5, T5 should has 2 in the result.</li>
  <li>If T5 is before T2, T2 should has 3 in the result.</li>
</ul>

<p>This is not only a violation of serializable, but also read committed because T2 has read the uncommitted data from the client’s point of view.</p>

<h2 id="patroni-setup-for-testing">Patroni Setup for Testing</h2>

<p>Even this is a known issue and is documented, I still try to reproduce it in my test for a few reason: first I want to make sure my test is good enough to actually be able to reproduce it. Second, I want to see it happens in real world: the Patroni auto failover makes manually triggering this problem hard because there is only a short time for the commit to be replicated.</p>

<p>In my test, I try to setup Patroni to make it prioritize consistency the most. The config is at <a href="https://github.com/wb14123/patroni/blob/9ecfbe6209af3b3fd686d77bb9beb04deabaf5a9/kubernetes/entrypoint.sh#L14">here</a> for the Docker’s entrypoint script and <a href="https://github.com/wb14123/jepsen-postgres-ha/blob/04ddd2bcc107f81eb8abdbcf14f0ad5e396dc6d0/cluster/patroni/k8s.yaml#L113">here</a> for the config in Kubernetes. The PostgreSQL version is 16 and Patroni version is v4.0.3.</p>

<p>The key configurations are about replication mode. The description of each parameter below is copied from <a href="https://patroni.readthedocs.io/en/latest/replication_modes.html">Patroni document about replication modes</a>:</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">synchronous_mode</code> is set to <code class="language-plaintext highlighter-rouge">on</code>: When <code class="language-plaintext highlighter-rouge">synchronous_mode</code> is turned on Patroni will not promote a standby unless it is certain that the standby contains all transactions that may have returned a successful commit status to client. Turning on synchronous_mode does not guarantee multi node durability of commits under all circumstances. When no suitable standby is available, primary server will still accept writes, but does not guarantee their replication.</li>
  <li><code class="language-plaintext highlighter-rouge">synchronous_mode_strict</code> is set to <code class="language-plaintext highlighter-rouge">on</code>: When it is absolutely necessary to guarantee that each write is stored durably on at least two nodes, enable <code class="language-plaintext highlighter-rouge">synchronous_mode_strict</code> in addition to the <code class="language-plaintext highlighter-rouge">synchronous_mode</code>. This parameter prevents Patroni from switching off the synchronous replication on the primary when no synchronous standby candidates are available.</li>
  <li><code class="language-plaintext highlighter-rouge">synchronous_node_count</code> is left to default as <code class="language-plaintext highlighter-rouge">1</code>: The parameter <code class="language-plaintext highlighter-rouge">synchronous_node_count</code> is used by Patroni to manage the number of synchronous standby databases. It is set to 1 by default. It has no effect when <code class="language-plaintext highlighter-rouge">synchronous_mode</code> is set to off. When enabled, Patroni manages the precise number of synchronous standby databases based on parameter <code class="language-plaintext highlighter-rouge">synchronous_node_count</code> and adjusts the state in DCS &amp; <code class="language-plaintext highlighter-rouge">synchronous_standby_names</code> in PostgreSQL as members join and leave. If the parameter is set to a value higher than the number of eligible nodes it will be automatically reduced by Patroni.</li>
</ul>

<p>In PostgreSQL:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>synchronous_commit: "on"
synchronous_standby_names: "*"
max_connections: 500
</code></pre></div></div>

<p>As stated in the Patroni doc, even with this setup it still has the known issue described above:</p>

<blockquote>
  <p>Note: Because of the way synchronous replication is implemented in PostgreSQL it is still possible to lose transactions even when using synchronous_mode_strict. If the PostgreSQL backend is cancelled while waiting to acknowledge replication (as a result of packet cancellation due to client timeout or backend failure) transaction changes become visible for other backends. Such changes are not yet replicated and may be lost in case of standby promotion.</p>
</blockquote>

<p>This is the thing I want to reproduce.</p>

<h2 id="reproduce-read-committed-violation">Reproduce Read Committed Violation</h2>

<p>The reproduce of this failure is harder than I thought, even I knew exactly the requirement to trigger it at the beginning. There are a few factors contributed to this:</p>

<p>First, if client doesn’t abort the connection itself, it’s hard to reproduce this scenario: Client not aborting the connection means it’s aborted by the primary node, which need to introduce some failures to primary node and that most likely makes it to failover immediately before the failure scenario is triggered. Jepsen’s built-in failures/nemesis are mostly on the server side. While not familiar with Clojure, it took me some time to figure out how to abort the connection just after sending the commit command. The code is at <a href="https://github.com/wb14123/jepsen-postgres-ha/blob/04ddd2bcc107f81eb8abdbcf14f0ad5e396dc6d0/src/jepsen/postgres/append.clj#L185">here</a>:</p>

<div class="language-clojure highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">(</span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="nb">and</span><span class="w"> </span><span class="n">break-conn</span><span class="w"> </span><span class="p">(</span><span class="nb">not</span><span class="w"> </span><span class="n">read-only?</span><span class="p">))</span><span class="w">
  </span><span class="p">(</span><span class="k">let</span><span class="w"> </span><span class="p">[</span><span class="n">result-chan</span><span class="w"> </span><span class="p">(</span><span class="nf">chan</span><span class="p">)</span><span class="w">
        </span><span class="n">close-chan</span><span class="w"> </span><span class="p">(</span><span class="nf">chan</span><span class="p">)</span><span class="w">
        </span><span class="p">]</span><span class="w">
    </span><span class="p">(</span><span class="nf">go</span><span class="w"> </span><span class="p">(</span><span class="nf">&gt;!</span><span class="w"> </span><span class="n">result-chan</span><span class="w"> </span><span class="p">(</span><span class="nf">try</span><span class="w"> </span><span class="p">(</span><span class="nf">run</span><span class="p">)</span><span class="w"> </span><span class="p">(</span><span class="nf">catch</span><span class="w"> </span><span class="n">Throwable</span><span class="w"> </span><span class="n">e</span><span class="w"> </span><span class="n">e</span><span class="p">))))</span><span class="w">
    </span><span class="p">(</span><span class="nf">go</span><span class="w"> </span><span class="p">(</span><span class="nf">&lt;!</span><span class="w"> </span><span class="p">(</span><span class="nf">timeout</span><span class="w"> </span><span class="mi">120</span><span class="p">))</span><span class="w">
        </span><span class="p">(</span><span class="nf">try</span><span class="w"> </span><span class="p">(</span><span class="nf">c/close!</span><span class="w"> </span><span class="n">conn</span><span class="p">)</span><span class="w"> </span><span class="p">(</span><span class="nf">catch</span><span class="w"> </span><span class="n">Throwable</span><span class="w"> </span><span class="n">e</span><span class="w"> </span><span class="n">e</span><span class="p">))</span><span class="w">
        </span><span class="p">(</span><span class="nf">&gt;!</span><span class="w"> </span><span class="n">close-chan</span><span class="w"> </span><span class="n">true</span><span class="p">))</span><span class="w">
    </span><span class="p">(</span><span class="nf">&lt;!!</span><span class="w"> </span><span class="n">close-chan</span><span class="p">)</span><span class="w">
    </span><span class="p">(</span><span class="k">let</span><span class="w"> </span><span class="p">[</span><span class="n">result</span><span class="w"> </span><span class="p">(</span><span class="nf">&lt;!!</span><span class="w"> </span><span class="n">result-chan</span><span class="p">)]</span><span class="w">
      </span><span class="p">(</span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="nb">instance?</span><span class="w"> </span><span class="n">Throwable</span><span class="w"> </span><span class="n">result</span><span class="p">)</span><span class="w">
        </span><span class="p">(</span><span class="nf">throw</span><span class="w"> </span><span class="n">result</span><span class="p">)</span><span class="w">
        </span><span class="n">result</span><span class="w">
        </span><span class="p">)))</span><span class="w">
  </span><span class="p">(</span><span class="nf">run</span><span class="p">))))</span><span class="w">
</span></code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">break-conn</code> is a boolean that produced from a random number. If it’s not a read only transaction, the client will close the connection after a timeout of 120ms. As I will talk about later, I introduced the network slowdown to make the round trip about 100ms in average, so a complete replicated transaction should take 100ms (client to primary) + 100ms (primary to replica) = 200ms. So 120ms will hopefully makes the connection abort after the commit command is sent to the primary but before the transaction is replicated. This is definitely not the perfect way but it’s the best I can do for now.</p>

<p>Second, the nemesis package I copied from the original test is not very suitable to reproduce this issue: it randomly introduce different failures (passed in by cli flags) by a predefined average interval. So it needs some luck to get the scenario that triggers this failure: a combination of slow network + primary failure. So after I studied the failure scenario again, I changed the nemesis suite to create slow network all the time, and create a 90 seconds cycle for primary failure (30 seconds healthy state + 60 seconds node killed).</p>

<p>Third, the default work load will create multiple keys and run multiple ops in a single transaction. Which makes it harder to trigger the exact scenario (the transaction network round trip time will be different depends on the number of ops so 120ms is less likely to close connection after commit). After think more about the requirement to trigger the failure, I tuned the parameters to operate on a single key most of the time and only have a single operation per transaction.</p>

<p>The other factors are mostly about my setup with VM + Kubernetes. For example, I need to figure out ways to do things like crash the node (k3s root process + children process). I also need to adjust the network interface name in network related failures since the VM created <code class="language-plaintext highlighter-rouge">eth1</code> instead of <code class="language-plaintext highlighter-rouge">eth0</code> hard coded in Jepsen.</p>

<p>At last, you need a little bit luck: the failures is hard to trigger so my test doesn’t reproduce it every time. Just before I decided to give up, it showed the error. The command to reproduce it is in the <a href="https://github.com/wb14123/jepsen-postgres-ha">readme</a>:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for </span>i <span class="k">in</span> <span class="sb">`</span><span class="nb">seq </span>1 10<span class="sb">`</span> <span class="p">;</span> <span class="k">do
  </span>lein run <span class="nb">test</span> <span class="nt">--nodes-file</span> ./nodes <span class="nt">--username</span> vagrant <span class="nt">-w</span> append <span class="nt">--concurrency</span> 10 <span class="nt">--isolation</span> serializable <span class="nt">--nemesis</span> packet,kill <span class="nt">--time-limit</span> 1800 <span class="nt">-r</span> 100 <span class="nt">--nemesis-interval</span> 60 <span class="nt">--break-conn-percent</span> 0.8 <span class="nt">--cluster</span> patroni <span class="nt">--key-count</span> 1 <span class="nt">--max-txn-length</span> 1 <span class="nt">--max-writes-per-key</span> 24000 <span class="nt">--nemesis-suite</span> slow-net-kill
  <span class="nb">sleep </span>30
<span class="k">done</span>
</code></pre></div></div>

<p>Some key params:</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">--time-limit 1800</code>: run the test for 1800 seconds.</li>
  <li><code class="language-plaintext highlighter-rouge">-r 100</code>: send 100 queries per second.</li>
  <li><code class="language-plaintext highlighter-rouge">--break-conn-percent 0.8</code>: 80% of the append transactions will be closed after 120ms.</li>
  <li><code class="language-plaintext highlighter-rouge">--key-count 1 --max-txn-length 1 --max-writes-per-key 24000</code>: operate on a single key until the operations exceed 24000 times.</li>
</ul>

<p>As stated above, the test slows down the network the whole time to an average of 100ms round trip. At the same time, it does this loop: wait 30 seconds. Kill the primary node by killing the k3s process and all its children processes. Wait 60 seconds. Start k3s service again.</p>

<p>At last, the outer for loop runs the command 10 times so it has a higher possibility to trigger the failure.</p>

<p>About why run the test 10 times instead of a single round of 300 mins, it’s related to another problem I found during the test which will be discussed in the later sections.</p>

<p>An example of the failure from a recent run:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>:workload {:valid? false,
            :anomaly-types (:incompatible-order),
            :anomalies {:incompatible-order ({:key 0,
                                              :values [[4
                                                        6
                                                        8
                                                        9
// ... omitted lines of numbers
                                                        7164
                                                        7171
                                                        7176
                                                        7181]
                                                       [4
                                                        6
                                                        8
                                                        9
// ... committed lines of numbers, the same as before
                                                        7164
                                                        7171
                                                        7176
                                                        8433]]})},
            :not #{:read-committed},
            :also-not #{:causal-cerone
                        :consistent-view
                        :cursor-stability
                        :forward-consistent-view
                        :monotonic-atomic-view
                        :monotonic-snapshot-read
                        :monotonic-view
                        :parallel-snapshot-isolation
                        :prefix
                        :read-atomic
                        :repeatable-read
                        :serializable
                        :snapshot-isolation
                        :strong-read-committed
                        :strong-serializable
                        :strong-session-read-committed
                        :strong-session-serializable
                        :strong-session-snapshot-isolation
                        :strong-snapshot-isolation
                        :update-atomic
                        :update-serializable}},
 :valid? false}
</code></pre></div></div>

<p>If you check the last 2 numbers for the 2 transactions listed above: one transaction reads <code class="language-plaintext highlighter-rouge">[..., 7176, 7181]</code> and another one reads <code class="language-plaintext highlighter-rouge">[...., 7176, 8433]</code>. It reproduced the exact problem we discussed in the last section.</p>

<p>One thing to notice is, even though the behaviour of this failure is the same as we discussed in the last section, it doesn’t necessarily mean it’s the same root cause. I say that because this failure is so hard to trigger and I’m not sure yet what exactly triggered it. This is another thing I want to digger deeper into but may not have the time in the near future.</p>

<h2 id="failed-to-recover-the-cluster-when-only-1-out-of-3-nodes-is-lost">Failed to Recover the Cluster When Only 1 Out of 3 Nodes is Lost</h2>

<p>Jepsen generates some graphs after the test. So you can see how the database behaves during the test. The following graph is one of them. It’s the latency of each transaction and the time range of imported nemesis:</p>

<p><img src="/static/images/2024-12-02-PostgreSQL-High-Availability-Solutions---Part-1/failure-latency-raw.png" alt="failure-latency" /></p>

<p>The green area at the top means the time that network is slowed down, which is basically during the whole test time in our case. The red part is when the primary node is killed by our test: the lighter red part means the killed node starts to recover by the test until it reaches the white part which means it has been recovered (we mark it as recovered as soon as k3s server is recovered, so it’s not that accurate).</p>

<p>Each square/point represents a transaction. You can see even without primary node being killed, there are still some failed transactions and that’s totally normal in our test: it has errors like conflicted transactions and max connections reached etc. The thing more related is whether there are successful transactions, which is the blue square/point means.</p>

<p>We can see during the first few rounds when the primary get killed, the cluster can recover with 2 of 3 nodes available (the red range). However, when the time passed by, it can only recover when all the nodes are available (the white range). At the end of the test, there are 2 of 3 nodes available (sometimes there are all 3 nodes available because the recovery time are not always the same so the end state of the test can also be different). Just out of curious, I wanted to see how much time Patroni needs to recover in such state, so I left it without make the failed node available and waited. However, after 20 minutes, the cluster is still not recovered.</p>

<p>This means the cluster is failed to recover even if you only lose a minor number of the nodes. After I <a href="https://github.com/patroni/patroni/issues/3194#issuecomment-2496586804">asked in the Github issue</a>, I got <a href="https://github.com/patroni/patroni/issues/3194#issuecomment-2497196127">confirmed</a> that Patroni cannot be auto healed from such state. Apparently this is kind of a known behaviour but came as a surprise to me. To be fair, the behaviour of the parameters are documented but it’s hard to realize the implication. Again quoted from the description before:</p>

<blockquote>
  <p><code class="language-plaintext highlighter-rouge">synchronous_node_count</code>: If the parameter is set to a value higher than the number of eligible nodes it will be automatically reduced by Patroni.</p>
</blockquote>

<p>It’s not clear what “eligible nodes” means but seems it means available nodes instead of all nodes in the cluster.</p>

<blockquote>
  <p><code class="language-plaintext highlighter-rouge">synchronous_mode_strict</code>: When it is absolutely necessary to guarantee that each write is stored durably on at least <strong>two nodes</strong> …</p>
</blockquote>

<p>So it’s two nodes instead of a majority of the nodes: if you have a 5 nodes cluster and you happen to lose the 2 nodes with the most up to date data, it’s not possible to recover the data anymore.</p>

<p>Checking the doc again, seems <a href="https://patroni.readthedocs.io/en/latest/replication_modes.html#quorum-commit-mode">quorum commit mode</a> is something can help here. But test with <code class="language-plaintext highlighter-rouge">synchronous_mode=quorum</code> still got the same result. And from the doc:</p>

<blockquote>
  <p>On each iteration of HA loop, Patroni re-evaluates synchronous standby choices and quorum, based on node availability and requested cluster configuration. In PostgreSQL versions above 9.6 all eligible nodes are added as synchronous standbys as soon as their replication catches up to leader.</p>
</blockquote>

<p>From the test, seems the availability of nodes also affect the quorum.</p>

<p>Back to the question about why need to run the tests multiple times instead of running a single longer test: because the cluster doesn’t recovery by itself during a node lost after a few kill loop, which means more time is needed for the healing between node kills and makes the test less efficient. Also, when wait enough time between node kills, I was not able to reproduce the read committed violation anymore. That’s another reason that I’m suspicious if it is really caused by early connection close or not.</p>

<h2 id="ways-to-improve">Ways to Improve?</h2>

<p>With a quorum based system, there is \(V_w\) means the min nodes to write for a write transaction. There is \(V_r\) means the min nodes to read for a read transaction. In order to maintain searilizable, \(V_w + V_r &gt; V\) needs to be true where \(V\) is the number of <strong>all nodes</strong>, so that \(V_w\) and \(V_r\) has at least 1 node overlapped. That means when a client reads data from \(V_r\) nodes, at least 1 node has the latest data. In our case, for the normal read transactions, \(V_r\) doesn’t matter since it only reads from the primary so it’s guaranteed to have the latest data. But when doing a failover, we need to make sure having \(V_r\) nodes available because primary is lost and we need to determine which node has the latest data.</p>

<p>In the case of Patroni, with <code class="language-plaintext highlighter-rouge">synchronous_node_count</code> can be auto reduced and <code class="language-plaintext highlighter-rouge">synchronous_mode_strict</code> only guarantees data writes to at least 2 nodes, \(V_w\) is essentially set to 2 which means in order to maintain consistency, \(V_r &gt; V - V_w = V - 2\) needs to be true, which means it only tolerates 1 node lose no matter the cluster size. But even with only 1 node lose in our test above, Patroni didn’t implemented auto failover.</p>

<p>So to make it better tolerate node lose, there should be an option similar to <code class="language-plaintext highlighter-rouge">synchronous_node_count</code> but actually enforce the minimal synced replication count instead of reduce it based on node availability. And if the available nodes meets the requirement of \(V_r\), do the auto failover by comparing the largest LSN on each node.</p>

<h2 id="minor-issue-wrong-role-label-for-kubernetes-pod">Minor Issue: Wrong Role Label for Kubernetes Pod</h2>

<p>At last there is a minor issue but also the first issue I found during the test: in the Patroni doc, it uses the command <code class="language-plaintext highlighter-rouge">kubectl get pods -L role -o wide</code> to show the role of each Patroni pod. However, it is inaccurate as <a href="https://github.com/patroni/patroni/issues/3194#issuecomment-2439591095">confirmed in the Github issue</a>. It’s not a big deal but something need to be aware when operate Patroni. I think theoretically it may be able to be fixed by let the primary pod set the k8s labels for all the other pods.</p>

<h2 id="whats-next">What’s Next?</h2>

<p>Ideally, I still want to dig deeper into Patroni’s test since it’s a very popular PostgreSQL HA solution. The test above is only a carefully create scenario based on a known issue. Running larger scale tests with more combined failure scenarios may be able to find more failure modes. However, because the fundamental PostgreSQL replicat flaw described above and the effort needed to run the large scale tests, I may want to setup and test another solution first.</p>

<p>The solution is what I had in mind even before I started Patroni’s Jepsen test, which is setup replication with <a href="https://linbit.com/drbd/">DRBD</a>: instead of using PostgreSQL’s replication, DRBD replicas the whole disk instead. With modern hardware, the performance with replication overhead should be acceptable but it remains to be tested, along with the correctness of it.</p>]]></content><author><name></name></author><category term="database" /><category term="jepsen" /><category term="test" /><category term="distributed system" /><category term="consistency" /><category term="HA" /><summary type="html"><![CDATA[Note: code used in this article can be found on the Github repo jepsen-postgres-ha.]]></summary></entry><entry><title type="html">SBT Task to Build Frontend Components</title><link href="https://www.binwang.me/2024-09-13-SBT-Task-to-Build-Frontend-Components.html" rel="alternate" type="text/html" title="SBT Task to Build Frontend Components" /><published>2024-09-13T00:00:00-04:00</published><updated>2024-09-13T00:00:00-04:00</updated><id>https://www.binwang.me/SBT-Task-to-Build-Frontend-Components</id><content type="html" xml:base="https://www.binwang.me/2024-09-13-SBT-Task-to-Build-Frontend-Components.html"><![CDATA[<p>Even writing a website using something else than Javascript to render content from server, sometimes it’s inevitable to have some Javascript or CSS code. So managing Javascript dependencies and build packages is needed. The easiest way may be just don’t use any tool: download all the dependency files into a directory and import them in the html file directly. That’s what I was doing for <a href="https://rssbrain.com">RSS Bran</a> before. But it get messy pretty quickly and it’s hard to keep track of the dependencies. So it’s time for me to resolve the problem. Since the project is written in Scala, I’ll note down how I do it with Scala’s build tool SBT.</p>

<h2 id="frontend-package-management-and-build">Frontend Package Management and Build</h2>

<p>I put all the frontend related code into a separate sub-directory and treat it like a frontend project. This makes things much easier and less hacky. I use npm to manage the dependencies and use webpack to build it. Here is a simplified example of the code tree structure from my project <a href="https://github.com/wb14123/rss_brain_release">RSS Brain</a>:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>▾ js/
  ▾ css/
      google-fonts.css
      main.css
      pico.jade.min.css
  ▾ dist/
      f20305dee9d396fea5c7.ttf
      f5ef242406fdcf40a232.otf
      main.css
      main.js
      main.js.LICENSE.txt
  ▾ fonts/
      google-material-icons-outlined.otf
      google-material-icons.ttf
  ▸ node_modules/
  ▾ src/
      boolean-checkbox.js
      error-handler.js
      global-htmx.js
      index.js
      match-id.js
      popover-menu.js
      register-service-worker.js
      service-worker.js
      set-theme.js
      source-images.js
    package-lock.json
    package.json
    readme.md
    webpack.config.js
▸ project/
▸ src/
  build.sbt
  LICENSE.txt
	readme.md
</code></pre></div></div>

<p>You can see other than the <code class="language-plaintext highlighter-rouge">js</code> directory, it’s a pretty standard structure for a Scala project managed by SBT.</p>

<p>When look into <code class="language-plaintext highlighter-rouge">js</code> directory, it’s a frontend project managed by npm and built with webpack.</p>

<p><code class="language-plaintext highlighter-rouge">js/src/index.js</code> bundles all the dependencies in node modules and local files. Here is an example:</p>

<div class="language-javascript highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// css</span>

<span class="k">import</span> <span class="dl">'</span><span class="s1">somment/somment.css</span><span class="dl">'</span><span class="p">;</span>
<span class="k">import</span> <span class="dl">'</span><span class="s1">lite-youtube-embed/src/lite-yt-embed.css</span><span class="dl">'</span><span class="p">;</span>
<span class="k">import</span> <span class="dl">'</span><span class="s1">toastify-js/src/toastify.css</span><span class="dl">'</span><span class="p">;</span>
<span class="k">import</span> <span class="dl">'</span><span class="s1">../css/google-fonts.css</span><span class="dl">'</span><span class="p">;</span>
<span class="k">import</span> <span class="dl">'</span><span class="s1">../css/pico.jade.min.css</span><span class="dl">'</span><span class="p">;</span>
<span class="k">import</span> <span class="dl">'</span><span class="s1">../css/main.css</span><span class="dl">'</span><span class="p">;</span>

<span class="c1">// js</span>
<span class="k">import</span> <span class="dl">'</span><span class="s1">./boolean-checkbox.js</span><span class="dl">'</span><span class="p">;</span>

<span class="k">import</span> <span class="dl">'</span><span class="s1">htmx.org</span><span class="dl">'</span><span class="p">;</span>
<span class="k">import</span> <span class="dl">'</span><span class="s1">./global-htmx.js</span><span class="dl">'</span><span class="p">;</span>

<span class="k">import</span> <span class="nx">Alpine</span> <span class="k">from</span> <span class="dl">'</span><span class="s1">alpinejs</span><span class="dl">'</span><span class="p">;</span>
<span class="nb">window</span><span class="p">.</span><span class="nx">Alpine</span> <span class="o">=</span> <span class="nx">Alpine</span><span class="p">;</span>

<span class="k">import</span> <span class="o">*</span> <span class="nx">as</span> <span class="nx">FloatingUIDOM</span> <span class="k">from</span> <span class="dl">'</span><span class="s1">@floating-ui/dom</span><span class="dl">'</span><span class="p">;</span>
<span class="nb">window</span><span class="p">.</span><span class="nx">FloatingUIDOM</span> <span class="o">=</span> <span class="nx">FloatingUIDOM</span><span class="p">;</span>

<span class="k">import</span> <span class="dl">'</span><span class="s1">lite-youtube-embed</span><span class="dl">'</span><span class="p">;</span>
<span class="k">import</span> <span class="dl">'</span><span class="s1">@splidejs/splide</span><span class="dl">'</span><span class="p">;</span>
<span class="k">import</span> <span class="nx">Toastify</span> <span class="k">from</span> <span class="dl">'</span><span class="s1">toastify-js</span><span class="dl">'</span><span class="p">;</span>
<span class="nb">window</span><span class="p">.</span><span class="nx">Toastify</span> <span class="o">=</span> <span class="nx">Toastify</span><span class="p">;</span>

<span class="k">import</span> <span class="nx">DOMPurify</span> <span class="k">from</span> <span class="dl">'</span><span class="s1">dompurify</span><span class="dl">'</span><span class="p">;</span>
<span class="nb">window</span><span class="p">.</span><span class="nx">DOMPurify</span> <span class="o">=</span> <span class="nx">DOMPurify</span><span class="p">;</span>

<span class="k">import</span> <span class="dl">'</span><span class="s1">imgs-html</span><span class="dl">'</span><span class="p">;</span>
<span class="k">import</span> <span class="dl">'</span><span class="s1">somment</span><span class="dl">'</span><span class="p">;</span>

<span class="k">import</span> <span class="dl">'</span><span class="s1">./error-handler.js</span><span class="dl">'</span><span class="p">;</span>
<span class="k">import</span> <span class="dl">'</span><span class="s1">./popover-menu.js</span><span class="dl">'</span><span class="p">;</span>
<span class="k">import</span> <span class="dl">'</span><span class="s1">./match-id.js</span><span class="dl">'</span><span class="p">;</span>
<span class="k">import</span> <span class="dl">'</span><span class="s1">./set-theme.js</span><span class="dl">'</span><span class="p">;</span>
<span class="k">import</span> <span class="dl">'</span><span class="s1">./source-images.js</span><span class="dl">'</span><span class="p">;</span>
<span class="k">import</span> <span class="dl">'</span><span class="s1">./register-service-worker.js</span><span class="dl">'</span><span class="p">;</span>

<span class="nx">Alpine</span><span class="p">.</span><span class="nf">start</span><span class="p">();</span>
</code></pre></div></div>

<p>Here is an example of <code class="language-plaintext highlighter-rouge">webpack.config.js</code>:</p>

<div class="language-javascript highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kd">const</span> <span class="nx">MiniCssExtractPlugin</span> <span class="o">=</span> <span class="nf">require</span><span class="p">(</span><span class="dl">"</span><span class="s2">mini-css-extract-plugin</span><span class="dl">"</span><span class="p">);</span>

<span class="nx">module</span><span class="p">.</span><span class="nx">exports</span> <span class="o">=</span> <span class="p">{</span>
  <span class="na">module</span><span class="p">:</span> <span class="p">{</span>
    <span class="na">rules</span><span class="p">:</span> <span class="p">[</span>
      <span class="p">{</span>
        <span class="c1">// If you enable `experiments.css` or `experiments.futureDefaults`, please uncomment line below</span>
        <span class="c1">// type: "javascript/auto",</span>
        <span class="na">test</span><span class="p">:</span> <span class="sr">/</span><span class="se">\.(</span><span class="sr">sa|sc|c</span><span class="se">)</span><span class="sr">ss$/i</span><span class="p">,</span>
        <span class="na">use</span><span class="p">:</span> <span class="p">[</span>
          <span class="nx">MiniCssExtractPlugin</span><span class="p">.</span><span class="nx">loader</span><span class="p">,</span>
          <span class="dl">"</span><span class="s2">css-loader</span><span class="dl">"</span><span class="p">,</span>
          <span class="dl">"</span><span class="s2">postcss-loader</span><span class="dl">"</span><span class="p">,</span>
        <span class="p">],</span>
      <span class="p">},</span>
    <span class="p">],</span>
  <span class="p">},</span>
  <span class="na">plugins</span><span class="p">:</span> <span class="p">[</span><span class="k">new</span> <span class="nc">MiniCssExtractPlugin</span><span class="p">()],</span>
<span class="p">};</span>
</code></pre></div></div>

<p>Since this is more related to frontend tech and is very basic, I will not go too much into details. But the point is, when run <code class="language-plaintext highlighter-rouge">npx webpack</code> under <code class="language-plaintext highlighter-rouge">js</code> directory, it will build bundled files into <code class="language-plaintext highlighter-rouge">js/dist</code>. We will write a SBT task to trigger this command and copy the dist files into resources to package.</p>

<h2 id="sbt-task-to-trigger-build-and-package-dist-files">SBT Task to Trigger Build and Package Dist Files</h2>

<p>SBT is very flexible since you can basically write Scala code to define the tasks. Here we define the first task to install npm dependencies and trigger webpack build (in <code class="language-plaintext highlighter-rouge">build.sbt</code>):</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">lazy</span> <span class="k">val</span> <span class="nv">webpack</span> <span class="k">=</span> <span class="n">taskKey</span><span class="o">[</span><span class="kt">Unit</span><span class="o">](</span><span class="s">"Run webpack in js directory"</span><span class="o">)</span>
<span class="n">webpack</span> <span class="o">:=</span>  <span class="o">{</span>
  <span class="k">val</span> <span class="nv">workDir</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">File</span><span class="o">(</span><span class="s">"./js"</span><span class="o">)</span>
  <span class="nc">Process</span><span class="o">(</span><span class="s">"npm"</span> <span class="o">::</span> <span class="s">"install"</span> <span class="o">::</span> <span class="nc">Nil</span><span class="o">,</span> <span class="n">workDir</span><span class="o">)</span> <span class="o">#&amp;&amp;</span> <span class="nc">Process</span><span class="o">(</span><span class="s">"npx"</span> <span class="o">::</span> <span class="s">"webpack"</span> <span class="o">::</span> <span class="nc">Nil</span><span class="o">,</span> <span class="n">workDir</span><span class="o">)</span> <span class="o">!</span>
<span class="o">}</span>
</code></pre></div></div>

<p>It defines a task called <code class="language-plaintext highlighter-rouge">webpack</code>, so when you run <code class="language-plaintext highlighter-rouge">sbt webpack</code>, it will run <code class="language-plaintext highlighter-rouge">npm install &amp;&amp; npx webpack</code> under <code class="language-plaintext highlighter-rouge">js</code>.</p>

<p>Then we define another task to copy all the dist files to generated resource directory:</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nc">Compile</span> <span class="o">/</span> <span class="n">resourceGenerators</span> <span class="o">+=</span> <span class="nv">Def</span><span class="o">.</span><span class="py">task</span> <span class="o">{</span>
  <span class="nv">webpack</span><span class="o">.</span><span class="py">value</span>
  <span class="k">val</span> <span class="nv">file</span> <span class="k">=</span> <span class="o">(</span><span class="nc">Compile</span> <span class="o">/</span> <span class="n">resourceManaged</span><span class="o">).</span><span class="py">value</span> <span class="o">/</span> <span class="s">"webview"</span> <span class="o">/</span> <span class="s">"static"</span> <span class="o">/</span> <span class="s">"dist"</span>
  <span class="nv">IO</span><span class="o">.</span><span class="py">copyDirectory</span><span class="o">(</span><span class="k">new</span> <span class="nc">File</span><span class="o">(</span><span class="s">"./js/dist"</span><span class="o">),</span> <span class="n">file</span><span class="o">,</span> <span class="n">overwrite</span> <span class="k">=</span> <span class="kc">true</span><span class="o">)</span>
  <span class="nv">IO</span><span class="o">.</span><span class="py">listFiles</span><span class="o">(</span><span class="n">file</span><span class="o">).</span><span class="py">toSeq</span>
<span class="o">}.</span><span class="py">taskValue</span>
</code></pre></div></div>

<p>Here we added some steps when SBT generate resource files: first we let it run <code class="language-plaintext highlighter-rouge">webpack</code> task we defined above, then copy all the files under <code class="language-plaintext highlighter-rouge">js/dist</code> to <code class="language-plaintext highlighter-rouge">webview/static/dist</code> under generated resources. Here resources means Java resource files, like the files under <code class="language-plaintext highlighter-rouge">src/main/resources</code>, but auto generated to <code class="language-plaintext highlighter-rouge">target/scala-2.13/resource_managed</code> and will be packaged together as resource files.</p>

<p>So when you run <code class="language-plaintext highlighter-rouge">sbt package</code> here, the generated jar package will include all those files as resource files. For example, in my project, the generated jar package have these if you open it with vim (which can view zipped package):</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>81663 webview/static/dist/f20305dee9d396fea5c7.ttf
81664 webview/static/dist/f5ef242406fdcf40a232.otf
81665 webview/static/dist/main.css
81666 webview/static/dist/main.js
81667 webview/static/dist/main.js.LICENSE.txt
</code></pre></div></div>

<h2 id="serve-resource-files-in-http-server">Serve Resource Files in Http Server</h2>

<p>Now you can serve the files under <code class="language-plaintext highlighter-rouge">webview/static/dist</code> with your web server. Different web server or framework do it differently. Here is an example of http4s:</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// include the following route into the http4s web server</span>
<span class="c1">// IMPORTANT: every resource file under `/webview` will be public accessible</span>
<span class="k">val</span> <span class="nv">assetsRoutes</span> <span class="k">=</span> <span class="n">resourceServiceBuilder</span><span class="o">[</span><span class="kt">IO</span><span class="o">](</span><span class="s">"/webview"</span><span class="o">).</span><span class="py">toRoutes</span>
</code></pre></div></div>

<p>Then you can use them in HTML:</p>

<div class="language-html highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nt">&lt;link</span> <span class="na">rel=</span><span class="s">"stylesheet"</span> <span class="na">href=</span><span class="s">"/static/dist/main.css"</span><span class="nt">&gt;</span>
<span class="nt">&lt;script </span><span class="na">src=</span><span class="s">"/static/dist/main.js"</span> <span class="na">defer=</span><span class="s">"defer"</span><span class="nt">&gt;&lt;/script&gt;</span>
</code></pre></div></div>]]></content><author><name></name></author><category term="Scala" /><category term="SBT" /><category term="Javascript" /><category term="CSS" /><category term="frontend" /><category term="webpack" /><category term="npm" /><summary type="html"><![CDATA[Even writing a website using something else than Javascript to render content from server, sometimes it’s inevitable to have some Javascript or CSS code. So managing Javascript dependencies and build packages is needed. The easiest way may be just don’t use any tool: download all the dependency files into a directory and import them in the html file directly. That’s what I was doing for RSS Bran before. But it get messy pretty quickly and it’s hard to keep track of the dependencies. So it’s time for me to resolve the problem. Since the project is written in Scala, I’ll note down how I do it with Scala’s build tool SBT.]]></summary></entry><entry><title type="html">My MacOS Essentials</title><link href="https://www.binwang.me/2024-08-07-My-MacOS-Essentials.html" rel="alternate" type="text/html" title="My MacOS Essentials" /><published>2024-08-07T00:00:00-04:00</published><updated>2024-08-07T00:00:00-04:00</updated><id>https://www.binwang.me/My-MacOS-Essentials</id><content type="html" xml:base="https://www.binwang.me/2024-08-07-My-MacOS-Essentials.html"><![CDATA[<p>As a long time Linux and KDE user, I’m pretty uncomfortable with the workflow of MacOS even though I have used MacOS fairly long as well. A lot of companies don’t support Linux to be used on the development laptop. Even for some companies that do support Linux, the hardware for Linux is usually far worse than Macbooks. So MacOS is often the best or even the only choice for work. This is still the case for my new job. I think it’s a good opportunity to write a blog about my MacOS setup. This can be a note for myself when I need to setup a fresh MacOS again in the future.</p>

<h2 id="my-complain-about-macos-desktop-environment">My Complain about MacOS Desktop Environment</h2>

<p>Everyone has different taste and needs about desktop environment and I respect that. The following is just based on my own preference. If you happen to have the same pain points, the setup may help you. Otherwise I find it’s pretty inspiring to see how other people work as well even though I may never work like that.</p>

<p>I mostly just use these apps for work:</p>

<ul>
  <li>A terminal. I use iTerm2 for this. I usually uses tmux to manage “windows” in terminal so I usually don’t open multiple iTerm2 windows.</li>
  <li>IDE. Usually Intellij Idea or other JetBrain family products.</li>
  <li>Browser: Firefox.</li>
  <li>Team collaboration software like Slack and Zoom.</li>
</ul>

<p>Most of those software are cross platform so I don’t have much complain about the software themselves. The things I want to change are on the desktop environment itself.</p>

<p>There is a thing in MacOS that I wouldn’t be used to in a million years: the logic of windows grouping for the same app. It results these problems:</p>

<p>First, it needs different keyboard shortcut when switch through windows. It just adds unnecessary complexity. Especially with my HHKB keyboard, the <code class="language-plaintext highlighter-rouge">~</code>/<code>`</code> key is far away from Tab key: it’s at the top right corner. And it’s hard to see from a glance what windows are available.</p>

<p>Talking about seeing what windows are available, the dock doesn’t do a good job as well. You can only see which apps are open. And I don’t feel it’s doing a good job even for that. Usually I just end with lots of opened windows/apps that’s no longer needed and it’s hard to keep track of them without a proper panel that shows all the windows.</p>

<h2 id="make-it-more-kdewindows-like">Make It More KDE/Windows Like</h2>

<p>So my goal here is to make it more KDE/Windows like, which means:</p>

<ul>
  <li>Use the same keyboard shortcut to cycle through all the windows, do not group the windows by app.</li>
  <li>Have a panel shows all the windows. Again, do not group by app.</li>
  <li>This is a good to have: use keyboard to snap windows on the left/right or maximum.</li>
</ul>

<p>I don’t need the “start menu” since I usually just open apps by bring up the searchable launcher: Spotlight in MacOS and KRunner in KDE.</p>

<p>So here are a list of software that archive my needs:</p>

<ul>
  <li><a href="https://alt-tab-macos.netlify.app/">AltTab</a>: cycle through all the windows without grouping by app.</li>
  <li><a href="https://rectangleapp.com/">Rectangle</a>: Windows snap and keyboard shortcuts</li>
  <li><a href="https://ubarapp.com/">uBar</a> or <a href="https://sidebarapp.net/">sidebar</a>: KDE/Windows like panel bar to show all windows.</li>
</ul>

<h2 id="other-quality-of-life-improvements">Other Quality of Life Improvements</h2>

<p>There are two other software I find very useful even though they are not related to the workflow above.</p>

<p>First, <a href="https://github.com/tombonez/noTunes">noTunes</a>. It bans the start of Apple Music. I find it’s very annoying that when I accidentally pressed some button or touched my Airpods, the Apple Music popped up. I don’t even know what triggered it. So this software solves this problem perfectly.</p>

<p>The second one is <a href="https://karabiner-elements.pqrs.org/">Karabiner-Elements</a>. This is a very powerful custom key mapping software. But I mainly use it to support two keyboards at the same time. That is a very very niche personal need: I use two same keyboards as split keyboard. I can write more on that in the future blogs. But the point is, MacOS doesn’t support two keyboards at the same time very well and this software solves that.</p>]]></content><author><name></name></author><category term="MacOS" /><category term="tools" /><category term="software" /><category term="desktop environment" /><summary type="html"><![CDATA[As a long time Linux and KDE user, I’m pretty uncomfortable with the workflow of MacOS even though I have used MacOS fairly long as well. A lot of companies don’t support Linux to be used on the development laptop. Even for some companies that do support Linux, the hardware for Linux is usually far worse than Macbooks. So MacOS is often the best or even the only choice for work. This is still the case for my new job. I think it’s a good opportunity to write a blog about my MacOS setup. This can be a note for myself when I need to setup a fresh MacOS again in the future.]]></summary></entry><entry><title type="html">Source Code of RSS Brain is Available</title><link href="https://www.binwang.me/2024-07-27-Source-Code-of-RSS-Brain-Is-Available.html" rel="alternate" type="text/html" title="Source Code of RSS Brain is Available" /><published>2024-07-27T00:00:00-04:00</published><updated>2024-07-27T00:00:00-04:00</updated><id>https://www.binwang.me/Source-Code-of-RSS-Brain-Is-Available</id><content type="html" xml:base="https://www.binwang.me/2024-07-27-Source-Code-of-RSS-Brain-Is-Available.html"><![CDATA[<p><em>This article is also posted at <a href="https://news.rssbrain.com/news/2024/07/26/Source-Code-Released">RSS Brain blog</a>.</em></p>

<p>When I first published <a href="https://www.rssbrain.com/">RSS Brain</a>, I promised the source code will be released (well, I actually said “open source”, but more on that later). After I rewrote the whole Flutter frontend with Javascript, most code is put into a single source repo. I feel comfortable to release it. So here it is on <a href="https://github.com/wb14123/rss_brain_release">Github</a>.</p>

<p>There are two things you may notice from the source code:</p>

<ul>
  <li>The commit history is mostly missing.</li>
  <li>The code license is not an open source license.</li>
</ul>

<p>I’ll talk about the most important one first: the code license.</p>

<h2 id="code-license">Code License</h2>

<p>RSS Brain’s source code is released under <a href="https://github.com/wb14123/rss_brain_release?tab=License-1-ov-file#readme">SSPL</a>, Server Side Public License. I don’t want to use “open source” as a market point for RSS Brain so I must make this clear first: technically, RSS Brain is a <a href="https://en.wikipedia.org/wiki/Source-available_software">source available software</a>, not an open source one, since SSPL is not recognized as an open source license.</p>

<p>SSPL is mostly the same as <a href="https://www.gnu.org/licenses/agpl-3.0.en.html">AGPL v3</a>, but with a key difference: it requires the user to release the source code of the whole stack if the project is used commercially. If you want to run the code on your own server and use RSS Brain freely, it’s all good. You can even share your server with family and friends. But as long as you start to charge money for that service, you need to release the source code of everything you use for the service, including things like OS, CI/CD, web server and so on. So it basically makes it impractical to use the source code commercially. I chose that feature on purpose.</p>

<h2 id="the-purpose">The Purpose</h2>

<p>Before I explain why I chose this license, I must explain the reasons of making RSS Brain’s source code available.</p>

<h3 id="transparent-algorithm">Transparent Algorithm</h3>

<p>In a past blog post <a href="https://www.binwang.me/2020-08-02-What-Is-Wrong-abount-Recommendation-System.html">What Is Wrong about Recommendation System</a>, I mentioned I don’t want to manipulated by recommendation systems. Ant that’s one of the main motivations for me to start write my own RSS reader. While there are still ranking and recommendation algorithms in RSS Brain, it’s aimed to provider better information instead of making the user more addicted to the product. In order to approve that, the algorithm needs to be available so that the users can inspect it and decide whether it’s the right one for them.</p>

<p>Be aware even the source code is available, it still needs some level of trust since the code running on my server <a href="https://app.rssbrain.com">app.rssbrain.com</a> can theoretically be different from what is being released. But it’s good enough for most people. However, if you want absolute control, you can always run it on your own server with the source code available.</p>

<h3 id="no-vendor-lock-in">No Vendor Lock-in</h3>

<p>Another important benefit is the user can expect the software to last. Even if I don’t host the service anymore, there is always a way to continue using it since the code is available. Yes it’s not commercial friendly, but if the software turned out to be really useful and attracted enthusiasts, I believe someone else will continue to maintain it for free. I think this property is critical for any product that needs to be used every day and becomes an important part of the digital life.</p>

<h3 id="no-free-commercial-usage">No Free Commercial Usage</h3>

<p>The next benefit is not for the user, but for myself. I want the <strong>users</strong> be able to self host the service for free, but I don’t want other people take my source code for free and earn money from it. I think that’s reasonable, especially considering I also provide paid hosted solution at <a href="https://app.rssbrain.com">app.rssbrain.com</a>.</p>

<h3 id="considerations-of-contributors">Considerations of Contributors</h3>

<p>One big advantage of open source project is it can attract contributors to make the software better. And it can sometimes justify the free commercial usage because all the competitors are contributing to the software. But because this is a software I am and will use daily, I want to have 100% control of the roadmap of it. Not only the product aspect, but also technology aspect. It’s just easier to write all the things by myself, at least for now. So I’m fine to chose a non open source license even with less potential contributors.</p>

<h2 id="release-process">Release Process</h2>

<p>You may notice the source code has very few commit history. The release process will be only one commit for each release. The release cycle will be one release every few weeks, depends on how much process I make. The regular releases will mostly on the weekend. If there is a bug or a security risk, the release maybe more frequent.</p>

<p>The version number is in the format of <code class="language-plaintext highlighter-rouge">X.Y.Z</code>. Where Y will be increased for every feature release and Z will be increased for every bug fix. X will only be increased for breaking changes or really major update.</p>

<p>I’ll make my hosted version at <a href="https://app.rssbrain.com">app.rssbrain.com</a> the same as the source code. Which means at each release, I’ll update the app first, and release the source code just after it. I’ll add a section in the app’s setting page to indicate the current version.</p>

<p>The reason I chose this release mode is the same reason as I released it under SSPL. I only want the source code be available to users, but I don’t really care about whether there will be contributions from other people. So hide the commit history between releases just make my life easier since I don’t need to care too much about keep my commit messages clean.</p>

<h2 id="roadmap">Roadmap</h2>

<p>With this source code released, everyone can inspect the algorithm to decide if this is the right product for them. However, for self-host, even if you can do it right now, it requires some undocumented configuration. So I’ll do the following things to make it easier:</p>

<ul>
  <li>Add documents for self-host.</li>
  <li>Add documents for admin operations like create admin users.</li>
  <li>Disable some components by default. To name a few:
    <ul>
      <li>There is an machine learning server mentioned in <a href="https://www.binwang.me/2023-11-14-Update-On-RSS-Brain-to-Find-Related-Articles-with-Machine-Learning.html">this blog</a>. I will likely disable it by default since I’m thinking about redo this part in the short future.</li>
      <li>Payment is not needed for self-hosted instances so I’ll disable it by default.</li>
      <li>There is an image proxy that I’ll likely to disable as well, just to make it easier to deploy.</li>
    </ul>
  </li>
</ul>]]></content><author><name></name></author><category term="RSS Brain" /><category term="open source" /><category term="source available" /><category term="project" /><category term="software engineer" /><summary type="html"><![CDATA[This article is also posted at RSS Brain blog.]]></summary></entry><entry><title type="html">A Review of Linux on Surface Pro 4</title><link href="https://www.binwang.me/2024-07-12-A-Review-of-Linux-on-Surface-Pro-4.html" rel="alternate" type="text/html" title="A Review of Linux on Surface Pro 4" /><published>2024-07-12T00:00:00-04:00</published><updated>2024-07-12T00:00:00-04:00</updated><id>https://www.binwang.me/A-Review-of-Linux-on-Surface-Pro-4</id><content type="html" xml:base="https://www.binwang.me/2024-07-12-A-Review-of-Linux-on-Surface-Pro-4.html"><![CDATA[<h2 id="background">Background</h2>

<p>I bought a Surface Pro 4 at 2016. It has an Intel Core m3-6Y30 CPU and 4GB memory. The spec is not that impressive even compared to an average laptop released years earlier. On the other hand, the form factor is very attractive to me: at a very low price, you get a tablet with a beautiful HiDPI 2k screen, a pressure sensitive stylus and an useable keyboard. It is on the heavier side if used as a tablet, but compared to other laptops, it’s very light. It served me very well for my limited use cases. The blog <a href="/2016-11-28-Config-Development-Environment-on-Windows.html">Build a Unix Like Environment on Windows</a> was written at that era. Some years later, I bought a more powerful laptop when I needed to work while traveling. So I gave the Surface away to a family member.</p>

<p>However, during the past years, I couldn’t stop thinking about having a Linux tablet. At first I checked <a href="https://pine64.org/devices/pinetab/">Pinetab</a>, then I realized I had a Surface which would be perfect if I could install Linux on it. I searched online and found some successful stories. So when I <a href="/2024-03-19-Travel-Back-to-China.html">travelled back to my hometown</a> at the beginning of this year, I brought the Surface back with me and started to experiment with it.</p>

<h2 id="use-cases">Use Cases</h2>

<p>Before I go further, I need to mention my intended use cases:</p>

<ul>
  <li>Browse Internet. Mainly <a href="https://www.rssbrain.com/">RSS Brain</a>, the RSS reader I built by myself.</li>
  <li>Media consumption: watch videos from my Samba share and online websites like Youtube.</li>
  <li>PDF reading: reading only is enough for me but it’s better if I can take notes in the PDF.</li>
  <li>Sketches: I don’t have a habit to do handwriting notes even at students era. Nowadays it’s more efficient and readable/searchable to take text notes with Markdown. However, I do like drawing sketches on paper when brain storming or resolving some hard problem. Moving it to digital has a lot of benefits if it works.</li>
  <li>Drawing: this is a good to have feature. I don’t really have needs to draw things but it’s always fun. Especially with the development of AI, if I draw something and send it to a more powerful machine to generate images, it could open doors to many possibilities.</li>
</ul>

<h2 id="installation">Installation</h2>

<p>The installation of Linux is actually very easy. I tried two distros and the installation process went very smooth for both of them. The distros I tried are <a href="https://endeavouros.com/">EndeavourOS</a> and Fedora workstation 40.</p>

<p>The installation steps are well documented in <a href="https://github.com/linux-surface/linux-surface/wiki/Installation-and-Setup#installation">linux-surface’s wiki</a>. <a href="https://github.com/linux-surface/linux-surface">linux-surface</a> is the Linux kernel and tools for Surface devices. The wiki page has its installation steps as well.</p>

<p>In general, if only used as a laptop, the experience is almost perfect even without the linux-surface kernel. But using it as a tablet is another story.</p>

<h2 id="what-works">What Works</h2>

<p>Let’s talk about what works first. Even without linux-surface kernel, almost everything works except touch screen and stylus. That includes things like wireless network, bluetooth, keyboard, power profile, UI scaling for Hi-DPI and so on. Multi touch and pressure sensitive stylus works as well (sort of, see sections below) after installed linux-surface kernel. Battery life is good enough: about 5-6 hours of light usage like web browsing, PDF reading, and about 3 hours of video watching. (Just some estimated time from my experience, no serious benchmarking was done).</p>

<p>On the software side, automatic screen rotation is enabled on both distros I tried. KDE with EndeavourOS is very fast and responsive. When the keyboard is detached, it enters tablet mode which makes some UI larger and more user friendly with touch gestures. For example, you can just touch on a folder to open it in Dolphin instead of double click it.</p>

<p>For Gnome, it’s less responsive than KDE but the UI is really beautiful when used as a tablet. I was never a fan after Gnome 3 but I guess the UI changes it made makes more sense on a tablet than on a laptop or a desktop. The overall layout really reminds you about the iPad or Android tablet (in a good way), but with the power of a real desktop OS at the same time. I would really like it if it uses less resource.</p>

<p>Even though the overall experience is positive and has the potential to meet all my use cases, one serious problem made it very unusable and made me gave up Linux on Surface at the end.</p>

<h2 id="the-problems-in-both-distros">The Problems in Both Distros</h2>

<p>The deal breaker problem is touch recognition. The problem is in the surface-linux tools so it affects all the distros. The biggest problem is ghost touch: touches are registered randomly even when I do nothing. I tried a lot of workarounds including the ones mentioned in <a href="https://github.com/linux-surface/linux-surface/wiki/Surface-Pro-5">linux-surface’s wiki page</a>, but none of them actually resolved it completely. Sometimes it’s fixed after reboot but reappeared after next reboot. Sometimes it get fixed for a period of time but reappeared after a system upgrade. Sometimes the touch screen doesn’t work at all after resume from sleep. The randomness and the serious of the problem is really annoying so I gave up using it with Linux at last.</p>

<p>Other than the ghost touching, another big problem about touch recognition is palm rejection. It’s really annoying when draw things with the pen. In iptsd (surface-linux’s deamon for touch recognition), there is a configuration to disable touch screen when using a pen but it doesn’t work well. So it makes drawing very unusable.</p>

<p>Both KDE and Gnome has virtual keyboards when the physical keyboard is detached, and works most of the time despite the problems I’ll mention in the following sections. But if you have setup disk encryption with a password, there is no virtual keyboard when you input the disk password, so a physical keyboard is always needed during the boot. Which can be annoying but not really a deal breaker.</p>

<p>The last big problem is battery drain during sleep. It uses about 30% battery for one night even it has been put into sleep. I had similar issues for other laptops. I believe there maybe some configurations I can tune to fix that. But after I gave up Linux on it because of the ghost touch, I didn’t dig deeper into that.</p>

<p>Other than the problems shared by both distros, each distro/desktop environment also has their own problems.</p>

<h2 id="the-problems-in-kde-with-endeavouros">The Problems in KDE with EndeavourOS</h2>

<p>The biggest problem in KDE other than the ones I talked above, is the virtual keyboard. It’s buggy and not very stable. Sometimes it kept pop up and sometimes it doesn’t show up. It’s annoying especially at the login screen: if it’s not popped up you will still need a physical keyboard, which prevent it to be a real tablet. Sometimes when the keyboard is popped up, the panel at the bottom cannot be touched. The bugs happened randomly that makes it hard to be properly reported.</p>

<p>Another problem is the touch gesture for right click. Naturally, with a touch screen, long press should be treated like a right click. But that is not the case for KDE. So a lot of operations just cannot be done without a mouse when you need a right click.</p>

<p>Resize a window is also very tricky with touch only operation: you need to touch on the boarder precisely on the first try.</p>

<p>At last, the scroll behaviour is not very smooth. It makes me a little bit dizzy just by scrolling through web pages and PDFs.</p>

<p>So I thought give another distro and desktop environment a try, to see if they can resolve my problems.</p>

<h2 id="the-problems-in-gnome-with-fedora-workstation-40">The Problems in Gnome with Fedora Workstation 40</h2>

<p>I choose Fedora because it comes with Gnome, and I had good experience with it before. After the installation, the first impression is it’s much slower than KDE with EndeavourOS. I found it enables swap and ZRam by default so I disabled them. It’s better but still slower than KDE. It uses more memory at around 40-50% percentage while idel. And I got a lot of OOM kills which almost never happened with KDE on EndeavourOS.</p>

<p>Maybe because of the slowness, it’s also buggy for lots of operations. For example, when switch to the workspace view from PDF viewer with 4 fingers swipe up, the PDF keeps scrolling at the background. And when scroll in the file manager, the context menu keeps popping up.</p>

<p>Other than the slowness, there is a problem on the virtual keyboard as well: the backspace key doesn’t work properly. I found a workaround by install a third-party Gnome addon, but sometimes the old keyboard still popped up.</p>

<h2 id="go-back-to-windows-10">Go Back to Windows 10</h2>

<p>I’d say if the touch recognition works well enough, all the other problems are acceptable with KDE. But with those problems, I finally decided to fallback to Windows 10 again. It works well enough, just as I remembered from years ago. However I abandoned OneNotes and some other Microsoft products and use the following software instead:</p>

<ul>
  <li>Firefox as the browser.</li>
  <li>Nextcloud to sync the files.</li>
  <li>Samba for video sharing.</li>
  <li>Built in video player for local video playing.</li>
  <li>Krita for drawing and sketches.</li>
  <li>Drawboard PDF for PDF reading.</li>
</ul>

<p>It’s pretty disappointing that this device cannot be used with Linux properly. But using Windows is still better to just let the device sitting there doing nothing. Maybe I will re-evaluate it after Windows 10 is end of life next year.</p>]]></content><author><name></name></author><category term="Linux" /><category term="Surface" /><category term="Microsoft" /><category term="Operating system" /><category term="tech" /><summary type="html"><![CDATA[Background]]></summary></entry><entry><title type="html">Create a Checkbox That Returns Boolean Value for htmx</title><link href="https://www.binwang.me/2024-06-08-Create-a-Checkbox-That-Returns-Boolean-Value-for-htmx.html" rel="alternate" type="text/html" title="Create a Checkbox That Returns Boolean Value for htmx" /><published>2024-06-08T00:00:00-04:00</published><updated>2024-06-08T00:00:00-04:00</updated><id>https://www.binwang.me/Create-a-Checkbox-That-Returns-Boolean-Value-for-htmx</id><content type="html" xml:base="https://www.binwang.me/2024-06-08-Create-a-Checkbox-That-Returns-Boolean-Value-for-htmx.html"><![CDATA[<h2 id="the-problem-of-checkbox">The Problem of Checkbox</h2>

<p><a href="https://htmx.org/">htmx</a> is a lightweight Javascript framework. We all know in native HTML, a <code class="language-plaintext highlighter-rouge">form</code> element can send a HTTP request to a server with the values of <code class="language-plaintext highlighter-rouge">input</code> elements. In htmx, this feature is made more powerful and flexible: you can include the value of any element, and with the help with htmx extensions like <a href="https://htmx.org/extensions/json-enc/">json-enc</a>, it can also post JSON data.</p>

<p>However, there is one thing that htmx inherited from the native HTML form behaviour: for checkboxes, it only includes its value when the checkbox is checked. And the default value for checkbox is <code class="language-plaintext highlighter-rouge">"on"</code> instead of <code class="language-plaintext highlighter-rouge">true</code> (even though you can change it to another value). I understand this decision because it wants to keep the same behaviour so there is no surprise, but it also makes the backend parsing very inconvenient. The checkbox field needs some special treatment at the backend: you need to know there is a checkbox field so that you can set it to false when it’s not submitted with the request, and set it to true otherwise.</p>

<p>In this article, we will explore how to define a custom checkbox element so that it has a boolean value and will always be submitted with the HTTP request. We first explore the implementation for htmx and then for native HTML.</p>

<h2 id="how-htmx-submit-the-checkbox-value">How htmx Submit the Checkbox Value</h2>

<p>In order to make it work with htmx, we first need to know how htmx do the HTTP request with parameters. The document doesn’t have a lot of details but we can always check the source code. The code that processes input values is in the function <a href="https://github.com/bigskysoftware/htmx/blob/d6afc5b8dbd7213037d0bc4213aa0b7b469bcd62/src/htmx.js#L2549"><code class="language-plaintext highlighter-rouge">processInputValue</code></a>:</p>

<div class="language-javascript highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kd">function</span> <span class="nf">processInputValue</span><span class="p">(</span><span class="nx">processed</span><span class="p">,</span> <span class="nx">values</span><span class="p">,</span> <span class="nx">errors</span><span class="p">,</span> <span class="nx">elt</span><span class="p">,</span> <span class="nx">validate</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">if </span><span class="p">(</span><span class="nx">elt</span> <span class="o">==</span> <span class="kc">null</span> <span class="o">||</span> <span class="nf">haveSeenNode</span><span class="p">(</span><span class="nx">processed</span><span class="p">,</span> <span class="nx">elt</span><span class="p">))</span> <span class="p">{</span>
        <span class="k">return</span><span class="p">;</span>
    <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
        <span class="nx">processed</span><span class="p">.</span><span class="nf">push</span><span class="p">(</span><span class="nx">elt</span><span class="p">);</span>
    <span class="p">}</span>
    <span class="k">if </span><span class="p">(</span><span class="nf">shouldInclude</span><span class="p">(</span><span class="nx">elt</span><span class="p">))</span> <span class="p">{</span>
        <span class="kd">var</span> <span class="nx">name</span> <span class="o">=</span> <span class="nf">getRawAttribute</span><span class="p">(</span><span class="nx">elt</span><span class="p">,</span><span class="dl">"</span><span class="s2">name</span><span class="dl">"</span><span class="p">);</span>
        <span class="kd">var</span> <span class="nx">value</span> <span class="o">=</span> <span class="nx">elt</span><span class="p">.</span><span class="nx">value</span><span class="p">;</span>
        <span class="k">if </span><span class="p">(</span><span class="nx">elt</span><span class="p">.</span><span class="nx">multiple</span> <span class="o">&amp;&amp;</span> <span class="nx">elt</span><span class="p">.</span><span class="nx">tagName</span> <span class="o">===</span> <span class="dl">"</span><span class="s2">SELECT</span><span class="dl">"</span><span class="p">)</span> <span class="p">{</span>
            <span class="nx">value</span> <span class="o">=</span> <span class="nf">toArray</span><span class="p">(</span><span class="nx">elt</span><span class="p">.</span><span class="nf">querySelectorAll</span><span class="p">(</span><span class="dl">"</span><span class="s2">option:checked</span><span class="dl">"</span><span class="p">)).</span><span class="nf">map</span><span class="p">(</span><span class="nf">function </span><span class="p">(</span><span class="nx">e</span><span class="p">)</span> <span class="p">{</span> <span class="k">return</span> <span class="nx">e</span><span class="p">.</span><span class="nx">value</span> <span class="p">});</span>
        <span class="p">}</span>
        <span class="c1">// include file inputs</span>
        <span class="k">if </span><span class="p">(</span><span class="nx">elt</span><span class="p">.</span><span class="nx">files</span><span class="p">)</span> <span class="p">{</span>
            <span class="nx">value</span> <span class="o">=</span> <span class="nf">toArray</span><span class="p">(</span><span class="nx">elt</span><span class="p">.</span><span class="nx">files</span><span class="p">);</span>
        <span class="p">}</span>
        <span class="nf">addValueToValues</span><span class="p">(</span><span class="nx">name</span><span class="p">,</span> <span class="nx">value</span><span class="p">,</span> <span class="nx">values</span><span class="p">);</span>
        <span class="k">if </span><span class="p">(</span><span class="nx">validate</span><span class="p">)</span> <span class="p">{</span>
            <span class="nf">validateElement</span><span class="p">(</span><span class="nx">elt</span><span class="p">,</span> <span class="nx">errors</span><span class="p">);</span>
        <span class="p">}</span>
    <span class="p">}</span>
    <span class="k">if </span><span class="p">(</span><span class="nf">matches</span><span class="p">(</span><span class="nx">elt</span><span class="p">,</span> <span class="dl">'</span><span class="s1">form</span><span class="dl">'</span><span class="p">))</span> <span class="p">{</span>
        <span class="kd">var</span> <span class="nx">inputs</span> <span class="o">=</span> <span class="nx">elt</span><span class="p">.</span><span class="nx">elements</span><span class="p">;</span>
        <span class="nf">forEach</span><span class="p">(</span><span class="nx">inputs</span><span class="p">,</span> <span class="kd">function</span><span class="p">(</span><span class="nx">input</span><span class="p">)</span> <span class="p">{</span>
            <span class="nf">processInputValue</span><span class="p">(</span><span class="nx">processed</span><span class="p">,</span> <span class="nx">values</span><span class="p">,</span> <span class="nx">errors</span><span class="p">,</span> <span class="nx">input</span><span class="p">,</span> <span class="nx">validate</span><span class="p">);</span>
        <span class="p">});</span>
    <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div>

<p>So it checks whether the element should be included through function <code class="language-plaintext highlighter-rouge">shouldInclude(elt)</code> and get its value if so (some additional logic for <code class="language-plaintext highlighter-rouge">select</code> and <code class="language-plaintext highlighter-rouge">file</code> but it’s not a concern here). In <a href="https://github.com/bigskysoftware/htmx/blob/d6afc5b8dbd7213037d0bc4213aa0b7b469bcd62/src/htmx.js#L2512"><code class="language-plaintext highlighter-rouge">shouldInclude</code></a>, it will only include a checkbox if it’s checked:</p>

<div class="language-javascript highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kd">function</span> <span class="nf">shouldInclude</span><span class="p">(</span><span class="nx">elt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">if</span><span class="p">(</span><span class="nx">elt</span><span class="p">.</span><span class="nx">name</span> <span class="o">===</span> <span class="dl">""</span> <span class="o">||</span> <span class="nx">elt</span><span class="p">.</span><span class="nx">name</span> <span class="o">==</span> <span class="kc">null</span> <span class="o">||</span> <span class="nx">elt</span><span class="p">.</span><span class="nx">disabled</span> <span class="o">||</span> <span class="nf">closest</span><span class="p">(</span><span class="nx">elt</span><span class="p">,</span> <span class="dl">"</span><span class="s2">fieldset[disabled]</span><span class="dl">"</span><span class="p">))</span> <span class="p">{</span>
        <span class="k">return</span> <span class="kc">false</span><span class="p">;</span>
    <span class="p">}</span>
    <span class="c1">// ignore "submitter" types (see jQuery src/serialize.js)</span>
    <span class="k">if </span><span class="p">(</span><span class="nx">elt</span><span class="p">.</span><span class="nx">type</span> <span class="o">===</span> <span class="dl">"</span><span class="s2">button</span><span class="dl">"</span> <span class="o">||</span> <span class="nx">elt</span><span class="p">.</span><span class="nx">type</span> <span class="o">===</span> <span class="dl">"</span><span class="s2">submit</span><span class="dl">"</span> <span class="o">||</span> <span class="nx">elt</span><span class="p">.</span><span class="nx">tagName</span> <span class="o">===</span> <span class="dl">"</span><span class="s2">image</span><span class="dl">"</span> <span class="o">||</span> <span class="nx">elt</span><span class="p">.</span><span class="nx">tagName</span> <span class="o">===</span> <span class="dl">"</span><span class="s2">reset</span><span class="dl">"</span> <span class="o">||</span> <span class="nx">elt</span><span class="p">.</span><span class="nx">tagName</span> <span class="o">===</span> <span class="dl">"</span><span class="s2">file</span><span class="dl">"</span> <span class="p">)</span> <span class="p">{</span>
        <span class="k">return</span> <span class="kc">false</span><span class="p">;</span>
    <span class="p">}</span>
    <span class="k">if </span><span class="p">(</span><span class="nx">elt</span><span class="p">.</span><span class="nx">type</span> <span class="o">===</span> <span class="dl">"</span><span class="s2">checkbox</span><span class="dl">"</span> <span class="o">||</span> <span class="nx">elt</span><span class="p">.</span><span class="nx">type</span> <span class="o">===</span> <span class="dl">"</span><span class="s2">radio</span><span class="dl">"</span> <span class="p">)</span> <span class="p">{</span>
        <span class="k">return</span> <span class="nx">elt</span><span class="p">.</span><span class="nx">checked</span><span class="p">;</span>
    <span class="p">}</span>
    <span class="k">return</span> <span class="kc">true</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div>

<h2 id="create-a-custom-checkbox-element-with-web-component">Create a Custom Checkbox Element with Web Component</h2>

<p>I tried to find or write an extension for htmx to include checkbox elements with boolean values, but from what I learnt in <a href="https://htmx.org/extensions/">the htmx extension doc</a>, there is no good way to do that. So I decided to create a custom HTML element that extends <code class="language-plaintext highlighter-rouge">input</code> to return boolean values for htmx to get.</p>

<p>With <a href="https://developer.mozilla.org/en-US/docs/Web/API/Web_components#attributechangedcallback">web component</a>, we can create a HTML tag that can be used just like any other built-in HTML tags. The <a href="https://developer.mozilla.org/en-US/docs/Web/API/Web_components/Using_custom_elements">MDN guide</a> does a good job to explain how to do it so I will not repeat it here. I’ll just put my implementation of the customized checkbox here:</p>

<div class="language-javascript highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kd">class</span> <span class="nc">BooleanCheckbox</span> <span class="kd">extends</span> <span class="nc">HTMLInputElement</span> <span class="p">{</span>
    <span class="nf">constructor</span><span class="p">()</span> <span class="p">{</span>
        <span class="k">super</span><span class="p">();</span>
    <span class="p">}</span>

    <span class="kd">get</span> <span class="nf">checked</span><span class="p">()</span> <span class="p">{</span>
        <span class="k">return</span> <span class="kc">true</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="kd">get</span> <span class="nf">value</span><span class="p">()</span> <span class="p">{</span>
        <span class="k">if </span><span class="p">(</span><span class="k">super</span><span class="p">.</span><span class="nx">checked</span><span class="p">)</span> <span class="p">{</span>
            <span class="k">return</span> <span class="kc">true</span><span class="p">;</span>
        <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
            <span class="k">return</span> <span class="kc">false</span><span class="p">;</span>
        <span class="p">}</span>
    <span class="p">}</span>
<span class="p">}</span>

<span class="nx">customElements</span><span class="p">.</span><span class="nf">define</span><span class="p">(</span><span class="dl">"</span><span class="s2">boolean-checkbox</span><span class="dl">"</span><span class="p">,</span> <span class="nx">BooleanCheckbox</span><span class="p">,</span> <span class="p">{</span> <span class="na">extends</span><span class="p">:</span> <span class="dl">"</span><span class="s2">input</span><span class="dl">"</span> <span class="p">});</span>
</code></pre></div></div>

<p>You can see it’s very simple. It extends the <code class="language-plaintext highlighter-rouge">input</code> element. It overwrite <code class="language-plaintext highlighter-rouge">checked</code> to always return <code class="language-plaintext highlighter-rouge">true</code> so that htmx will always include it in the request. And for <code class="language-plaintext highlighter-rouge">value</code>, it returns a boolean depends on <code class="language-plaintext highlighter-rouge">super.checked</code>. At last it register the customized element as a tag namedj<code class="language-plaintext highlighter-rouge">boolean-checkbox</code>, so that we can just use it like this in HTML:</p>

<div class="language-html highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nt">&lt;input</span> <span class="na">type=</span><span class="s">"checkbox"</span> <span class="na">is=</span><span class="s">"boolean-checkbox"</span> <span class="nt">/&gt;</span>Boolean checkbox
</code></pre></div></div>

<p>The <code class="language-plaintext highlighter-rouge">is="boolean-checkbox"</code> part tells the browser that this is a customized input element.</p>

<p>Here is a complete example:</p>

<div class="language-html highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">&lt;!DOCTYPE html&gt;</span>
<span class="nt">&lt;html&gt;</span>
  <span class="nt">&lt;head&gt;</span>
    <span class="nt">&lt;title&gt;</span>htmx boolean checkbox example<span class="nt">&lt;/title&gt;</span>
    <span class="nt">&lt;script </span><span class="na">src=</span><span class="s">"https://unpkg.com/htmx.org@1.9.12"</span><span class="nt">&gt;&lt;/script&gt;</span>
    <span class="nt">&lt;script </span><span class="na">src=</span><span class="s">"https://unpkg.com/htmx.org@1.9.12/dist/ext/json-enc.js"</span><span class="nt">&gt;&lt;/script&gt;</span>
    <span class="nt">&lt;script&gt;</span>
      <span class="kd">class</span> <span class="nc">BooleanCheckbox</span> <span class="kd">extends</span> <span class="nc">HTMLInputElement</span> <span class="p">{</span>
          <span class="nf">constructor</span><span class="p">()</span> <span class="p">{</span>
              <span class="k">super</span><span class="p">();</span>
          <span class="p">}</span>

          <span class="kd">get</span> <span class="nf">checked</span><span class="p">()</span> <span class="p">{</span>
              <span class="k">return</span> <span class="kc">true</span><span class="p">;</span>
          <span class="p">}</span>

          <span class="kd">get</span> <span class="nf">value</span><span class="p">()</span> <span class="p">{</span>
              <span class="k">if </span><span class="p">(</span><span class="k">super</span><span class="p">.</span><span class="nx">checked</span><span class="p">)</span> <span class="p">{</span>
                  <span class="k">return</span> <span class="kc">true</span><span class="p">;</span>
              <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
                  <span class="k">return</span> <span class="kc">false</span><span class="p">;</span>
              <span class="p">}</span>
          <span class="p">}</span>
      <span class="p">}</span>
      <span class="nx">customElements</span><span class="p">.</span><span class="nf">define</span><span class="p">(</span><span class="dl">"</span><span class="s2">boolean-checkbox</span><span class="dl">"</span><span class="p">,</span> <span class="nx">BooleanCheckbox</span><span class="p">,</span> <span class="p">{</span> <span class="na">extends</span><span class="p">:</span> <span class="dl">"</span><span class="s2">input</span><span class="dl">"</span> <span class="p">});</span>
    <span class="nt">&lt;/script&gt;</span>
  <span class="nt">&lt;/head&gt;</span>

  <span class="nt">&lt;body&gt;</span>
    <span class="nt">&lt;form&gt;</span>
      <span class="nt">&lt;div&gt;&lt;input</span> <span class="na">type=</span><span class="s">"checkbox"</span> <span class="na">name=</span><span class="s">"default-checkbox"</span> <span class="nt">/&gt;</span>Default checkbox<span class="nt">&lt;/div&gt;</span>
      <span class="nt">&lt;div&gt;&lt;input</span> <span class="na">type=</span><span class="s">"checkbox"</span> <span class="na">is=</span><span class="s">"boolean-checkbox"</span> <span class="na">name=</span><span class="s">"boolean-checkbox"</span> <span class="nt">/&gt;</span>Boolean checkbox<span class="nt">&lt;/div&gt;</span>
      <span class="nt">&lt;button</span> <span class="na">hx-post=</span><span class="s">"test-post"</span> <span class="na">hx-ext=</span><span class="s">"json-enc"</span><span class="nt">&gt;</span>Submit<span class="nt">&lt;/button&gt;</span>
    <span class="nt">&lt;/form&gt;</span>
  <span class="nt">&lt;/body&gt;</span>
<span class="nt">&lt;/html&gt;</span>
</code></pre></div></div>

<p>It defines two checkboxes: a native one and a customized one. We use the <code class="language-plaintext highlighter-rouge">json-enc</code> extension so it will post JSON as request body. When click the submit button, if both of them are unchecked, the post body looks like this:</p>

<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="nl">"boolean-checkbox"</span><span class="p">:</span><span class="kc">false</span><span class="p">}</span><span class="w">
</span></code></pre></div></div>

<p>And if both are selected, here is the post body:</p>

<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="nl">"default-checkbox"</span><span class="p">:</span><span class="s2">"on"</span><span class="p">,</span><span class="nl">"boolean-checkbox"</span><span class="p">:</span><span class="kc">true</span><span class="p">}</span><span class="w">
</span></code></pre></div></div>

<h2 id="what-about-the-native-html-form-action">What About the Native HTML Form Action</h2>

<p>The custom element <code class="language-plaintext highlighter-rouge">boolean-checkbox</code> only works with htmx to post boolean values. If you use native form action like this:</p>

<div class="language-html highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nt">&lt;form</span> <span class="na">action=</span><span class="s">"test-call"</span><span class="nt">&gt;</span>
  <span class="nt">&lt;input</span> <span class="na">is=</span><span class="s">"boolean-checkbox"</span> <span class="na">type=</span><span class="s">"checkbox"</span> <span class="na">name=</span><span class="s">"boolean-checkbox"</span><span class="nt">&gt;</span>Boolean Checkbox<span class="nt">&lt;/input&gt;</span>
  <span class="nt">&lt;button&gt;</span>Submit<span class="nt">&lt;/button&gt;</span>
<span class="nt">&lt;/form&gt;</span>
</code></pre></div></div>

<p>The behaviour is still like the native checkbox, which only posts value “on” when it’s checked.</p>

<p>Even though I don’t use the native form action, it still makes me wonder if I can support it. (Disclaimer: all the code below are experiments and I don’t recommend anyone uses it on production without careful tests.)</p>

<p>In fact, there is a way to set form value in web component through <a href="https://developer.mozilla.org/en-US/docs/Web/API/ElementInternals/setFormValue"><code class="language-plaintext highlighter-rouge">ElementInternals.setFormValue</code></a>:</p>

<div class="language-javascript highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">this</span><span class="p">.</span><span class="nx">internals</span> <span class="o">=</span> <span class="k">this</span><span class="p">.</span><span class="nf">attachInternals</span><span class="p">();</span>
<span class="k">this</span><span class="p">.</span><span class="nx">internals</span><span class="p">.</span><span class="nf">setFormValue</span><span class="p">(</span><span class="k">this</span><span class="p">.</span><span class="nx">value</span><span class="p">);</span>
</code></pre></div></div>

<p>However, in HTML standard, <code class="language-plaintext highlighter-rouge">ElementInternals</code> is not supported if the custom element is extending a built-in input element. Actually there is a <a href="https://github.com/whatwg/html/issues/5166">Github issue</a> asking for this feature, and the response to not support it doesn’t make sense to me:</p>

<blockquote>
  <p>Since Apple’s WebKit team’s position is that customized builtins shouldn’t exist in the first place, we don’t support this proposal.</p>
</blockquote>

<p>Anyway, it is what it is. So I need to workaround it. The solution I came up is to include another checkbox element as a child instead of inherit it. Here is the code:</p>

<div class="language-javascript highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kd">class</span> <span class="nc">BooleanCheckbox</span> <span class="kd">extends</span> <span class="nc">HTMLElement</span> <span class="p">{</span>

    <span class="kd">static</span> <span class="nx">formAssociated</span> <span class="o">=</span> <span class="kc">true</span><span class="p">;</span>

    <span class="nf">constructor</span><span class="p">()</span> <span class="p">{</span>
        <span class="k">super</span><span class="p">();</span>
        <span class="k">this</span><span class="p">.</span><span class="nx">internals</span> <span class="o">=</span> <span class="k">this</span><span class="p">.</span><span class="nf">attachInternals</span><span class="p">();</span>
    <span class="p">}</span>

    <span class="nf">connectedCallback</span><span class="p">()</span> <span class="p">{</span>
        <span class="k">this</span><span class="p">.</span><span class="nx">shadow</span> <span class="o">=</span> <span class="k">this</span><span class="p">.</span><span class="nf">attachShadow</span><span class="p">({</span><span class="na">mode</span><span class="p">:</span> <span class="dl">"</span><span class="s2">open</span><span class="dl">"</span><span class="p">});</span>
        <span class="kd">const</span> <span class="nx">internalCheckbox</span> <span class="o">=</span> <span class="nb">document</span><span class="p">.</span><span class="nf">createElement</span><span class="p">(</span><span class="dl">"</span><span class="s2">input</span><span class="dl">"</span><span class="p">);</span>
        <span class="nx">internalCheckbox</span><span class="p">.</span><span class="nf">setAttribute</span><span class="p">(</span><span class="dl">"</span><span class="s2">type</span><span class="dl">"</span><span class="p">,</span> <span class="dl">"</span><span class="s2">checkbox</span><span class="dl">"</span><span class="p">);</span>
        <span class="k">this</span><span class="p">.</span><span class="nf">getAttributeNames</span><span class="p">().</span><span class="nf">forEach</span><span class="p">((</span><span class="nx">name</span><span class="p">)</span> <span class="o">=&gt;</span> <span class="p">{</span>
            <span class="nx">internalCheckbox</span><span class="p">.</span><span class="nf">setAttribute</span><span class="p">(</span><span class="nx">name</span><span class="p">,</span> <span class="k">this</span><span class="p">.</span><span class="nf">getAttribute</span><span class="p">(</span><span class="nx">name</span><span class="p">));</span>
        <span class="p">});</span>
        <span class="k">this</span><span class="p">.</span><span class="nx">shadow</span><span class="p">.</span><span class="nf">appendChild</span><span class="p">(</span><span class="nx">internalCheckbox</span><span class="p">);</span>
        <span class="k">this</span><span class="p">.</span><span class="nx">internals</span><span class="p">.</span><span class="nf">setFormValue</span><span class="p">(</span><span class="nx">internalCheckbox</span><span class="p">.</span><span class="nx">value</span><span class="p">);</span>
        <span class="nx">internalCheckbox</span><span class="p">.</span><span class="nf">addEventListener</span><span class="p">(</span><span class="dl">'</span><span class="s1">change</span><span class="dl">'</span><span class="p">,</span> <span class="p">()</span> <span class="o">=&gt;</span> <span class="p">{</span>
            <span class="k">this</span><span class="p">.</span><span class="nx">internals</span><span class="p">.</span><span class="nf">setFormValue</span><span class="p">(</span><span class="k">this</span><span class="p">.</span><span class="nx">value</span><span class="p">);</span>
        <span class="p">});</span>
    <span class="p">}</span>

    <span class="kd">get</span> <span class="nf">checkbox</span><span class="p">()</span> <span class="p">{</span>
        <span class="k">return</span> <span class="k">this</span><span class="p">.</span><span class="nx">shadow</span><span class="p">.</span><span class="nf">querySelector</span><span class="p">(</span><span class="dl">"</span><span class="s2">input[type=checkbox]</span><span class="dl">"</span><span class="p">);</span>
    <span class="p">}</span>


    <span class="kd">get</span> <span class="nf">checked</span><span class="p">()</span> <span class="p">{</span>
        <span class="k">return</span> <span class="kc">true</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="kd">get</span> <span class="nf">value</span><span class="p">()</span> <span class="p">{</span>
        <span class="k">if </span><span class="p">(</span><span class="k">this</span><span class="p">.</span><span class="nx">checkbox</span><span class="p">.</span><span class="nx">checked</span><span class="p">)</span> <span class="p">{</span>
            <span class="k">return</span> <span class="kc">true</span><span class="p">;</span>
        <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
            <span class="k">return</span> <span class="kc">false</span><span class="p">;</span>
        <span class="p">}</span>
    <span class="p">}</span>

<span class="p">}</span>

<span class="nx">customElements</span><span class="p">.</span><span class="nf">define</span><span class="p">(</span><span class="dl">"</span><span class="s2">boolean-checkbox</span><span class="dl">"</span><span class="p">,</span> <span class="nx">BooleanCheckbox</span><span class="p">);</span>
</code></pre></div></div>

<p>It listens on the <code class="language-plaintext highlighter-rouge">checked</code> attribute on the child checkbox and update the form value based on it. <code class="language-plaintext highlighter-rouge">static formAssociated = true;</code> is needed so that we can set form values.</p>

<p>Then in HTML, we can use it like this:</p>

<div class="language-html highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nt">&lt;form</span> <span class="na">action=</span><span class="s">"/test-call"</span><span class="nt">&gt;</span>
  <span class="nt">&lt;div&gt;&lt;input</span> <span class="na">type=</span><span class="s">"checkbox"</span> <span class="na">name=</span><span class="s">"default-checkbox"</span> <span class="nt">/&gt;</span>Default Checkbox<span class="nt">&lt;/div&gt;</span>
  <span class="nt">&lt;div&gt;&lt;boolean-checkbox</span> <span class="na">name=</span><span class="s">"boolean-checkbox"</span><span class="nt">&gt;&lt;/boolean-checkbox&gt;</span>Boolean Checkbox<span class="nt">&lt;/div&gt;</span>
  <span class="nt">&lt;div&gt;&lt;button&gt;</span>Submit<span class="nt">&lt;/button&gt;&lt;/div&gt;</span>
<span class="nt">&lt;/form&gt;</span>
</code></pre></div></div>

<p>When click the submit button, it calls <code class="language-plaintext highlighter-rouge">/test-call?boolean-checkbox=false</code> if both checkboxes are unchecked and <code class="language-plaintext highlighter-rouge">/test-call?default-checkbox=on&amp;boolean-checkbox=true</code> if both are checked.</p>]]></content><author><name></name></author><category term="HTML" /><category term="htmx" /><category term="Javascript" /><category term="frontend" /><category term="tech" /><summary type="html"><![CDATA[The Problem of Checkbox]]></summary></entry><entry><title type="html">Random Playlists for Self Hosted Videos</title><link href="https://www.binwang.me/2024-06-03-Random-Video-Playlists-for-Self-Hosted-Videos.html" rel="alternate" type="text/html" title="Random Playlists for Self Hosted Videos" /><published>2024-06-03T00:00:00-04:00</published><updated>2024-06-03T00:00:00-04:00</updated><id>https://www.binwang.me/Random-Video-Playlists-for-Self-Hosted-Videos</id><content type="html" xml:base="https://www.binwang.me/2024-06-03-Random-Video-Playlists-for-Self-Hosted-Videos.html"><![CDATA[<p>With the development of computer systems and online streaming services, it’s never easier to play TV shows or movies on demand. There are some shows that I watch over and over when I want to relax. But the action of finding a show and selecting an episode makes it less causal. To some extent, I miss the old days to causally open a TV channel just to watch some random things. In this article, I will explain my journey to achieve that. More specifically, I want something like this:</p>

<ul>
  <li>Be able to add videos into collections and play videos randomly from a collection.</li>
  <li>Be able to share the collections and videos to other devices including:
    <ul>
      <li>Other desktops and laptops, including Linux and MacOS.</li>
      <li>Mobile devices including Android and iOS.</li>
      <li>TVs like Android TV box.</li>
    </ul>
  </li>
  <li>No transcoding on the server.</li>
  <li>The solution needs to be self hosted, free and open.</li>
</ul>

<p>I think I need to add more details about “no transcoding on the server” since a lot of solutions need that. All my devices are compatible to play the formats in my video collection. So it’s a waste of resource to do another transcoding on the server, especially my video server is also the desktop PC I use the most everyday. If this is not a requirement to you, you may be able to find much better solutions. That’s why I listed everything I’ve tried so it may help someone even it’s not the solution I chose at last.</p>

<p>So here you go. If you just want to see my final solution, go to the last section.</p>

<h2 id="ersatztv">ErsatzTV</h2>

<p><a href="https://ersatztv.org/">ErsatzTV</a> is a self hosted service to create live TV channels and stream them. You can add videos to collections, and put them into schedules. It works very much like a real TV channel. It has a Docker image and doesn’t need any external databases, so it’s really easy to try it out. Once you create channels it can generate m3u8 playlists so that you can stream it on any client that supports it.</p>

<p>It has great features. However, without transcoding on the server and use HLS Direct to stream the videos, there are some problems: I cannot open the stream in VLC. I could open it in Jellyfin, but once it jumps to another video with different format, it stops playing. I need to restart the client which is very annoying.</p>

<h2 id="jellyfin">Jellyfin</h2>

<p><a href="https://jellyfin.org/">Jellyfin</a> is a very popular media server. It’s like the more popular <a href="https://www.plex.tv/">Plex</a> but is free and open source. I was never a fan of Plex since it just doesn’t feel right to self host something you cannot really control. Jellyfin has gone a long way since I tried it a few years ago. You can add TV shows and movies to collections and play random videos from there. Even though it’s not as powerful as the schedule feature in ErsatzTV, it’s still great for my use case.</p>

<p>However, it falls short on “no transcoding on server” part again. The web client can only play a very limited video format. Its Linux client can play most video formats fairly well, but I still need my mobile devices be able to play the videos. The official Android and iOS clients are not any better than the web client. A third party iOS client <a href="https://github.com/jellyfin/Swiftfin">Swiftlin</a> does much better, but somehow it cannot play from a collection.</p>

<h2 id="kodi-with-samba">Kodi with Samba</h2>

<p>I use Kodi on my Android TV box all the time. The videos are shared through Samba. Kodi has <a href="https://kodi.wiki/view/Add-on:Play_Random_Videos">an offical add-on</a> to play random videos from TV shows, movies, folders and so on. However Kodi doesn’t have the concept of collection. It has playlist but it’s very hard to use. In theory you can symbol link all the videos to different folders as collections and play from there, but it’s too hacky. Kodi has an iOS client but it’s not in App Store so it needs to be compiled and resigned every a few days.</p>

<p>While I was exploring these ideas, I realized even Kodi doesn’t have any good built in playlist or collection feature, there are some file formats for video playlists. With that, we can even use other video clients. m3u file came to mind at first but the videos paths should be relative paths so it can be played from any device even though the mount point is different. At last I found <a href="https://en.wikipedia.org/wiki/XML_Shareable_Playlist_Format">XSPF</a> which allows relative path for the videos. With that, I came up with my final solution.</p>

<h2 id="xspf-playlist-on-samba-with-kodi-and-vlc">XSPF Playlist on Samba with Kodi and VLC</h2>

<p>So based on my exploration above, I came out an idea to use XSPF playlist to create collections. I just put the XSPF files in my videos folder to share through Samba together. Since the video paths are relative in the playlist, once you mount the Samba folder on other devices, you can just click the playlist and play it through supported clients.</p>

<p>For the clients, I use Kodi on the Android TV box and VLC on other devices. For Kodi, once <a href="https://kodi.wiki/view/Add-on:Play_Random_Videos">Play Random Videos add-on</a> is installed, you can long press on the playlist file to play a random video. VLC on desktops <a href="https://superuser.com/a/1808182">can be configured</a> to always play videos randomly from a playlist. On Android, there is an option to shuffle play once you open the playlist. But strangely, the VLC on my iPad is not able to play the XSPF file. I may dig into that in the future but it’s good enough for me now.</p>

<p>The only part left is to create the XSPF playlist. It’s a xml file so you can edit it manually but that takes too much time. So I created a Scala script to add or remove videos from a folder. Even though I used Scala for a long time and write my side projects with it, it’s the first time I use it as scripting and it’s such a pleasant with the help of <a href="https://ammonite.io/">Ammonite</a>. The script is on <a href="https://github.com/wb14123/xspf-editor">Github</a> so that you can also use it if needed.</p>]]></content><author><name></name></author><category term="video" /><category term="selfhost" /><category term="vlc" /><category term="kodi" /><category term="media" /><summary type="html"><![CDATA[With the development of computer systems and online streaming services, it’s never easier to play TV shows or movies on demand. There are some shows that I watch over and over when I want to relax. But the action of finding a show and selecting an episode makes it less causal. To some extent, I miss the old days to causally open a TV channel just to watch some random things. In this article, I will explain my journey to achieve that. More specifically, I want something like this:]]></summary></entry><entry><title type="html">Make Flutter Web Apps More Native Like</title><link href="https://www.binwang.me/2024-04-18-Make-Flutter-Web-App-More-Native-Like.html" rel="alternate" type="text/html" title="Make Flutter Web Apps More Native Like" /><published>2024-04-18T00:00:00-04:00</published><updated>2024-04-18T00:00:00-04:00</updated><id>https://www.binwang.me/Make-Flutter-Web-App-More-Native-Like</id><content type="html" xml:base="https://www.binwang.me/2024-04-18-Make-Flutter-Web-App-More-Native-Like.html"><![CDATA[<h2 id="background">Background</h2>

<p>I’ve built the client app of <a href="https://rssbrain.com">RSS Brain</a> with Flutter so that I don’t need to write different code for different platforms. It’s a pleasant to write Flutter code. And the app works good enough for Android and iOS. However, Flutter web support is a different story. You can feel the app is just not a normal website. I’m not satisfy with that. After attempts to make it more like a native web page and failed, I’m rewriting it with web technology again. That’s why the <a href="/2024-03-26-Prevent-HTMX-Lazy-Loaded-Content-From-Reload.html">last blog post</a> is about htmx.</p>

<p>Before I move on, I’d like to record what I have tried, as a note for myself and hopefully it can also help someone else. It’s really sad this article as my first blog about Flutter, maybe the only one for a long time.</p>

<h2 id="how-flutter-renders-a-web-page">How Flutter Renders a Web Page</h2>

<p>In Flutter, you define the UI widgets in Dart. And Flutter the engine will parse the widgets and render it to different targets: iOS, Android, web and even Windows and Linux applications. In principle, I think that is a good idea and I really enjoy writing Flutter code compared to Javascript frameworks like AngularJS or ReactJS. It’s really unfortunate the web support is not good enough to me.</p>

<p>The core problem is how Flutter renders the web pages. We all know a web page is represented in HTML. Even if we don’t write HTML directly but use a Javascript framework, it is manipulating HTML tags at the end. Flutter renders widgets to different HTML elements like <code class="language-plaintext highlighter-rouge">div</code> at first. However, it was later changed to draw all the widgets in a canvas. (The old render method is still available through <code class="language-plaintext highlighter-rouge">--web-render html</code> but I encountered multiple bugs and seems it’s given less and less care). This makes Flutter web apps doesn’t really behave like a native app, because a normal web page doesn’t have everything in a canvas.</p>

<p>For the problems it brings, I found solutions for some of them. For some others, I didn’t find one. The sections below are some of the problems and some of the solutions.</p>

<h2 id="make-text-selectable">Make Text Selectable</h2>

<p>By default, the text in Flutter app is not selectable. You can use the <a href="https://api.flutter.dev/flutter/material/SelectableText-class.html">SeletableText</a> widget to make text selectable.</p>

<h2 id="make-links-and-buttons-recognized-by-browser">Make Links And Buttons Recognized by Browser</h2>

<p>I use <a href="https://vimium.github.io/">Vimium</a> heavily. But Flutter rendering all the content into a canvas makes the clickable links and buttons not recognized by the browser, thus makes Vimium not working. This is a deal breaker for me, especially it’s something I built that breaks my workflow.</p>

<p>I found a solution at the end to make links and buttons recognizable. It can be done by enabling semantics support. Add this line in the main function after <code class="language-plaintext highlighter-rouge">runApp</code>:</p>

<div class="language-dart highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">SemanticsBinding</span><span class="o">.</span><span class="na">instance</span><span class="o">.</span><span class="na">ensureSemantics</span><span class="p">();</span>
</code></pre></div></div>

<p>This will render extra information in HTML instead of only drawing the canvas. It will make widgets like <code class="language-plaintext highlighter-rouge">Button</code> recognizable.</p>

<p>However, if you are using something more lower level like <code class="language-plaintext highlighter-rouge">GestureDetector</code>, you need to wrap the widgets with <code class="language-plaintext highlighter-rouge">Semantics</code>. Here is an example:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Semantics(button: true, enabled: true, child: myCustomClickable)
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">myCustomClickable</code> will be recognized as a clickable element with that.</p>

<h2 id="scrolling-behaviour">Scrolling Behaviour</h2>

<p>The scrolling feels choppy sometimes. And because the browser has no idea about the scroll position of the page, it just makes the scrolling behaviour feels different. For example, <a href="https://github.com/flutter/flutter/issues/69529">here</a> is a Github issue opened 4 years ago describing this kind of problem and is still not resolved. For me, this is the last straw to make me give up Flutter, since it breaks scrolling keyboard shortcuts of Vimium.</p>

<h2 id="conclusion">Conclusion</h2>

<p>The idea behind Flutter is great. I hope the web support can be better and better so that I can finally come back to it one day. But for now, I cannot wait for it and need to take another route. Stay tuned for more updates about that journey.</p>]]></content><author><name></name></author><category term="Flutter" /><category term="web" /><category term="UI" /><category term="Dart" /><summary type="html"><![CDATA[Background]]></summary></entry><entry><title type="html">Prevent htmx Lazy Loaded Content From Reloading</title><link href="https://www.binwang.me/2024-03-26-Prevent-HTMX-Lazy-Loaded-Content-From-Reload.html" rel="alternate" type="text/html" title="Prevent htmx Lazy Loaded Content From Reloading" /><published>2024-03-26T00:00:00-04:00</published><updated>2024-03-26T00:00:00-04:00</updated><id>https://www.binwang.me/Prevent-HTMX-Lazy-Loaded-Content-From-Reload</id><content type="html" xml:base="https://www.binwang.me/2024-03-26-Prevent-HTMX-Lazy-Loaded-Content-From-Reload.html"><![CDATA[<p>This is a short article about some tricks in <a href="https://htmx.org">htmx</a>. I have more to say about htmx but I’ll save that to another blog. In this one, I will skip the basics about htmx and assume you already know that.</p>

<h2 id="1-problem">1. Problem</h2>

<p>I’ll briefly introduce two features of htmx in order the explain the problem. You can go to official website for more details about the features.</p>

<h3 id="11-browser-history">1.1. Browser History</h3>

<p>htmx has <a href="https://htmx.org/docs/#history">a feature to interact with browser history</a>. Here is an example in the official document:</p>

<div class="language-html highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nt">&lt;a</span> <span class="na">hx-get=</span><span class="s">"/blog"</span> <span class="na">hx-push-url=</span><span class="s">"true"</span><span class="nt">&gt;</span>Blog<span class="nt">&lt;/a&gt;</span>
</code></pre></div></div>

<p>This will change the url in browser to <code class="language-plaintext highlighter-rouge">/blog</code> when you click the link and save a snapshot of current page into local storage. When you click back button in browser, htmx will try to find the cache in local storage, and swap it out so you don’t need to reload the whole page.</p>

<h3 id="12-lazy-load">1.2. Lazy Load</h3>

<p>htmx sends requests when an event is triggered on an element. The rule is defined by <a href="https://htmx.org/attributes/hx-trigger/">hx-trigger</a> attribute. There are some special events can be used for lazy loading:</p>

<ul>
  <li>load - triggered on load (useful for lazy-loading something).</li>
  <li>revealed - triggered when an element is scrolled into the viewport (also useful for lazy-loading).</li>
  <li>intersect - fires once when an element first intersects the viewport.</li>
</ul>

<p>However, when combined this with history support, the lazy loaded elements will be requested again when the pages are navigated in history. Here is an example:</p>

<div class="language-html highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nt">&lt;a</span> <span class="na">hx-get=</span><span class="s">"/page1"</span> <span class="na">hx-push-url=</span><span class="s">"true"</span> <span class="na">hx-target=</span><span class="s">"#content"</span><span class="nt">&gt;</span>page1<span class="nt">&lt;/a&gt;</span>
<span class="nt">&lt;div</span> <span class="na">id=</span><span class="s">"content"</span> <span class="na">hx-get=</span><span class="s">"/content"</span> <span class="na">hx-trigger=</span><span class="s">"load"</span><span class="nt">&gt;&lt;/div&gt;</span>
</code></pre></div></div>

<p>When you click on <code class="language-plaintext highlighter-rouge">page1</code>, it will replace <code class="language-plaintext highlighter-rouge">#content</code> with the response from <code class="language-plaintext highlighter-rouge">/page1</code> and change the URL. However, when you click on back in browser, htmx will send a request to <code class="language-plaintext highlighter-rouge">/content</code> again even though it’s already in history cache, because technically, <code class="language-plaintext highlighter-rouge">#content</code> <strong>is</strong> loaded again so <code class="language-plaintext highlighter-rouge">hx-get</code> is triggered based on <code class="language-plaintext highlighter-rouge">hx-trigger</code> rule. This results a waste of resource and can sometimes make the webpage lost previous scroll position.</p>

<p>In this article, I’ll show some tricks to prevent this. They are very simple once you know them but sometimes it’s just hard to get when you are new to the framework.</p>

<h2 id="2-best-solution-swap-outer-html-instead-of-inner-html">2. Best Solution: Swap Outer HTML instead of Inner HTML</h2>

<p>I think this is the best solution. It’s so simple that I don’t know why I didn’t get it earlier. Anyway, that’s why I write this blog so that it can help more people like me.</p>

<p>By default, htmx swap the inner HTML of the element. So the <code class="language-plaintext highlighter-rouge">hx-trigger="load"</code> attribute is still there after the content is loaded and will be triggered again when load from history. The solution is to just let htmx swap the outer HTML instead. Using the same example, the code will be changed to this:</p>

<div class="language-html highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nt">&lt;a</span> <span class="na">hx-get=</span><span class="s">"/page1"</span> <span class="na">hx-push-url=</span><span class="s">"true"</span> <span class="na">hx-target=</span><span class="s">"#content"</span><span class="nt">&gt;</span>page1<span class="nt">&lt;/a&gt;</span>
<span class="nt">&lt;div</span> <span class="na">id=</span><span class="s">"content"</span> <span class="na">hx-get=</span><span class="s">"/content"</span><span class="nt">&gt;</span>
  <span class="nt">&lt;div</span> <span class="na">hx-get=</span><span class="s">"/content"</span> <span class="na">hx-trigger=</span><span class="s">"load"</span> <span class="na">hx-target=</span><span class="s">"this"</span> <span class="na">hx-swap=</span><span class="s">"outerHTML"</span><span class="nt">&gt;&lt;/div&gt;</span>
<span class="nt">&lt;/div&gt;</span>
</code></pre></div></div>

<p>In the new implementation, we have another <code class="language-plaintext highlighter-rouge">div</code> tag inside <code class="language-plaintext highlighter-rouge">#content</code> to do the lazy load. After the response is loaded, it will swap out the whole <code class="language-plaintext highlighter-rouge">div</code> element so <code class="language-plaintext highlighter-rouge">hx-get</code> and <code class="language-plaintext highlighter-rouge">hx-trigger</code> are not there anymore when the snapshot is taken and loaded from history.</p>

<p>As I said, this is the best solution in my mind and I think it fits all the cases. So if you only care about the solution, you can stop reading here. I record the following solutions simply because I figured them out earlier than this one.</p>

<h2 id="3-solution-b-dont-snapshot-the-whole-body">3. Solution B: Don’t Snapshot the Whole Body</h2>

<p>The solution above removes the htmx attributes. The solution in section tackles the problem in another direction: it prevents the element from loading again when go back in history.</p>

<p>By default, htmx will take the snapshot of <code class="language-plaintext highlighter-rouge">body</code> and put it into history cache. That’s why when go back in history, the <code class="language-plaintext highlighter-rouge">load</code> event of the element is triggered again. To prevent it, we can let htmx only snapshot children of <code class="language-plaintext highlighter-rouge">#content</code>. <a href="https://htmx.org/docs/#specifying-history-snapshot-element">Here</a> is the official doc about how to do it. Using the same example, the code will be changed into:</p>

<div class="language-html highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nt">&lt;a</span> <span class="na">hx-get=</span><span class="s">"/page1"</span> <span class="na">hx-push-url=</span><span class="s">"true"</span> <span class="na">hx-target=</span><span class="s">"#content"</span><span class="nt">&gt;</span>page1<span class="nt">&lt;/a&gt;</span>
<span class="nt">&lt;div</span> <span class="na">id=</span><span class="s">"content-load"</span> <span class="na">hx-get=</span><span class="s">"/content"</span> <span class="na">hx-trigger=</span><span class="s">"load"</span> <span class="na">hx-target=</span><span class="s">"#content"</span><span class="nt">&gt;&lt;/div&gt;</span>&gt;
<span class="nt">&lt;div</span> <span class="na">id=</span><span class="s">"content"</span> <span class="na">hx-history-elt</span><span class="nt">&gt;&lt;/div&gt;</span>
</code></pre></div></div>

<p>Here we load the content with <code class="language-plaintext highlighter-rouge">#content-load</code> element. htmx will only swap out <code class="language-plaintext highlighter-rouge">#content</code> when we forward or go back in browser history since we added <code class="language-plaintext highlighter-rouge">hx-history-elt</code> on <code class="language-plaintext highlighter-rouge">#content</code>. This prevents <code class="language-plaintext highlighter-rouge">load</code> event from being triggered on <code class="language-plaintext highlighter-rouge">#content-load</code> so it will not send a new request.</p>

<p>But this solution has great limitations: you need to change the snapshot element which is not always possible.</p>

<h2 id="4-solution-c-remove-htmx-action-attributes-before-taking-snapshot">4. Solution C: Remove htmx Action Attributes Before Taking Snapshot</h2>

<p>This is a solution that could work in theory but I didn’t test it, because I came up with the best solution when thinking about it.</p>

<p>The idea is similar: we don’t want htmx action attributes like <code class="language-plaintext highlighter-rouge">hx-get</code> when we load the history. Other than swap the whole outerHTML, there is a htmx event you can catch in Javascript to remove the attribute before taking a snapshot:</p>

<div class="language-javascript highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nx">htmx</span><span class="p">.</span><span class="nf">on</span><span class="p">(</span><span class="dl">'</span><span class="s1">htmx:beforeHistorySave</span><span class="dl">'</span><span class="p">,</span> <span class="kd">function</span><span class="p">()</span> <span class="p">{</span>
  <span class="nb">document</span><span class="p">.</span><span class="nf">getElementById</span><span class="p">(</span><span class="dl">'</span><span class="s1">#content</span><span class="dl">'</span><span class="p">).</span><span class="nf">removeAttributes</span><span class="p">(</span><span class="dl">"</span><span class="s2">hx-get</span><span class="dl">"</span><span class="p">))</span>
<span class="p">})</span>
</code></pre></div></div>]]></content><author><name></name></author><category term="htmx" /><category term="web" /><category term="UI" /><category term="Javascript" /><summary type="html"><![CDATA[This is a short article about some tricks in htmx. I have more to say about htmx but I’ll save that to another blog. In this one, I will skip the basics about htmx and assume you already know that.]]></summary></entry><entry><title type="html">Travel Back to China</title><link href="https://www.binwang.me/2024-03-19-Travel-Back-to-China.html" rel="alternate" type="text/html" title="Travel Back to China" /><published>2024-03-19T00:00:00-04:00</published><updated>2024-03-19T00:00:00-04:00</updated><id>https://www.binwang.me/Travel-Back-to-China</id><content type="html" xml:base="https://www.binwang.me/2024-03-19-Travel-Back-to-China.html"><![CDATA[<p>After more than 4 years staying aboard without being able to go back to China because of Covid, I finally had the chance and spent this Chinese New Year at my hometown. Now I’ve come back to Toronto, it’s time to record it when my memory and feelings are still fresh.</p>

<h2 id="before-we-go">Before We Go</h2>

<p>Being able to travel back doesn’t mean it’s easy. The number of flights between China and other countries are still not recovered to pre Covid level. In order to keep our budget in a reasonable level, we need to fly through 2 stops, and then drive more than 3 hours to home from the airport. The flying time and the waiting time at airport combined is more than 24 hours. It’s a very long trip for any adult, not to mention traveling with a 6 months old baby. I was very nervous about that since our longest trip with the baby was taking her to the clinic. But since we haven’t been back for so many years, this is a travel that shouldn’t be delayed anymore. On the bright side, my sister in law will come to meet us at the first stop Tokyo. We will stay there for a few days for resting and sight seeing.</p>

<p>Things were not smooth before we go. First, our company had a bad outrage during the holiday season so I needed to work overtime. Following that was hot debates about the following steps to make our services better, which made me very frustrate for reasons I’d rather not to talk here. And during all these things, the whole family also caught cold and had fever for a few days. It’s the first time the baby is sick so it’s very stressful situation. The baby awoke every 2 hours at night while my wife and I were sick. When everyone finally recovered, we barely had the time to get new Covid vaccines and pack the baggages.</p>

<p>Anyway, we successfully handled everything before we go, took the 15 hours long flight and headed to our first stop, Tokyo.</p>

<h2 id="stay-in-tokyo">Stay in Tokyo</h2>

<p>I had been to Tokyo twice. But they are both many years ago and I didn’t have enough time to see the whole city. Even though it’s a relatively short visit again this time: just 3 - 4 days, it still got me excited to be there again.</p>

<p>We wanted to book a hotel near Asakusa (浅草) area since Sensō-ji is a must see site in Tokyo. We also want a subway station nearby. At last we found a place near Ueno (上野) station. It’s a traditional Japanese style hotel that has Tatamis, which is perfect for us: our baby doesn’t like to sleep in the crib anymore, so Tatamis is much safer since she cannot fall from it, and the mattress is also much firmer than the ones in regular hotels, which prevent the baby’s face from buried into the mattress. And she can also play on it during day time as well.</p>

<p>Only after I booked the hotel, I found out Ueno area is a place I wanted to visit but didn’t have enough time last time: when my wife and I visited Tokyo last time, we planned to take the train from Ueno station to the airport. We didn’t notice the schedule of that train is less frequent than subway. So we didn’t plan the time ahead and missed it. Disappointedly, we decided to have some food near Ueno station first. That’s when we found out the area around Ueno: there are many pedestrian streets filled with street food, outdoor eatings, restaurants, shops, and people. I was so fascinated by it and it was a shame that we didn’t have enough time to explore the area since we needed to head to Kyoto at that day. I forgot the name of that area since then because we were in such a hurry and we visited so many places in Japan after that. But when I was checking the surrounding area of the hotel on Google Maps, the Ueno station struck my memory and I was so excited that I had another opportunity to fully explore that area.</p>

<p>So Ueno and Asakusa are where we explored most when we were at Tokyo. We went to the Tokyo National Museum and enjoyed the ukiyo-e (浮世絵, wood block prints) exhibition that I wanted to see long before we went. We ate some delicious food at Ueno area. We also bought some electronic devices and manga books at Akihabara (秋葉原). What I didn’t expect was the experience at Asakusa: last time I only visited Sensō-ji and the street in the front of it. I didn’t know there is a larger area surrounding it that has lots of traditional Japanese style buildings, shops and restaurants. We found a shop by coincidence that sells high quality ukiyo-e prints. There are many places selling them in Tokyo, but they are either low quality or too expensive. I’m so glad to find a shop that sells lots of high quality prints in reasonable price range.</p>

<p>The whole experience in Tokyo is very positive. The mix of tradition Japanese and modern culture creates a very unique vibe. Because Japanese culture is largely impacted by Chinese culture in the past, I think I can appreciate more of the beauty of it. I have a fresh eye when I looked at the city after I explored more on the topic of city design in the past years: the non car centric culture, high quality public transit and high density of population makes it very different from North American cities. The city is more vibrant, much cleaner and safer, and have so many interesting places to explore. But unfortunately, Japan is a country better for visiting than long term living for foreigners because of its (almost non-exist of) immigration culture and stressful working environment.</p>

<p>The biggest happy surprise we got from Japan is our baby can sleep the whole night! It’s such a life changing improvement for my wife and me. After having the baby, I felt like there is nothing more important than being able to sleep a whole night. It’s so great to have that back!</p>

<p>On that happy note, we continued the trip back to home.</p>

<h2 id="back-to-hometown">Back to Hometown</h2>

<p>I thought there would be lots of feelings on the road to home. But there wasn’t. Maybe because of there are too many concrete things to worry about with a baby on the road so it left little room for feelings.</p>

<p>With the things happened in the past years in China: the lockdown of cities during Covid, the re-election of Xi which broke the political practice, the protests of both the re-eleciton and lockdowns, the broke of Evergrande Group, and the downhill of America-China relationship, you’d imagine China is in a pretty bad place. However, when I went back to home, I found things were not as bad as I thought. Yes, economic has gone bad: there are lots of unfinished buildings, small businesses are struggling, it’s harder to find a job for new grad, nationalism is on the rise and so on. But on another hand, at least from my limited experience, people’s life is still going on. I saw there is disapproval when people talk about the economic and government policies, but I saw little desperation feelings. When there are fewer ways to make life better, people continue to find new ways. For good or for bad, that’s the resilience of Chinese people. Maybe it looks better than normal because it’s holiday season: the malls and restaurants are packed with people. Beautiful decoration lights are everywhere. There are fireworks everyday.</p>

<p>Theoretically, fireworks have been banned for many years in China. However, with the lift of lockdown at the end of last year, there were lots of celebrations with fireworks at the new year (not the Chinese New Year) and created some conflicts between the crowd and the police in some cities. After that, the ban of fireworks still exists but is rarely enforced. Fireworks in the new year’s eve has been a tradition since ancient time. But in my opinion, the mixed feelings it brings represents the complexity of contemporary China perfectly: It’s believed to be able to dispel bad luck, which is much needed after the Covid and the following weak economic. It extends to some level of superstitious that some people believe it can cleanup the virus in the air. It also seems to be a subtle way to express disapproval of government policies because the ban is still in place. Of cause there is also pure excitement about the lights and sounds, the happiness about holiday, and wishes for a better year ahead.</p>

<p>Another reason of the weak economic not showing much trace may be my hometown is a small city so the trend is kind of lagged behind. It’s still benefiting from the development of the bigger cities in the past years: more and more big brands and chain stores are opening so there are more choices when buying things. Food delivery is more convenient. There are also more culture innovation products with better traditional Chinese aesthetic. If not considering education and healthcare system, the everyday life has little difference from big cities, or even better because of the less stressful working environment.</p>

<p>Not all things are good. Not mentioning the things that were already there before I left China, there is one new development that would trouble me a lot if I lived for a longer time: the lack of privacy both in the real world and in the cyber space. In the real world, cameras are everywhere. Lots of people start to use smart locks on the door that has a camera that you cannot avoid when you pass by. You must have scan the face in order to enter some residential compounds. Every crossing has high resolution cameras recording license numbers of cars and are able to recognize the drivers. In Beijing, face is recorded when entering every subway station. Even worse, when I was playing arcade games in a mall, the arcade machine has a camera that took a photo of me without reminding me first. On the cyber space side, there is little service you can use without installing an app and register an account that linked to your phone number and in turn linked to your ID. The worst experience I had is at a parking lot: there was no person at the exit and you need to scan the QR code to register an account, input personal details and pay the fee in order to leave. Again, there was nothing reminds you that before you actually try to leave and scan the QR code. I guess it’s not like there is no one in China cares about the privacy, it’s more like an already lost battle because the desire of surveillance from both the government and tech giants, and the lack of power to balance that.</p>

<p>Another thing I dislike is the trend of city planning. I think the city did a very good job in the past: reasonable density and mixed use was very well maintained. There are dedicated bike lanes, wide sidewalks and reasonable public transit coverage. However, with the widely adoption of cars, things got worth and the city seems just want to change things in the name of changing. That’s kind of understandable because there are more opportunity for corrupt when there are more projects. But at the end, parking lots replaced lots of green spaces on sidewalks. Roads has been re-designed with confusing turning lanes which replaced some bike lanes. Traffic lights replaced lots of roundabouts, and even worse, sometimes traffic lights are combined with roundabouts which is totally unnecessary. If the changes are limited because of the old foundation, then it’s not surprise that the worse place happens at the newly developed areas. It’s mostly all high rise residential buildings with little commercial uses. That’s kind of understandable as well since one of the main income of government is by selling land to developers. Seems like there were some commercial uses planned but the progress get delayed because of the real estate crisis. But the most ridiculous part is the roadway network design: there are many very wide roads. Many of them have 10 lanes! And some of them even have additional 2-3 lanes service road on each side. Be aware those are not highways. In a grid layout, those very wide roads are just beside residential buildings and are connected without skipping any crossing. It’s such a waste of resource because if there are so many cars that such wide roads are needed, then the non exist of road hierarchy doesn’t make any sense. Combined with the lack of commercial uses, it makes people rely more on cars and makes traffic very bad for commercial areas. Just go outside for a walk like the old days is not enjoyable anymore in the newly developed areas.</p>

<p>Despite all those things, it’s still a vacation at my hometown. So my mind was laid back even though I was very busy physically: my wife’s sister got married just days after we arrived. My wife and I also had the wedding that was planned years ago but got pushed because of Covid. I’m very happy how the wedding went considering we need to take care of the baby at the same time. If we were not preparing for the wedding, we took the baby to my parents and my in-law’s places. Between the gaps, I also needed to find some time to meet with friends that I haven’t seen for a long time. So it’s a very packed schedule but it’s so different (in a good way) to be close with family and friends again. Being aboard so many years and having a baby gave me a new perspective of the importance of family and friends.</p>

<p>However, I couldn’t stay there for long. I left half a month’s parental leave for the travel. But even combined with that, one month is basically the most I can have for a vacation and the company doesn’t allow work from China. So even we felt like we haven’t spent much time at home yet, we needed to go back. The trip back to Toronto has 3 stops on the way. So it’s another battle to fight. Our first stop is Beijing and we will stay at the airport for one night.</p>

<h2 id="one-night-in-beijing">One Night in Beijing</h2>

<p>I lived in Beijing for 8 years. It’s the second longest city I’ve lived in, just behind my hometown. It’s the longest if considering only the time of adulthood. So I have lots of memory and friends there. It’s unfortunate that I can only stay there for one night but it’s better than nothing.</p>

<p>Just before the day of leaving for Beijing, there was a snowstorm and most highways were closed as a result. We booked the train from a nearby city because the time of the train is better. But since the highway was closed, we changed the departure station to our hometown city. It was a very cold morning and we needed to leave for the railway station at 5:00am. When we were waiting at the station, there was an announcement that said the train was delayed. Following that, there were more announcements and the train was delayed longer and longer. Luckily, while debating if it’s better to go home instead of waiting in the station, the delay got shorter and we were finally able to aboard the train.</p>

<p>Things got better after this rocky start. We took the subway to the airport after arrived at Beijing since we didn’t have the baby’s car seat with us. It’s mostly underground on the way so I had little opportunity to see the city. It’s almost time for dinner when we arrived the hotel in the airport. If not because of the delay of train, we could arrive at noon. I made the plan to meet some friends and have dinner together. I left early from the hotel to walk around the city before I meet them.</p>

<p>I took the subway to Sanyuan Bridge (三元桥). It’s the northeast corner of the Third Ring Road and only one stop away from the airport by the airport express line. I went to a mall first. It’s still early for a weekday so it’s a little bit quite there. I decided to walked to a nearby subway station Liangma Bridge (亮马桥), which is a place surrounded by many embassies. I met my friends there and walked to the nearby restaurant together. Two of my jobs were at that area so I have lots of memory there. Walking along the streets at night, everything feels very familiar but also has a sense of distance. There are lots of restaurants and shops disappeared or changed owners, but the base layout is the same. While taking the subway, walking along the narrow road that has barriers to separate it from the Third Ring Road, going through the underground tunnel, I recognized the familiar feeling: Beijing is like a big machine or beast that doesn’t care about normal human beings. The city is not designed with human scale. Multiple ring road highways cut through the city with giant crossing bridges. But that doesn’t make driving easier because the traffic is still bad and only limited cars can be on the road at weekdays based on the license number. The public transit is wonderful compared to North American cities and most of the people use it. But the subway is usually packed with people during commute hours and stations have maze like paths for exits and connection to another station. It can suck all the remaining energy out after a work day. The pace of life is fast and people are busy. It’s not an enjoyable city to live. But it’s still the capital of China and is the biggest city of the north. There is no shortage of people live there with the hope of a better life. I was one of them and it gave me valuable adventures. I don’t love the city but I love the memory with it.</p>

<h2 id="back-to-toronto">Back to Toronto</h2>

<p>We left early next morning for the flight to Tokyo, then to Montreal, then to Toronto. We had the opportunity to fully explore the airports at Tokyo and Montreal because we left enough time in between of the flights. The longest flight from Tokyo to Montreal is full but fortunately the baby was able to sleep most of the time. We arrived at Toronto at night which means it’s another morning in China and it has been more than 24 hours since we took the first flight from Beijing.</p>

<p>The whole travel went much better than I thought. We not only see the family and friends after 4 years, we also have the experience of traveling a long distance with the baby so it opens so many possibilities in the future. It would be great if I can stay longer with family every year in the future.</p>]]></content><author><name></name></author><category term="life" /><category term="travel" /><category term="China" /><category term="Japan" /><category term="Beijing" /><category term="Tokyo" /><summary type="html"><![CDATA[After more than 4 years staying aboard without being able to go back to China because of Covid, I finally had the chance and spent this Chinese New Year at my hometown. Now I’ve come back to Toronto, it’s time to record it when my memory and feelings are still fresh.]]></summary></entry><entry><title type="html">Scala 2 Macro Tutorial</title><link href="https://www.binwang.me/2023-12-29-Scala-Macro-Tutorial.html" rel="alternate" type="text/html" title="Scala 2 Macro Tutorial" /><published>2023-12-29T00:00:00-05:00</published><updated>2023-12-29T00:00:00-05:00</updated><id>https://www.binwang.me/Scala-Macro-Tutorial</id><content type="html" xml:base="https://www.binwang.me/2023-12-29-Scala-Macro-Tutorial.html"><![CDATA[<p>Macros are powerful but complex. Especially when the language itself like Scala is already complex. The lack of learning resource and documents makes it more so. In this article, I’ll write down some of my learnings and hopefully it can help someone else who is new to it as well. I’ll keep the examples small and simple so it’s easier to understand. Since I’m still learning it, I may continue to update this article on the way, or write a new article if there is a big topic. Either way, I’ll make notes here so you know there are updates.</p>

<p>Scala’s macro syntax and APIs can be different from version to version. Especially it’s almost completely redesigned in Scala 3. This article only targets Scala 2 and I’ve only tested the examples on Scala 2.13.</p>

<h2 id="1-what-is-macro">1. What is Macro</h2>

<p>The basic idea of macro is to modify the code with code. For example, let’s imagine a macro <code class="language-plaintext highlighter-rouge">plusToMinus</code> that modifies all the plus operations of integers to minus:</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plusToMinus</span> <span class="o">{</span> <span class="mi">1</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">}</span>
</code></pre></div></div>

<p>This will be compiled to <code class="language-plaintext highlighter-rouge">1 - 1</code> and ends up as <code class="language-plaintext highlighter-rouge">0</code>.</p>

<p>Of cause this is not a practical example and not all the languages’ macro system can do it. But this demonstrate what macros can do where normal code cannot. Here is a more practical example: when we log something in different log levels, the API usually looks like this:</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">v</span> <span class="k">=</span> <span class="o">...</span>
<span class="nv">logger</span><span class="o">.</span><span class="py">info</span><span class="o">(</span><span class="n">s</span><span class="s">"This is a info log. Value: $v"</span><span class="o">)</span>
<span class="nv">logger</span><span class="o">.</span><span class="py">warn</span><span class="o">(</span><span class="n">s</span><span class="s">"This is a warning. Value: $v"</span><span class="o">)</span>
</code></pre></div></div>

<p>However, with this kind of interface, the string <code class="language-plaintext highlighter-rouge">s"..."</code> need to be computed before passed in to the method, which is a waste since not all the strings need to be logged based on the log level configuration. Especially when <code class="language-plaintext highlighter-rouge">v.toString</code> needs a lot of resource to compute. So in language like Java, the values are usually passed in as separate parameters:</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nc">String</span> <span class="n">v</span> <span class="o">=</span> <span class="o">...</span>
<span class="n">logger</span><span class="o">.</span><span class="na">info</span><span class="o">(</span><span class="s">"This is a info log. Value: {}"</span><span class="o">,</span> <span class="n">v</span><span class="o">);</span>
<span class="n">logger</span><span class="o">.</span><span class="na">warn</span><span class="o">(</span><span class="s">"This is a warning. Value: {}"</span><span class="o">,</span> <span class="n">v</span><span class="o">);</span>
</code></pre></div></div>

<p>Even though it resolves the problem, the interface is kind of awful. And not all the users know this kind of details so they may still just construct the string directly instead of pass in separate parameters. However, with the help of macros, you can still keep the logger interface in the intuitive way. As macros, <code class="language-plaintext highlighter-rouge">logger.info</code> and <code class="language-plaintext highlighter-rouge">logger.warn</code> can modify the code directly during the compile time. For example, it can modify the code like this:</p>

<p>From</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">logger</span><span class="o">.</span><span class="py">info</span><span class="o">(</span><span class="n">s</span><span class="s">"This is a info log. Value: $v"</span><span class="o">)</span>
</code></pre></div></div>

<p>To</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">if</span> <span class="o">(</span><span class="n">loggerLevel</span> <span class="o">&gt;=</span> <span class="nc">INFO</span><span class="o">)</span> <span class="o">{</span>
  <span class="nf">println</span><span class="o">(</span><span class="n">s</span><span class="s">"This is a info log. Value: $v"</span><span class="o">)</span>
<span class="o">}</span>
</code></pre></div></div>

<p>So that the actually string computation is not done unless log level is configured to print it.</p>

<h2 id="2-how-to-write-a-macro">2. How to Write a Macro</h2>

<p>Different languages have different syntaxes to write a macro. On the simpler side, macros in C can only do text substitution. On the powerful side, Lisp languages can modify the AST (abstract syntax tree) very easily because the code itself is written as a tree structure. The macro in Scala is on the powerful side since it is able to modify the AST even though it may not be as intuitive as Lisp. There are multiple ways to do it. But essentially, the process it to take the current AST as input and output a new AST. The APIs of reading AST input is very similar to reflection APIs (and in fact, sometimes they share some APIs). Generating a new AST part is more complex. In the following sections, we will walk through how to setup a SBT project to write macros, how to read an AST and how to generate a new AST.</p>

<h2 id="3-project-setup-with-sbt">3. Project Setup with SBT</h2>

<p>In Scala, the implementation of macros and the use of macros need to be compiled separately. So if you are using SBT, they need to be in different sub projects. Here is an example of <code class="language-plaintext highlighter-rouge">build.sbt</code>:</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">lazy</span> <span class="k">val</span> <span class="nv">root</span> <span class="k">=</span> <span class="o">(</span><span class="n">project</span> <span class="n">in</span> <span class="nf">file</span><span class="o">(</span><span class="s">"."</span><span class="o">))</span>
  <span class="o">.</span><span class="py">aggregate</span><span class="o">(</span><span class="n">core</span><span class="o">,</span> <span class="n">coretest</span>
  <span class="o">.</span><span class="py">settings</span><span class="o">(</span>
    <span class="n">name</span> <span class="o">:=</span> <span class="s">"archmage"</span>
  <span class="o">)</span>

<span class="k">lazy</span> <span class="k">val</span> <span class="nv">core</span> <span class="k">=</span> <span class="o">(</span><span class="n">project</span> <span class="n">in</span> <span class="nf">file</span><span class="o">(</span><span class="s">"core"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">settings</span><span class="o">(</span>
    <span class="n">name</span> <span class="o">:=</span> <span class="s">"core"</span><span class="o">,</span>
    <span class="n">libraryDependencies</span> <span class="o">++=</span> <span class="nc">Seq</span><span class="o">(</span>
      <span class="s">"org.scala-lang"</span> <span class="o">%</span> <span class="s">"scala-reflect"</span> <span class="o">%</span> <span class="s">"2.13.12"</span><span class="o">,</span>
      <span class="s">"co.fs2"</span> <span class="o">%%</span> <span class="s">"fs2-core"</span> <span class="o">%</span> <span class="s">"3.9.3"</span><span class="o">,</span>
    <span class="o">)</span>
  <span class="o">)</span>

<span class="k">lazy</span> <span class="k">val</span> <span class="nv">coretest</span> <span class="k">=</span> <span class="o">(</span><span class="n">project</span> <span class="n">in</span> <span class="nf">file</span><span class="o">(</span><span class="s">"coretest"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">settings</span><span class="o">(</span>
    <span class="n">name</span> <span class="o">:=</span> <span class="s">"core-test"</span>
  <span class="o">)</span> <span class="n">dependsOn</span> <span class="n">core</span>
</code></pre></div></div>

<p>It creates two sub projects. You can implement the macros in <code class="language-plaintext highlighter-rouge">core</code> and use them in <code class="language-plaintext highlighter-rouge">coretest</code>.</p>

<p>If you want to debug the generated code from macros, add debug flags to Scala like this in <code class="language-plaintext highlighter-rouge">build.sbt</code>:</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nc">ThisBuild</span> <span class="o">/</span> <span class="n">scalacOptions</span> <span class="o">+=</span> <span class="s">"-Ymacro-debug-lite"</span>
</code></pre></div></div>

<h2 id="4-how-to-read-ast">4. How to Read AST</h2>

<h3 id="41-read-macro-parameters">4.1 Read macro parameters:</h3>

<p>Here is the basic syntax of a macro. First, define a macro implementation:</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">macroImpl</span><span class="o">(</span><span class="n">c</span><span class="k">:</span> <span class="kt">blackbox.Context</span><span class="o">)(</span><span class="n">s</span><span class="k">:</span> <span class="kt">c.Expr</span><span class="o">[</span><span class="kt">String</span><span class="o">])</span> <span class="k">:</span> <span class="kt">c.Expr</span><span class="o">[</span><span class="kt">String</span><span class="o">]</span> <span class="k">=</span> <span class="o">{</span>
  <span class="nf">println</span><span class="o">(</span><span class="nv">s</span><span class="o">.</span><span class="py">tree</span><span class="o">.</span><span class="py">symbol</span><span class="o">.</span><span class="py">fullName</span><span class="o">)</span>
  <span class="n">s</span>
<span class="o">}</span>
</code></pre></div></div>

<p>The first parameter <code class="language-plaintext highlighter-rouge">c: blackbox.Context</code> is a must have for a macro implementation. There is also a <code class="language-plaintext highlighter-rouge">whitebox.Context</code> but we will not cover it in this article. More details about whitebox can be found in <a href="https://docs.scala-lang.org/overviews/macros/blackbox-whitebox.html">the official document</a>.</p>

<p>The remaining parameters of the implementation method are parameters for the macro. For example, if you want to take a parameter of type <code class="language-plaintext highlighter-rouge">String</code> for the macro, then the implementation of macro will take <code class="language-plaintext highlighter-rouge">c.Expr[String]</code> as a parameter, which <code class="language-plaintext highlighter-rouge">c.Expr[String]</code> is the tree representation of the macro’s <code class="language-plaintext highlighter-rouge">String</code> parameter. The same applies to the return type of the macro. You can also  use <code class="language-plaintext highlighter-rouge">c.Tree</code> instead of <code class="language-plaintext highlighter-rouge">c.Expr[T]</code>. They can be converted between each other, which we will see in section 4.4.</p>

<p>This example prints out the variable name of the passed in parameter and return the parameter without modification. Note that the printing happens at compile time since that’s when the implementation of the macro is ran. Only the returned tree or <code class="language-plaintext highlighter-rouge">c.Expr</code> is used at run time. So this macro is not doing anything useful, it’s just a demo of how to read the input tree.</p>

<p>Once we have the macro implementation, we can define the macro like this:</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">macroTest</span><span class="o">(</span><span class="n">arg</span><span class="k">:</span> <span class="kt">String</span><span class="o">)</span><span class="k">:</span> <span class="kt">String</span> <span class="o">=</span> <span class="n">macro</span> <span class="n">macroImpl</span>
</code></pre></div></div>

<p>Then we can use it in another (sub) project so that the compilation is separated:</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">a</span> <span class="k">=</span> <span class="s">"abc"</span>
<span class="nf">macroTest</span><span class="o">(</span><span class="n">a</span><span class="o">)</span>
</code></pre></div></div>

<p>It will print out the full name of <code class="language-plaintext highlighter-rouge">a</code> like this during compilation:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>me.binwang.archmage.coretest.MethodMetaTest.a
</code></pre></div></div>

<p>The API of <code class="language-plaintext highlighter-rouge">c.Expr</code> is very similar as reflection API. You can experiment with it by print out different things from it and see what you can get.</p>

<h3 id="42-read-type-parameters">4.2 Read type parameters:</h3>

<p>Macro can also take generic type as parameters. The example below takes a parameter of any type and print out its type at compile time.</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">macroImpl</span><span class="o">[</span><span class="kt">T:</span> <span class="kt">c.WeakTypeTag</span><span class="o">](</span><span class="n">c</span><span class="k">:</span> <span class="kt">blackbox.Context</span><span class="o">)(</span><span class="n">s</span><span class="k">:</span> <span class="kt">c.Expr</span><span class="o">[</span><span class="kt">T</span><span class="o">])</span> <span class="k">:</span> <span class="kt">c.Expr</span><span class="o">[</span><span class="kt">T</span><span class="o">]</span> <span class="k">=</span> <span class="o">{</span>
  <span class="nf">println</span><span class="o">(</span><span class="nv">c</span><span class="o">.</span><span class="py">weakTypeOf</span><span class="o">[</span><span class="kt">T</span><span class="o">])</span>
  <span class="n">s</span>
<span class="o">}</span>

<span class="k">def</span> <span class="nf">macroTest</span><span class="o">[</span><span class="kt">T</span><span class="o">](</span><span class="n">s</span><span class="k">:</span> <span class="kt">T</span><span class="o">)</span><span class="k">:</span> <span class="kt">T</span> <span class="o">=</span> <span class="n">macro</span> <span class="n">macroImpl</span><span class="o">[</span><span class="kt">T</span><span class="o">]</span>
</code></pre></div></div>

<p>Which can be used like this:</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">macroTest</span><span class="o">(</span><span class="s">"abc"</span><span class="o">)</span>
<span class="nf">macroTest</span><span class="o">(</span><span class="mi">1</span><span class="o">)</span>
</code></pre></div></div>

<p>The output during compilation will be:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>String
Int
</code></pre></div></div>

<h3 id="43-read-implicit-parameters">4.3 Read implicit parameters:</h3>

<p>Macro can have implicit parameters, but the macro implementation shouldn’t define them as implicit. Otherwise Scala compiler will give confusing errors. See <a href="https://github.com/scala/bug/issues/6494">this issue</a> for more details.</p>

<p>In the following example, <code class="language-plaintext highlighter-rouge">macroTest</code> takes an implicit double variable and return it as the new generated tree:</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">macroImpl</span><span class="o">(</span><span class="n">c</span><span class="k">:</span> <span class="kt">blackbox.Context</span><span class="o">)(</span><span class="n">s</span><span class="k">:</span> <span class="kt">c.Expr</span><span class="o">[</span><span class="kt">String</span><span class="o">])(</span><span class="n">num</span><span class="k">:</span> <span class="kt">c.Expr</span><span class="o">[</span><span class="kt">Double</span><span class="o">])</span> <span class="k">:</span> <span class="kt">c.Expr</span><span class="o">[</span><span class="kt">Double</span><span class="o">]</span> <span class="k">=</span> <span class="o">{</span>
  <span class="nf">println</span><span class="o">(</span><span class="n">s</span><span class="s">"Name of implicit num: ${num.tree.symbol.fullName}"</span><span class="o">)</span>
  <span class="n">num</span>
<span class="o">}</span>

<span class="k">def</span> <span class="nf">macroTest</span><span class="o">(</span><span class="n">s</span><span class="k">:</span> <span class="kt">String</span><span class="o">)(</span><span class="k">implicit</span> <span class="n">num</span><span class="k">:</span> <span class="kt">Double</span><span class="o">)</span><span class="k">:</span> <span class="kt">Double</span> <span class="o">=</span> <span class="n">macro</span> <span class="n">macroImpl</span>
</code></pre></div></div>

<p>Note how <code class="language-plaintext highlighter-rouge">num</code> in <code class="language-plaintext highlighter-rouge">macroImpl</code> doesn’t have any <code class="language-plaintext highlighter-rouge">implicit</code> definition.</p>

<p>Then the test code:</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">implicit</span> <span class="k">val</span> <span class="nv">num</span><span class="k">:</span> <span class="kt">Double</span> <span class="o">=</span> <span class="mf">1.1</span>
<span class="nf">println</span><span class="o">(</span><span class="nf">macroTest</span><span class="o">(</span><span class="s">"abc"</span><span class="o">))</span>
</code></pre></div></div>

<p>It will print this during the compile time:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Name of implicit num: me.binwang.archmage.coretest.MethodMetaTest.num
</code></pre></div></div>

<p>And this during the run time:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>1.1
</code></pre></div></div>

<h3 id="44-read-code-block-with-by-name-parameter">4.4 Read code block with by-name parameter</h3>

<p>Macros can also take <a href="https://docs.scala-lang.org/tour/by-name-parameters.html">by-name parameter</a>. However, it needs to use <code class="language-plaintext highlighter-rouge">c.Tree</code> instead of <code class="language-plaintext highlighter-rouge">c.Expr</code> as parameter in the macro implementation:</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">macroImpl</span><span class="o">(</span><span class="n">c</span><span class="k">:</span> <span class="kt">blackbox.Context</span><span class="o">)(</span><span class="n">s</span><span class="k">:</span> <span class="kt">c.Tree</span><span class="o">)</span> <span class="k">:</span> <span class="kt">c.Expr</span><span class="o">[</span><span class="kt">String</span><span class="o">]</span> <span class="k">=</span> <span class="o">{</span>
  <span class="nf">println</span><span class="o">(</span><span class="n">s</span><span class="o">)</span>
  <span class="nv">c</span><span class="o">.</span><span class="py">Expr</span><span class="o">[</span><span class="kt">String</span><span class="o">](</span><span class="n">s</span><span class="o">)</span>
<span class="o">}</span>

<span class="k">def</span> <span class="nf">macroTest</span><span class="o">(</span><span class="n">s</span><span class="k">:</span> <span class="o">=&gt;</span> <span class="nc">String</span><span class="o">)</span><span class="k">:</span> <span class="kt">String</span> <span class="o">=</span> <span class="n">macro</span> <span class="n">macroImpl</span>
</code></pre></div></div>

<p>See how <code class="language-plaintext highlighter-rouge">c.Tree</code> is converted to <code class="language-plaintext highlighter-rouge">c.Expr</code>. You can also convert <code class="language-plaintext highlighter-rouge">c.Expr</code> to <code class="language-plaintext highlighter-rouge">c.Tree</code> by using the <code class="language-plaintext highlighter-rouge">.tree</code> method, which we’ve seen in the examples above.</p>

<p>Test it with this code:</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">macroTest</span> <span class="o">{</span>
  <span class="k">val</span> <span class="nv">a</span> <span class="k">=</span> <span class="s">"a"</span>
  <span class="k">val</span> <span class="nv">b</span> <span class="k">=</span> <span class="s">"b"</span>
  <span class="nf">println</span><span class="o">(</span><span class="s">"hello!"</span><span class="o">)</span>
  <span class="n">a</span> <span class="o">+</span> <span class="n">b</span>
<span class="o">}</span>
</code></pre></div></div>

<p>It will print out this during compile time:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{
  val a: String = "a";
  val b: String = "b";
  scala.Predef.println("hello!");
  a.+(b)
}
</code></pre></div></div>

<h3 id="45-use-quasiquotes">4.5 Use Quasiquotes</h3>

<p><a href="https://docs.scala-lang.org/overviews/quasiquotes/intro.html">Quasiquotes</a>, or <code class="language-plaintext highlighter-rouge">q"..."</code>, is a very powerful syntax for Scala macro. It can both match a tree and generate a tree. For example, the following code can match different parts of a if else clause to <code class="language-plaintext highlighter-rouge">c.Tree</code> variables:</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">macroImpl</span><span class="o">(</span><span class="n">c</span><span class="k">:</span> <span class="kt">blackbox.Context</span><span class="o">)(</span><span class="n">s</span><span class="k">:</span> <span class="kt">c.Tree</span><span class="o">)</span><span class="k">:</span> <span class="kt">c.Tree</span> <span class="o">=</span> <span class="o">{</span>
  <span class="k">import</span> <span class="nn">c.universe._</span>
  <span class="k">val</span> <span class="nv">q</span><span class="s">"if ($cond) $thenp else $elsep"</span> <span class="k">=</span> <span class="n">s</span>
  <span class="nf">println</span><span class="o">(</span><span class="n">cond</span><span class="o">)</span>
  <span class="nf">println</span><span class="o">(</span><span class="n">thenp</span><span class="o">)</span>
  <span class="nf">println</span><span class="o">(</span><span class="n">elsep</span><span class="o">)</span>
  <span class="n">q</span><span class="s">"$cond"</span>
<span class="o">}</span>

<span class="k">def</span> <span class="nf">macroTest</span><span class="o">(</span><span class="n">s</span><span class="k">:</span> <span class="o">=&gt;</span> <span class="nc">Any</span><span class="o">)</span><span class="k">:</span> <span class="kt">Any</span> <span class="o">=</span> <span class="n">macro</span> <span class="n">macroImpl</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">cond</code>, <code class="language-plaintext highlighter-rouge">thenp</code> and <code class="language-plaintext highlighter-rouge">elsep</code> are all matched parts from the input tree.</p>

<p><code class="language-plaintext highlighter-rouge">q"$cond"</code> generates a new tree using the matched condition part of the tree. We will see more details in how to use quasiquotes to generate trees in section 5.4.</p>

<p>Test it with this code:</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">bigNum</span> <span class="k">=</span> <span class="mi">2</span>
<span class="k">val</span> <span class="nv">smallNum</span> <span class="k">=</span> <span class="mi">1</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="n">macroTest</span> <span class="o">{</span>
  <span class="nf">if</span> <span class="o">(</span><span class="n">bigNum</span> <span class="o">&gt;</span> <span class="n">smallNum</span><span class="o">)</span> <span class="o">{</span>
    <span class="s">"no surprise"</span>
  <span class="o">}</span> <span class="k">else</span> <span class="o">{</span>
    <span class="s">"surprise!"</span>
  <span class="o">}</span>
<span class="o">}</span>
<span class="nf">println</span><span class="o">(</span><span class="n">result</span><span class="o">)</span>
</code></pre></div></div>

<p>During the compile time, it will print out the different parts of the tree that we have asked it to match:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>bigNum.&gt;(smallNum)
"no surprise"
"surprise!"
</code></pre></div></div>

<p>And during the run time, it will print out the value of condition instead of either if or else clause:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>true
</code></pre></div></div>

<p>More examples about how to match the tree can be found in <a href="https://docs.scala-lang.org/overviews/quasiquotes/syntax-summary.html">the document</a>. Click on each example to see more details.</p>

<h2 id="5-how-to-generate-tree">5. How to Generate Tree</h2>

<h3 id="51-construct-tree-directly-with-api">5.1 Construct Tree Directly with API</h3>

<p>An AST can be constructed from the classes that represent the tree. For example, a constant of string can be created by <code class="language-plaintext highlighter-rouge">Literal(Constant("I replaced you!"))</code>. The following example replace any string to <code class="language-plaintext highlighter-rouge">I replaced you</code>:</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">macroImpl</span><span class="o">(</span><span class="n">c</span><span class="k">:</span> <span class="kt">blackbox.Context</span><span class="o">)(</span><span class="n">s</span><span class="k">:</span> <span class="kt">c.Expr</span><span class="o">[</span><span class="kt">String</span><span class="o">])</span> <span class="k">:</span> <span class="kt">c.Expr</span><span class="o">[</span><span class="kt">String</span><span class="o">]</span> <span class="k">=</span> <span class="o">{</span>
  <span class="k">import</span> <span class="nn">c.universe._</span>
  <span class="nv">c</span><span class="o">.</span><span class="py">Expr</span><span class="o">[</span><span class="kt">String</span><span class="o">](</span><span class="nc">Literal</span><span class="o">(</span><span class="nc">Constant</span><span class="o">(</span><span class="s">"I replaced you!"</span><span class="o">)))</span>
<span class="o">}</span>

<span class="k">def</span> <span class="nf">macroTest</span><span class="o">(</span><span class="n">s</span><span class="k">:</span> <span class="kt">String</span><span class="o">)</span><span class="k">:</span> <span class="kt">String</span> <span class="o">=</span> <span class="n">macro</span> <span class="n">macroImpl</span>
</code></pre></div></div>

<p>With the code below, it will print <code class="language-plaintext highlighter-rouge">I replaced you!</code> instead of <code class="language-plaintext highlighter-rouge">abc</code>:</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">println</span><span class="o">(</span><span class="nf">macroTest</span><span class="o">(</span><span class="s">"abc"</span><span class="o">))</span>
</code></pre></div></div>

<p>This is a very simple example. When the tree becomes larger and larger , it’s more and more difficult to construct a tree with this approach. It’s like a much worse version of lisp. So in the following sections, we will see some easier ways to construct a tree.</p>

<h3 id="52-use-cparse">5.2 Use <code class="language-plaintext highlighter-rouge">c.parse</code>:</h3>

<p><code class="language-plaintext highlighter-rouge">c.parse</code> can parse a string as Scala code and generate an AST. For example, the following macro returns the variable name of a <code class="language-plaintext highlighter-rouge">String</code>:</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">macroImpl</span><span class="o">(</span><span class="n">c</span><span class="k">:</span> <span class="kt">blackbox.Context</span><span class="o">)(</span><span class="n">s</span><span class="k">:</span> <span class="kt">c.Expr</span><span class="o">[</span><span class="kt">String</span><span class="o">])</span><span class="k">:</span> <span class="kt">c.Expr</span><span class="o">[</span><span class="kt">String</span><span class="o">]</span> <span class="k">=</span> <span class="o">{</span>
  <span class="k">val</span> <span class="nv">name</span> <span class="k">=</span> <span class="nv">s</span><span class="o">.</span><span class="py">tree</span><span class="o">.</span><span class="py">symbol</span><span class="o">.</span><span class="py">fullName</span>
  <span class="nv">c</span><span class="o">.</span><span class="py">Expr</span><span class="o">(</span><span class="nv">c</span><span class="o">.</span><span class="py">parse</span><span class="o">(</span><span class="n">s</span><span class="s">""" "Name of var is: $name" """</span><span class="o">))</span>
<span class="o">}</span>

<span class="k">def</span> <span class="nf">macroTest</span><span class="o">(</span><span class="n">s</span><span class="k">:</span> <span class="kt">String</span><span class="o">)</span><span class="k">:</span> <span class="kt">String</span> <span class="o">=</span> <span class="n">macro</span> <span class="n">macroImpl</span>
</code></pre></div></div>

<p>Then use it like this:</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">a</span> <span class="k">=</span> <span class="s">"abc"</span>
<span class="nf">println</span><span class="o">(</span><span class="nf">macroTest</span><span class="o">(</span><span class="n">a</span><span class="o">))</span>
</code></pre></div></div>

<p>It will print out:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Name of var is: me.binwang.archmage.coretest.MethodMetaTest.a
</code></pre></div></div>

<p>Note the output is at run time instead of compile time like the examples in the last section, because we’ve replaced the tree with new code.</p>

<h3 id="53-use-reify">5.3 Use <code class="language-plaintext highlighter-rouge">reify</code></h3>

<p><code class="language-plaintext highlighter-rouge">c.parse</code> is easy to use and understand. But when generating more and more code with it, it can be pretty messy since it is just a string. There is no syntax checks in IDE. Even worse, you cannot get any run time information to use in the generated tree.</p>

<p><code class="language-plaintext highlighter-rouge">reify</code> is a much better option. You can write code as usual. The code in <code class="language-plaintext highlighter-rouge">reify</code> block is the code that will be generated. You can refer to another <code class="language-plaintext highlighter-rouge">Expr</code> (in the old tree) by using its <code class="language-plaintext highlighter-rouge">.splice</code> method. Here is an example to print out both the variable name and it’s value:</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">macroImpl</span><span class="o">(</span><span class="n">c</span><span class="k">:</span> <span class="kt">blackbox.Context</span><span class="o">)(</span><span class="n">s</span><span class="k">:</span> <span class="kt">c.Expr</span><span class="o">[</span><span class="kt">String</span><span class="o">])</span><span class="k">:</span> <span class="kt">c.Expr</span><span class="o">[</span><span class="kt">String</span><span class="o">]</span> <span class="k">=</span> <span class="o">{</span>
  <span class="k">import</span> <span class="nn">c.universe._</span>
  <span class="k">val</span> <span class="nv">name</span> <span class="k">=</span> <span class="nv">c</span><span class="o">.</span><span class="py">Expr</span><span class="o">(</span><span class="nv">c</span><span class="o">.</span><span class="py">parse</span><span class="o">(</span><span class="s">"\""</span> <span class="o">+</span> <span class="nv">s</span><span class="o">.</span><span class="py">tree</span><span class="o">.</span><span class="py">symbol</span><span class="o">.</span><span class="py">fullName</span> <span class="o">+</span> <span class="s">"\""</span><span class="o">))</span>
  <span class="n">reify</span> <span class="o">{</span>
    <span class="n">s</span><span class="s">"${name.splice}: ${s.splice}"</span>
  <span class="o">}</span>
<span class="o">}</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">macroTest</code> and the test code is the same above. Running the test code will get output like this:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>me.binwang.archmage.coretest.MethodMetaTest.a: abc
</code></pre></div></div>

<h3 id="54-use-quasiquotes">5.4 Use Quasiquotes</h3>

<p>As we’ve seen in section 4.5, <code class="language-plaintext highlighter-rouge">q"..."</code> can be used to match a tree. It can be used to generate a tree as well. For example, in the following code:</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">macroImpl</span><span class="o">(</span><span class="n">c</span><span class="k">:</span> <span class="kt">blackbox.Context</span><span class="o">)(</span><span class="n">s</span><span class="k">:</span> <span class="kt">c.Tree</span><span class="o">)</span> <span class="k">=</span> <span class="o">{</span>
  <span class="k">import</span> <span class="nn">c.universe._</span>
  <span class="k">val</span> <span class="nv">q</span><span class="s">"if ($cond) $thenp else $elsep"</span> <span class="k">=</span> <span class="n">s</span>
  <span class="n">q</span><span class="s">"if ($cond) $elsep else $thenp"</span>
<span class="o">}</span>

<span class="k">def</span> <span class="nf">macroTest</span><span class="o">[</span><span class="kt">T</span><span class="o">](</span><span class="n">s</span><span class="k">:</span> <span class="kt">T</span><span class="o">)</span><span class="k">:</span> <span class="kt">T</span> <span class="o">=</span> <span class="n">macro</span> <span class="n">macroImpl</span>
</code></pre></div></div>

<p>It uses the parts that have been matched by <code class="language-plaintext highlighter-rouge">q"..."</code> and generates a new tree using those parts. It swaps the if and else clause. Run it with this test code:</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">macroTest</span><span class="o">(</span><span class="nf">if</span> <span class="o">(</span><span class="kc">true</span><span class="o">)</span> <span class="nf">println</span><span class="o">(</span><span class="s">"a"</span><span class="o">)</span> <span class="k">else</span> <span class="nf">println</span><span class="o">(</span><span class="s">"b"</span><span class="o">))</span>
</code></pre></div></div>

<p>It will print <code class="language-plaintext highlighter-rouge">b</code> instead of <code class="language-plaintext highlighter-rouge">a</code>.</p>

<h3 id="55-avoid-name-conflict">5.5 Avoid Name Conflict</h3>

<p>When generating a new tree, we may generate some variables that have conflict names with the existing ones. Use <code class="language-plaintext highlighter-rouge">c.freshName</code> to get a unique name to avoid the conflict.</p>

<h3 id="56-type-checked-and-unchecked-tree">5.6 Type Checked and Unchecked Tree</h3>

<p>There are two kinds of AST in Scala’s internal compiler: type checked and unchecked. See more details in <a href="https://stackoverflow.com/questions/20936509/scala-macros-what-is-the-difference-between-typed-aka-typechecked-and-untyped">this Stack Overflow answer</a>. Some APIs can only accept either type checked or unchecked tree. And sometimes the compiler throws out weird errors if using the wrong type of tree. If that’s the case, try to use <code class="language-plaintext highlighter-rouge">c.untypecheck</code> and <code class="language-plaintext highlighter-rouge">c.typecheck</code> to covert trees.</p>

<p>For example, here is some code that cannot be compiled:</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">macroImpl</span><span class="o">(</span><span class="n">c</span><span class="k">:</span> <span class="kt">blackbox.Context</span><span class="o">)(</span><span class="n">blockTree</span><span class="k">:</span> <span class="kt">c.Tree</span><span class="o">)</span> <span class="k">:</span> <span class="kt">c.Expr</span><span class="o">[</span><span class="kt">Seq</span><span class="o">[</span><span class="kt">String</span><span class="o">]]</span> <span class="k">=</span> <span class="o">{</span>
  <span class="k">import</span> <span class="nn">c.universe._</span>
  <span class="k">val</span> <span class="nv">block</span> <span class="k">=</span> <span class="nv">c</span><span class="o">.</span><span class="py">Expr</span><span class="o">[</span><span class="kt">Seq</span><span class="o">[</span><span class="kt">String</span><span class="o">]](</span><span class="n">blockTree</span><span class="o">)</span>
  <span class="n">reify</span> <span class="o">{</span>
    <span class="nc">Seq</span><span class="o">(</span><span class="s">"a"</span><span class="o">).</span><span class="py">flatMap</span><span class="o">{</span><span class="k">_</span> <span class="k">=&gt;</span> <span class="nv">block</span><span class="o">.</span><span class="py">splice</span><span class="o">}</span>
  <span class="o">}</span>
<span class="o">}</span>

<span class="k">def</span> <span class="nf">macroTest</span><span class="o">(</span><span class="n">blockTree</span><span class="k">:</span> <span class="o">=&gt;</span> <span class="nc">Seq</span><span class="o">[</span><span class="kt">String</span><span class="o">])</span><span class="k">:</span> <span class="kt">Seq</span><span class="o">[</span><span class="kt">String</span><span class="o">]</span> <span class="k">=</span> <span class="n">macro</span> <span class="n">macroImpl</span>

<span class="c1">// Testing code in another sub project:</span>
<span class="k">val</span> <span class="nv">s</span> <span class="k">=</span> <span class="s">"abc"</span>
<span class="n">macroTest</span> <span class="o">{</span>
  <span class="k">val</span> <span class="nv">a</span> <span class="k">=</span> <span class="n">s</span>
  <span class="nc">Seq</span><span class="o">(</span><span class="n">a</span><span class="o">)</span>
<span class="o">}</span>
</code></pre></div></div>

<p>The compiler will throw error:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[error] Error while emitting XXX.scala
[error] value a
[error] one error found
</code></pre></div></div>

<p>To fix this, we need to convert <code class="language-plaintext highlighter-rouge">blockTree</code> to unchecked tree:</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">macroImpl</span><span class="o">(</span><span class="n">c</span><span class="k">:</span> <span class="kt">blackbox.Context</span><span class="o">)(</span><span class="n">blockTree</span><span class="k">:</span> <span class="kt">c.Tree</span><span class="o">)</span> <span class="k">:</span> <span class="kt">c.Expr</span><span class="o">[</span><span class="kt">Seq</span><span class="o">[</span><span class="kt">String</span><span class="o">]]</span> <span class="k">=</span> <span class="o">{</span>
  <span class="k">import</span> <span class="nn">c.universe._</span>
  <span class="k">val</span> <span class="nv">cleanedBlock</span> <span class="k">=</span> <span class="nv">c</span><span class="o">.</span><span class="py">untypecheck</span><span class="o">(</span><span class="nv">blockTree</span><span class="o">.</span><span class="py">duplicate</span><span class="o">)</span>
  <span class="k">val</span> <span class="nv">block</span> <span class="k">=</span> <span class="nv">c</span><span class="o">.</span><span class="py">Expr</span><span class="o">[</span><span class="kt">Seq</span><span class="o">[</span><span class="kt">String</span><span class="o">]](</span><span class="n">cleanedBlock</span><span class="o">)</span>
  <span class="n">reify</span> <span class="o">{</span>
    <span class="nc">Seq</span><span class="o">(</span><span class="s">"a"</span><span class="o">).</span><span class="py">flatMap</span><span class="o">{</span><span class="k">_</span> <span class="k">=&gt;</span> <span class="nv">block</span><span class="o">.</span><span class="py">splice</span><span class="o">}</span>
  <span class="o">}</span>
<span class="o">}</span>
</code></pre></div></div>]]></content><author><name></name></author><category term="Scala" /><category term="macro" /><category term="meta programming" /><category term="AOP" /><summary type="html"><![CDATA[Macros are powerful but complex. Especially when the language itself like Scala is already complex. The lack of learning resource and documents makes it more so. In this article, I’ll write down some of my learnings and hopefully it can help someone else who is new to it as well. I’ll keep the examples small and simple so it’s easier to understand. Since I’m still learning it, I may continue to update this article on the way, or write a new article if there is a big topic. Either way, I’ll make notes here so you know there are updates.]]></summary></entry><entry><title type="html">ZFS Profiling on Arch Linux</title><link href="https://www.binwang.me/2023-12-14-ZFS-Profiling-on-Arch-Linux.html" rel="alternate" type="text/html" title="ZFS Profiling on Arch Linux" /><published>2023-12-14T00:00:00-05:00</published><updated>2023-12-14T00:00:00-05:00</updated><id>https://www.binwang.me/ZFS-Profiling-on-Arch-Linux</id><content type="html" xml:base="https://www.binwang.me/2023-12-14-ZFS-Profiling-on-Arch-Linux.html"><![CDATA[<p>I bought a new video game recently but found <code class="language-plaintext highlighter-rouge">z_rd_int</code> processes took almost all the CPU time when I was playing it. That doesn’t make much sense to me since I install games on a non compressed ZFS dataset. Even though I don’t have a powerful CPU, I don’t expect ZFS to use all of them and only reads about 60-70MiB/s from each of the NVME SSDs. To double check, I used <code class="language-plaintext highlighter-rouge">iostat -x 1</code> to confirm the iowait is very low. So disk IO is not the bottleneck.</p>

<p>Without finding any root cause from Internet, I decide to do some profiling by myself. From OpenZFS’ Github issues, people are using <a href="https://perf.wiki.kernel.org/index.php/Main_Page">perf</a> to do profiling. It is trivial enough to do it from a glance. But let <code class="language-plaintext highlighter-rouge">perf</code> showing debug symbols for ZFS spent me a lot of time. So in this article, I will document the steps to enable debug symbols for ZFS and hopefully it can help more people that facing difficulties to do it. After that, I will continue with how do I find the root cause and the solution. If you’ve seen my previous blog <a href="/2023-09-30-A-Boring-JVM-Memory-Profiling-Story.html">A Boring JVM Memory Profiling Story</a>, this is an even more boring profiling story. But the tool set is important. Use them efficiently and hopefully all the profiling stories become boring.</p>

<h2 id="1-enable-debug-info-for-zfs">1. Enable Debug Info for ZFS</h2>

<p>On Arch Linux, if you run <code class="language-plaintext highlighter-rouge">perf top</code>, you can see kernel has debug symbols attached like this:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>2.95%  [kernel]                                        [k] entry_SYSCALL_64
</code></pre></div></div>

<p>But for some other processes like zfs ones, it only has an address like this:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>2.65%  [zfs]                                           [k] 0x00000000002990cf
</code></pre></div></div>

<p>This is because perf cannot find debug info for zfs module. Let’s enable it now.</p>

<h3 id="11-use-dkms-package">1.1 Use DKMS Package</h3>

<p>First we need to use <a href="https://wiki.archlinux.org/title/Dynamic_Kernel_Module_Support">DKMS</a> package instead a pre compiled one so that we can control the compiling behaviour when build the zfs kernel module. In Arch Linux, the package name is <code class="language-plaintext highlighter-rouge">zfs-dkms</code> either in AUR or <a href="https://github.com/archzfs/archzfs">archzfs</a> repo. Be aware packages are different from those different repos even they have the same name. Personally I like archzfs repo more since it’s more well maintained and has better dependency management.</p>

<h3 id="12-enable-debuginfo-flags">1.2 Enable debuginfo Flags</h3>

<h4 id="tldr">TL;DR:</h4>

<p>Add these three lines to <code class="language-plaintext highlighter-rouge">/etc/sysconfig/zfs</code>, (re)install the zfs dkms package and reboot.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">ZFS_DKMS_ENABLE_DEBUG</span><span class="o">=</span>y
<span class="nv">ZFS_DKMS_ENABLE_DEBUGINFO</span><span class="o">=</span>y
<span class="nv">ZFS_DKMS_DISABLE_STRIP</span><span class="o">=</span>y
</code></pre></div></div>

<p>Decompress the installed ko file.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo </span>unzstd /lib/modules/&lt;your kernel version&gt;/updates/dkms/zfs.ko.zst
</code></pre></div></div>

<p>Now you should be able to see zfs symbols in <code class="language-plaintext highlighter-rouge">perf top</code>.</p>

<p>Remember to cleanup the files after profiling.</p>

<p>If you care about the reason behind these changes, continue reading. Otherwise you can skip the remaining of this section.</p>

<h4 id="what-is-etcsysconfigzfs">What is <code class="language-plaintext highlighter-rouge">/etc/sysconfig/zfs</code>?</h4>

<p>The package <code class="language-plaintext highlighter-rouge">zfs-dkms</code> only installs the code that will be compiled by dkms to <code class="language-plaintext highlighter-rouge">/usr/src/zfs-&lt;zfs-version&gt;</code>. (I learned this by reading <code class="language-plaintext highlighter-rouge">PKGBUILD</code> of the aur package). Then when <code class="language-plaintext highlighter-rouge">dkms</code> commands are run, <code class="language-plaintext highlighter-rouge">dkms</code> copies the files to <code class="language-plaintext highlighter-rouge">/var/lib/dkms/zfs/&lt;zfs-version&gt;/build</code> to build it and then install the built ko files to <code class="language-plaintext highlighter-rouge">/lib/modules/&lt;your kernel version&gt;/updates/dkms</code>. So in order to build zfs module with debug symbols, we need to let dkms uses correct compile flags.</p>

<p>Under <code class="language-plaintext highlighter-rouge">/usr/src/zfs-&lt;zfs-version&gt;</code>, there is <code class="language-plaintext highlighter-rouge">dkms.conf</code> that tells DKMS how to use the source code to build and install modules. We can find some key information there:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">PRE_BUILD</span><span class="o">=</span><span class="s2">"configure
  --prefix=/usr
  --with-config=kernel
  --with-linux=</span><span class="se">\$</span><span class="s2">(
    if [ -e "</span><span class="se">\$</span><span class="o">{</span>kernel_source_dir/%build/source<span class="o">}</span><span class="s2">" ]
    then
      echo "</span><span class="se">\$</span><span class="o">{</span>kernel_source_dir/%build/source<span class="o">}</span><span class="s2">"
    else
      echo "</span><span class="se">\$</span><span class="o">{</span>kernel_source_dir<span class="o">}</span><span class="s2">"
    fi
  )
  --with-linux-obj="</span><span class="se">\$</span><span class="o">{</span>kernel_source_dir<span class="o">}</span><span class="s2">"
  </span><span class="se">\$</span><span class="s2">(
    [[ -n </span><span class="se">\"\$</span><span class="s2">{ICP_ROOT}</span><span class="se">\"</span><span class="s2"> ]] &amp;&amp; </span><span class="se">\\</span><span class="s2">
    {
      echo --with-qat=</span><span class="se">\"\$</span><span class="s2">{ICP_ROOT}</span><span class="se">\"</span><span class="s2">
    }
  )
  </span><span class="se">\$</span><span class="s2">(
    [[ -r </span><span class="se">\$</span><span class="s2">{PACKAGE_CONFIG} ]] </span><span class="se">\\</span><span class="s2">
    &amp;&amp; source </span><span class="se">\$</span><span class="s2">{PACKAGE_CONFIG} </span><span class="se">\\</span><span class="s2">
    &amp;&amp; shopt -q -s extglob </span><span class="se">\\</span><span class="s2">
    &amp;&amp; </span><span class="se">\\</span><span class="s2">
    {
      if [[ </span><span class="se">\$</span><span class="s2">{ZFS_DKMS_ENABLE_DEBUG,,} == @(y|yes) ]]
      then
        echo --enable-debug
      fi
      if [[ </span><span class="se">\$</span><span class="s2">{ZFS_DKMS_ENABLE_DEBUGINFO,,} == @(y|yes) ]]
      then
        echo --enable-debuginfo
      fi
    }
  )
"</span>
</code></pre></div></div>

<p>There is <code class="language-plaintext highlighter-rouge">--enable-debug</code> and <code class="language-plaintext highlighter-rouge">--enable-debuginfo</code>. Run <code class="language-plaintext highlighter-rouge">./configure --help</code> shows the meaning of these two flags:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  --enable-debug          Enable compiler and code assertions [default=no]
  --enable-debuginfo      Force generation of debuginfo [default=no]
</code></pre></div></div>

<p>So if those two flags are enabled, the zfs module should be built with debug info. The code above checks <code class="language-plaintext highlighter-rouge">ZFS_DKMS_ENABLE_DEBUG</code> and <code class="language-plaintext highlighter-rouge">ZFS_DKMS_ENABLE_DEBUGINFO</code> in file <code class="language-plaintext highlighter-rouge">${PACKAGE_CONFIG}</code>. If they are <code class="language-plaintext highlighter-rouge">y</code> or <code class="language-plaintext highlighter-rouge">yes</code>, the corresponding flags are enabled. At the beginning of <code class="language-plaintext highlighter-rouge">dkms.conf</code> we can find <code class="language-plaintext highlighter-rouge">PACKAGE_CONFIG</code> is defined as <code class="language-plaintext highlighter-rouge">/etc/sysconfig/zfs</code>.</p>

<p>However, only defining <code class="language-plaintext highlighter-rouge">ZFS_DKMS_ENABLE_DEBUG</code> and <code class="language-plaintext highlighter-rouge">ZFS_DKMS_ENABLE_DEBUGINFO</code> is not enough. I learnt it the hard way. Checking <code class="language-plaintext highlighter-rouge">dkms.conf</code> more closely, we can see these code below:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>STRIP[0]<span class="o">=</span><span class="s2">"</span><span class="se">\$</span><span class="s2">(
  [[ -r </span><span class="se">\$</span><span class="s2">{PACKAGE_CONFIG} ]] </span><span class="se">\\</span><span class="s2">
  &amp;&amp; source </span><span class="se">\$</span><span class="s2">{PACKAGE_CONFIG} </span><span class="se">\\</span><span class="s2">
  &amp;&amp; shopt -q -s extglob </span><span class="se">\\</span><span class="s2">
  &amp;&amp; [[ </span><span class="se">\$</span><span class="s2">{ZFS_DKMS_DISABLE_STRIP,,} == @(y|yes) ]] </span><span class="se">\\</span><span class="s2">
  &amp;&amp; echo -n no
)"</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">man dkms</code> shows the meaning of <code class="language-plaintext highlighter-rouge">STRIP</code>:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>STRIP[#]=
       By default strip is considered to be "yes". If set to  "no",  DKMS  will
       not  run strip -g against your built module to remove debug symbols from
       it.  STRIP[0] is used as the default for any unset entries in the  STRIP
       array.
</code></pre></div></div>

<p>If <code class="language-plaintext highlighter-rouge">STRIP</code> is not set to <code class="language-plaintext highlighter-rouge">no</code>, <code class="language-plaintext highlighter-rouge">dkms</code> will stripe the debug info! So we also need to set <code class="language-plaintext highlighter-rouge">ZFS_DKMS_DISABLE_STRIP</code> in <code class="language-plaintext highlighter-rouge">/etc/sysconfig/zfs</code> to <code class="language-plaintext highlighter-rouge">y</code> or <code class="language-plaintext highlighter-rouge">yes</code> so that <code class="language-plaintext highlighter-rouge">STRIP[0]</code> will be <code class="language-plaintext highlighter-rouge">no</code>.</p>

<h4 id="why-unzstd">Why unzstd?</h4>

<p>In my system, the dkms modules are compressed with zstd when installing. But it seems <code class="language-plaintext highlighter-rouge">perf</code> is not able to read the compressed module file in order to find the debug symbols, so we need to uncompress it at the same location.</p>

<h2 id="2-profiling-zfs">2. Profiling ZFS</h2>

<p><code class="language-plaintext highlighter-rouge">perf top</code> can show the CPU usage for each function in real time. But in order to analysis it better, we can record it with <code class="language-plaintext highlighter-rouge">perf record -g -p &lt;pid&gt;</code>. It should generate <code class="language-plaintext highlighter-rouge">perf.data</code> file in the current directory. Press <code class="language-plaintext highlighter-rouge">Ctrl + C</code> to stop the recording and flush the file.</p>

<p>Then use <code class="language-plaintext highlighter-rouge">sudo perf report</code> to show the report of the recording. Mine is like this (press <code class="language-plaintext highlighter-rouge">+</code> to extend a row of interest in <code class="language-plaintext highlighter-rouge">perf report</code>):</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Samples: 277K of event 'cycles:P', Event count (approx.): 244633155596
Children      Self  Command   Shared Object     Symbol
+   96.59%     0.01%  z_rd_int  [zfs]             [k] zio_do_crypt_uio
+   96.58%     0.00%  z_rd_int  [zfs]             [k] crypto_decrypt
+   96.57%     0.01%  z_rd_int  [zfs]             [k] aes_decrypt_atomic
+   75.53%     8.17%  z_rd_int  [zfs]             [k] aes_encrypt_block
+   49.76%     0.00%  z_rd_int  [zfs]             [k] crypto_update_uio
+   49.76%     0.00%  z_rd_int  [zfs]             [k] aes_decrypt_contiguous_blocks
+   49.76%     4.52%  z_rd_int  [zfs]             [k] ccm_mode_decrypt_contiguous_blocks
+   46.42%     2.08%  z_rd_int  [zfs]             [k] ccm_decrypt_final
+   42.15%     6.94%  z_rd_int  [zfs]             [k] aes_aesni_encrypt
-   24.72%    24.36%  z_rd_int  [zfs]             [k] kfpu_end
     24.36% ret_from_fork_asm
        ret_from_fork
        kthread
        0xffffffffc02b15eb
        zio_execute
        zio_done
        zio_pop_transforms
        zio_decrypt
        spa_do_crypt_abd
        zio_do_crypt_data
        zio_do_crypt_uio
        crypto_decrypt
      + aes_decrypt_atomic
-   21.20%    20.96%  z_rd_int  [zfs]             [k] kfpu_begin
     20.96% ret_from_fork_asm
        ret_from_fork
        kthread
        0xffffffffc02b15eb
        zio_execute
        zio_done
        zio_pop_transforms
        zio_decrypt
        spa_do_crypt_abd
        zio_do_crypt_data
        zio_do_crypt_uio
        crypto_decrypt
      + aes_decrypt_atomic
+   14.42%    14.21%  z_rd_int  [zfs]             [k] aes_encrypt_intel
+    7.36%     7.14%  z_rd_int  [zfs]             [k] aes_xor_block
+    6.31%     6.16%  z_rd_int  [zfs]             [k] aes_copy_block
+    1.27%     0.03%  z_rd_int  [zfs]             [k] arc_read_done
+    1.17%     0.02%  z_rd_int  [zfs]             [k] zio_vdev_io_done
+    1.14%     0.00%  z_rd_int  [zfs]             [k] abd_iterate_func
</code></pre></div></div>

<h2 id="3-find-root-cause">3. Find Root Cause</h2>

<p>From the profiling report, we can easily see that the CPU is mostly used on decrypting the content on ZFS. That makes some sense because decryption do need CPU power. But there is no reason it uses so much CPU at that throughput. In fact found some performance issues related encryption and did something to rule out some causes:</p>

<ol>
  <li>I made sure the AES hardware acceleration is enabled for my CPU by checking <code class="language-plaintext highlighter-rouge">lscpu | grep aes</code>.</li>
  <li>My system can decrypt and encrypt at a much higher speed (2000+ MB/s) by running <code class="language-plaintext highlighter-rouge">cryptsetup benchmark</code>.</li>
</ol>

<p>That’s why I need the profiling to confirm where the bottleneck comes from.</p>

<p>Even though the code path is related to decryption, the hotspot is at <code class="language-plaintext highlighter-rouge">kfpu_begin</code> and <code class="language-plaintext highlighter-rouge">kfpu_end</code>. I read the code and have totally no idea what they are doing. I asked ChatGPT and it explains to me that it’s saving and restoring FPU state. I don’t know if its answer is correct or not, but that at least gave me some direction to search issues. At last I found this Github issue <a href="https://github.com/openzfs/zfs/pull/9749">ICP: Improve AES-GCM performance</a>. It says exactly that there is performance issue with saving FPU state when doing encryption. And the PR improves it for AES-GCM algorithm. It states AES-CCM can benifit from similar fix but the performance improvement will not be as great. So in the discussion of the PR, they decide to change the default encryption algorithm to AES-GCM instead of AES-CCM.</p>

<p>I <a href="/2020-01-28-Migrate-Arch-Linux-to-Zfs.html">started use zfs</a> before this PR. So I checked the encryption algorithm on my system by <code class="language-plaintext highlighter-rouge">zfs get all &lt;dataset&gt; | grep encryption</code>. And it is indeed using AES-CCM. In order to confirm it is causing performance issue, I did some benchmark on AES-CCM, AES-GCM and not encrypted datasets.</p>

<p>First, created the datasets:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo </span>zfs create <span class="nt">-o</span> <span class="nv">encryption</span><span class="o">=</span>aes-256-ccm <span class="nt">-o</span> <span class="nv">compression</span><span class="o">=</span>off <span class="nt">-o</span> <span class="nv">atime</span><span class="o">=</span>off zroot/root/ccm-test
<span class="nb">sudo </span>zfs create <span class="nt">-o</span> <span class="nv">encryption</span><span class="o">=</span>aes-256-gcm <span class="nt">-o</span> <span class="nv">compression</span><span class="o">=</span>off <span class="nt">-o</span> <span class="nv">atime</span><span class="o">=</span>off zroot/root/gcm-test
<span class="nb">sudo </span>zfs create <span class="nt">-o</span> <span class="nv">encryption</span><span class="o">=</span>off <span class="nt">-o</span> <span class="nv">compression</span><span class="o">=</span>off <span class="nt">-o</span> <span class="nv">atime</span><span class="o">=</span>off zroot/local_steam_unencrypt
</code></pre></div></div>

<p>Then I write a script to benchmark it:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/bin/bash</span>

<span class="nb">set</span> <span class="nt">-e</span>

<span class="k">function </span>print_cputime<span class="o">()</span> <span class="o">{</span>
	<span class="nv">pname</span><span class="o">=</span><span class="nv">$1</span>
	<span class="k">for </span>pid <span class="k">in</span> <span class="sb">`</span>pgrep <span class="nv">$pname</span><span class="sb">`</span> <span class="p">;</span> <span class="k">do
		</span>ps <span class="nt">-p</span> <span class="nv">$pid</span> <span class="nt">-o</span> cputime,etime
	<span class="k">done</span>
<span class="o">}</span>


<span class="k">function </span>benchmark <span class="o">{</span>
	<span class="nv">test_name</span><span class="o">=</span><span class="nv">$1</span>
	<span class="nv">test_file</span><span class="o">=</span><span class="nv">$2</span>

	<span class="nv">file_size</span><span class="o">=</span><span class="s2">"20480"</span>

	<span class="nb">echo</span> <span class="s2">"### Start benchmark </span><span class="nv">$test_name</span><span class="s2">"</span>

	<span class="nb">echo</span> <span class="s2">"### Print z_wr_iss cpu time before the write test"</span>
	print_cputime z_wr_iss
	<span class="nb">echo</span> <span class="s2">"### Start write test"</span>
	<span class="nb">time dd </span><span class="k">if</span><span class="o">=</span>/dev/random <span class="nv">of</span><span class="o">=</span><span class="nv">$test_file</span> <span class="nv">bs</span><span class="o">=</span>1M <span class="nv">count</span><span class="o">=</span><span class="nv">$file_size</span> <span class="nv">oflag</span><span class="o">=</span>direct
	<span class="nb">echo</span> <span class="s2">"### Pring z_wr_iss cpu time afte the write test"</span>
	print_cputime z_wr_iss

	<span class="nb">echo</span> <span class="s2">"### Print z_rd_int cpu time before the read test"</span>
	print_cputime z_rd_int
	<span class="nb">echo</span> <span class="s2">"### Start read test"</span>
	<span class="nb">time dd </span><span class="k">if</span><span class="o">=</span><span class="nv">$test_file</span> <span class="nv">of</span><span class="o">=</span>/dev/null <span class="nv">bs</span><span class="o">=</span>1M <span class="nv">count</span><span class="o">=</span><span class="nv">$file_size</span>
	<span class="nb">echo</span> <span class="s2">"### Print z_rd_int cpu time before the read test"</span>
	print_cputime z_rd_int
<span class="o">}</span>

benchmark ccm-test /ccm-test/test-file
benchmark gcm-test /gcm-test/test-file
benchmark non-encrypt-test /data/local_steam/test-file
</code></pre></div></div>

<p>My ZFS cache is set to 8GB. So I write and read files with 20GB. It uses dd to write and read a file. Before the read and write, it uses <code class="language-plaintext highlighter-rouge">ps -o cputime,etime</code> to print out CPU time and wall time used by each related ZFS processes.</p>

<p>Running this script creates lots of output. The full output can be found in the appendix at the end. Here are the key lines:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>### Start benchmark ccm-test
// ... output omitted ...
21474836480 bytes (21 GB, 20 GiB) copied, 107.307 s, 200 MB/s
// ... output omitted ...
### Start benchmark gcm-test
// ... output omitted ...
21474836480 bytes (21 GB, 20 GiB) copied, 13.7417 s, 1.6 GB/s
// ... output omitted ...
### Start benchmark non-encrypt-test
// ... output omitted ...
21474836480 bytes (21 GB, 20 GiB) copied, 9.03496 s, 2.4 GB/s
// ... output omitted ...
</code></pre></div></div>

<p>During the test, AES-CCM makes <code class="language-plaintext highlighter-rouge">z_rd_int</code> takes all CPU time as observed before. For AES-GCM, it’s much better, <code class="language-plaintext highlighter-rouge">z_rd_int</code> takes less than 50% and for non encrypted it’s less than 20%. The testing output prints the CPU time and wall time for each of the <code class="language-plaintext highlighter-rouge">z_rd_int</code> processes before and after the test. So you can count the percentage.</p>

<p>From the test result, we can see AES-CCM indeed affect read performance a lot. It’s even slower than writes. We can confirm this is the root cause for our problem.</p>

<h2 id="4-solution-and-workaround">4. Solution and Workaround</h2>

<p>The solution is obvious: just change the encryption from AES-CCM to AES-GCM. But it cannot be done without migrating the dataset to another place and then move it back. It takes time. At the mean time, I moved my Steam library to a non encrypted dataset since I have enough disk space to do the migration. It doesn’t have sensitive information. Yes it exposes the machine to <a href="https://en.wikipedia.org/wiki/Evil_maid_attack">evil maid attack</a>, but my setup on the machine doesn’t prevent it anyway. See my previous blog <a href="/2021-09-19-Personal-ZFS-Offsite-Online-Backup-Solution.html">Personal ZFS Offsite Backup Solution</a> for more information on putting a machine into a not trusted environment.</p>

<p>I’ll do the migration from AES-CCM to AES-GCM in the future and report back how it works. Stay tuned!</p>

<h2 id="5-appendix">5. Appendix</h2>

<p>Here is the full output from the benchmark script:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>### Start benchmark ccm-test
### Print z_wr_iss cpu time before the write test
    TIME     ELAPSED
00:47:56  3-03:39:21
    TIME     ELAPSED
00:22:34  3-03:39:21
    TIME     ELAPSED
00:47:54  3-03:39:21
    TIME     ELAPSED
00:47:55  3-03:39:21
    TIME     ELAPSED
00:00:01  3-03:39:17
    TIME     ELAPSED
00:00:00  3-03:39:17
    TIME     ELAPSED
00:04:50    15:30:06
    TIME     ELAPSED
00:04:49    15:29:57
    TIME     ELAPSED
00:04:51    15:29:56
    TIME     ELAPSED
00:04:51    15:29:18
    TIME     ELAPSED
00:00:00    10:07:30
    TIME     ELAPSED
00:00:00       55:49
### Start write test
20480+0 records in
20480+0 records out
21474836480 bytes (21 GB, 20 GiB) copied, 91.4066 s, 235 MB/s

real	1m31.414s
user	0m0.059s
sys	0m53.252s
### Pring z_wr_iss cpu time afte the write test
    TIME     ELAPSED
00:49:23  3-03:40:53
    TIME     ELAPSED
00:22:34  3-03:40:53
    TIME     ELAPSED
00:49:21  3-03:40:53
    TIME     ELAPSED
00:49:22  3-03:40:53
    TIME     ELAPSED
00:00:01  3-03:40:49
    TIME     ELAPSED
00:00:00  3-03:40:49
    TIME     ELAPSED
00:04:50    15:31:38
    TIME     ELAPSED
00:04:50    15:31:28
    TIME     ELAPSED
00:04:51    15:31:28
    TIME     ELAPSED
00:04:51    15:30:50
    TIME     ELAPSED
00:00:00    10:09:01
    TIME     ELAPSED
00:00:00       57:21
### Print z_rd_int cpu time before the read test
    TIME     ELAPSED
00:24:46  3-03:40:53
    TIME     ELAPSED
00:00:02  3-03:40:49
    TIME     ELAPSED
00:01:50       06:47
    TIME     ELAPSED
00:01:49       06:47
### Start read test
20480+0 records in
20480+0 records out
21474836480 bytes (21 GB, 20 GiB) copied, 107.307 s, 200 MB/s

real	1m47.372s
user	0m0.060s
sys	0m8.091s
### Print z_rd_int cpu time after the read test
    TIME     ELAPSED
00:26:24  3-03:42:41
    TIME     ELAPSED
00:00:02  3-03:42:37
    TIME     ELAPSED
00:03:28       08:34
    TIME     ELAPSED
00:03:27       08:34
### Start benchmark gcm-test
### Print z_wr_iss cpu time before the write test
    TIME     ELAPSED
00:49:35  3-03:42:41
    TIME     ELAPSED
00:22:34  3-03:42:41
    TIME     ELAPSED
00:49:33  3-03:42:41
    TIME     ELAPSED
00:49:33  3-03:42:41
    TIME     ELAPSED
00:00:01  3-03:42:37
    TIME     ELAPSED
00:00:00  3-03:42:37
    TIME     ELAPSED
00:04:50    15:33:26
    TIME     ELAPSED
00:04:50    15:33:16
    TIME     ELAPSED
00:04:51    15:33:16
    TIME     ELAPSED
00:04:51    15:32:38
    TIME     ELAPSED
00:00:00    10:10:49
    TIME     ELAPSED
00:00:00       59:08
### Start write test
20480+0 records in
20480+0 records out
21474836480 bytes (21 GB, 20 GiB) copied, 56.9529 s, 377 MB/s

real	0m56.960s
user	0m0.045s
sys	0m53.566s
### Pring z_wr_iss cpu time afte the write test
    TIME     ELAPSED
00:49:42  3-03:43:38
    TIME     ELAPSED
00:22:35  3-03:43:38
    TIME     ELAPSED
00:49:39  3-03:43:38
    TIME     ELAPSED
00:49:39  3-03:43:38
    TIME     ELAPSED
00:00:01  3-03:43:34
    TIME     ELAPSED
00:00:00  3-03:43:34
    TIME     ELAPSED
00:04:51    15:34:23
    TIME     ELAPSED
00:04:50    15:34:14
    TIME     ELAPSED
00:04:52    15:34:13
    TIME     ELAPSED
00:04:52    15:33:35
    TIME     ELAPSED
00:00:00    10:11:46
    TIME     ELAPSED
00:00:00    01:00:06
### Print z_rd_int cpu time before the read test
    TIME     ELAPSED
00:26:24  3-03:43:38
    TIME     ELAPSED
00:00:02  3-03:43:34
    TIME     ELAPSED
00:00:00       00:05
    TIME     ELAPSED
00:00:00       00:05
### Start read test
20480+0 records in
20480+0 records out
21474836480 bytes (21 GB, 20 GiB) copied, 13.7417 s, 1.6 GB/s

real	0m13.743s
user	0m0.071s
sys	0m11.215s
### Print z_rd_int cpu time after the read test
    TIME     ELAPSED
00:26:31  3-03:43:52
    TIME     ELAPSED
00:00:02  3-03:43:48
    TIME     ELAPSED
00:00:07       00:19
    TIME     ELAPSED
00:00:07       00:19
### Start benchmark non-encrypt-test
### Print z_wr_iss cpu time before the write test
    TIME     ELAPSED
00:49:42  3-03:43:52
    TIME     ELAPSED
00:22:35  3-03:43:52
    TIME     ELAPSED
00:49:40  3-03:43:52
    TIME     ELAPSED
00:49:39  3-03:43:52
    TIME     ELAPSED
00:00:01  3-03:43:48
    TIME     ELAPSED
00:00:00  3-03:43:48
    TIME     ELAPSED
00:04:51    15:34:37
    TIME     ELAPSED
00:04:50    15:34:28
    TIME     ELAPSED
00:04:52    15:34:28
    TIME     ELAPSED
00:04:52    15:33:49
    TIME     ELAPSED
00:00:00    10:12:01
    TIME     ELAPSED
00:00:00    01:00:20
### Start write test
20480+0 records in
20480+0 records out
21474836480 bytes (21 GB, 20 GiB) copied, 56.0508 s, 383 MB/s

real	0m56.052s
user	0m0.042s
sys	0m53.060s
### Pring z_wr_iss cpu time afte the write test
    TIME     ELAPSED
00:49:46  3-03:44:49
    TIME     ELAPSED
00:22:35  3-03:44:49
    TIME     ELAPSED
00:49:44  3-03:44:49
    TIME     ELAPSED
00:49:43  3-03:44:49
    TIME     ELAPSED
00:00:01  3-03:44:44
    TIME     ELAPSED
00:00:00  3-03:44:44
    TIME     ELAPSED
00:04:51    15:35:33
    TIME     ELAPSED
00:04:50    15:35:24
    TIME     ELAPSED
00:04:52    15:35:24
    TIME     ELAPSED
00:04:52    15:34:46
    TIME     ELAPSED
00:00:00    10:12:57
    TIME     ELAPSED
00:00:00    01:01:16
### Print z_rd_int cpu time before the read test
    TIME     ELAPSED
00:26:31  3-03:44:49
    TIME     ELAPSED
00:00:02  3-03:44:45
    TIME     ELAPSED
00:00:07       01:16
    TIME     ELAPSED
00:00:07       01:16
### Start read test
20480+0 records in
20480+0 records out
21474836480 bytes (21 GB, 20 GiB) copied, 9.03496 s, 2.4 GB/s

real	0m9.036s
user	0m0.032s
sys	0m8.207s
### Print z_rd_int cpu time after the read test
    TIME     ELAPSED
00:26:33  3-03:44:58
    TIME     ELAPSED
00:00:02  3-03:44:54
    TIME     ELAPSED
00:00:09       01:25
    TIME     ELAPSED
00:00:09       01:25
</code></pre></div></div>]]></content><author><name></name></author><category term="ZFS" /><category term="Linux" /><category term="Profiling" /><category term="dkms" /><category term="kernel" /><summary type="html"><![CDATA[I bought a new video game recently but found z_rd_int processes took almost all the CPU time when I was playing it. That doesn’t make much sense to me since I install games on a non compressed ZFS dataset. Even though I don’t have a powerful CPU, I don’t expect ZFS to use all of them and only reads about 60-70MiB/s from each of the NVME SSDs. To double check, I used iostat -x 1 to confirm the iowait is very low. So disk IO is not the bottleneck.]]></summary></entry><entry><title type="html">Introduce K3s, CephFS and MetalLB to My High Avaliable Cluster</title><link href="https://www.binwang.me/2023-11-28-Introduce-K3s-CephFS-and-MetalLB-to-My-High-Avaliable-Cluster.html" rel="alternate" type="text/html" title="Introduce K3s, CephFS and MetalLB to My High Avaliable Cluster" /><published>2023-11-28T00:00:00-05:00</published><updated>2023-11-28T00:00:00-05:00</updated><id>https://www.binwang.me/Introduce-K3s-CephFS-and-MetalLB-to-My-High-Avaliable-Cluster</id><content type="html" xml:base="https://www.binwang.me/2023-11-28-Introduce-K3s-CephFS-and-MetalLB-to-My-High-Avaliable-Cluster.html"><![CDATA[<p>In a previous blog <a href="/2023-03-13-Infrastructure-Setup-for-High-Availability.html">Infrastructure Setup for High Availability</a>, I talked about how I setup a cluster infrastructure for high availability applications. I have made a few changes since then. This blog is to talk about them in details.</p>

<h2 id="updated-architecture-overview">Updated Architecture Overview</h2>

<p><img src="/static/images/2023-11-28-Introduce-K3s-CephFS-and-MetalLB-to-My-High-Avaliable-Cluster/ha-cluster-infrastructure-k3s.png" alt="arch-diagram" /></p>

<p>Comparing the diagram with the one in <a href="/2023-03-13-Infrastructure-Setup-for-High-Availability.html">Infrastructure Setup for High Availability</a>, the overall structure remains the same, with a few modifications:</p>

<ul>
  <li>Not shown in the graph, but replaced official Kubernetes with K3s.</li>
  <li>Replaced GlusterFS with CephFS.</li>
  <li>Included cert-manager to get SSL certificates.</li>
  <li>Replaced Keepalived on each node with MetalLB.</li>
</ul>

<h2 id="replace-kubernetes-with-k3s">Replace Kubernetes with K3s</h2>

<p>I didn’t know <a href="https://k3s.io/">K3s</a> back when I setup my Kubernetes cluster for the first time. But since then I heard a lot of good things about it at various places. However, the complexity of migration and its installation method through a script from Internet instead of an OS package made me think twice before adopt it. But after I watched the video <a href="https://www.youtube.com/watch?v=k58WnbKmjdA">Talk About K3s Internals from Darren Shepherd</a>, I realized how simple k3s is compared to Kubernetes. I highly recommend everyone who is interested in K3s watch this video.</p>

<p>In short, K3s is a distribution of Kubernetes instead of a fork. It does these things with a few patches: combined the components of Kubernetes into one binary and process, and removed some components not needed in a bare metal environment. By doing so, it makes its binary size and memory footprint smaller than Kubernetes, and makes it easier to deploy and manage. It only needs a binary <code class="language-plaintext highlighter-rouge">k3s</code> and a configuration file under <code class="language-plaintext highlighter-rouge">/etc/rancher/k3s/config.yaml</code> to start, and all of its content is under <code class="language-plaintext highlighter-rouge">/var/lib/rancher/k3s</code>. The official install script adds a little bit more than just the binary file: it has a few scripts to kill and uninstall k3s. It also includes systemd file to start/stop k3s through systemd. So even though it’s not packaged into a standard OS package, I think the complexity is manageable so I started to experiment with it.</p>

<p>It’s very easy to config K3s since all it needs is a configuration file on each machine. I created a virtual machine cluster with Vagrant in the project <a href="https://github.com/wb14123/k3s-vm-cluster">k3s-vm-cluster</a> to experiment with it. Feel free to play with it to get a feel with it before go all in. The setup is based on the official guide for <a href="https://docs.k3s.io/datastore/ha-embedded">High Availability Embedded etcd</a>. It’s the easiest way to setup a high available K3s cluster.</p>

<p>No load balancer setup is needed if no external Kubernetes API server HA is needed. That means, you can access to Kubernetes API server within the cluster if any of the machine fails. But if you still want to access it outside of the cluster during a failure, check <a href="https://docs.k3s.io/datastore/cluster-loadbalancer">this doc</a>. Alternatively, I think load balancer like MentalLB can also do it, but I don’t need it so I didn’t experiment with it.</p>

<h2 id="distributed-storage-system-glusterfs-to-cephfs">Distributed Storage System: GlusterFS to CephFS</h2>

<p>The biggest motivation drives this migration is the deprecation of GlusterFS. I’m using distributed file system for a few use cases:</p>

<ul>
  <li>Configuration files: this can be migrated to <a href="https://kubernetes.io/docs/concepts/configuration/configmap/">Kubernetes ConfigMaps</a>.</li>
  <li>Logs: this can be migrated to a centralized log management system like ElasticSearch. But some of them like <a href="https://grafana.com/oss/loki/">Loki</a> in turn depends on another distributed storage.</li>
  <li>Data files: this is most complex one. Some of the services support saving files into S3 compatible systems. But some of them don’t. (I cannot control the services since I only self host them instead of developed them). One option is to not having HA and just bind those services into a specific host and use local storage.</li>
  <li>Docker registry: this belongs to the point “Data files” above, but this is very import so I separate into another point. I’m using <a href="https://www.sonatype.com/products/sonatype-nexus-repository">Sonatype Nexus</a> as the docker registry. It supports to put packages into S3 but still pretty tricky to get rid of all the local files. This is a service that absolutely needs HA if I want to have a HA cluster. Or I can change to another Docker registry implementation, but I feel pretty comfortable using it so I don’t want to change it.</li>
</ul>

<p>So it basically comes down to these 2 options:</p>

<ol>
  <li>Use a S3 compatible storage like <a href="https://min.io/">MinIO</a> but do a lot of work to configure services to store files into that, and make services cannot do that not HA anymore.</li>
  <li>Go ahead and uses a real distributed file system like CephFs or <a href="https://longhorn.io/">Longhorn</a>.</li>
</ol>

<p><em>Update: I also explored <a href="https://linbit.com/">LINBIT</a> which I forgot to write it here. It got more and more complex when I went into the rabbit hole. But its architecture looks very interesting to me. So I may explore it more in the future for other use cases.</em></p>

<p>Option 1 sounds appealing to me at first since I really don’t want to deal with the complexity of setting up CephFS. But as I go into the rabbit hole, I found configuring the services to use S3 may be a more complex process and less portable than just setup CephFS. So at the end I decide to go option 2.</p>

<p>I’ve heard of CephFS long time ago but decided to use GlusterFS at previous setups because of the level of user friendly. So CephFS seems like a nature choice after GlusterFs is deprecated. Especially when I found other than the distributed block device, it also supports file system and S3 compatible storage system. It’s also easier to install than before because of <a href="https://rook.io/">Rook</a>. Longhorn is another choice I looked a little bit but because of wider adoption of CephFS and more features of it, I decide to use CephFS at the end.</p>

<p>The way I use it is mainly <a href="https://rook.io/docs/rook/v1.11/Storage-Configuration/Shared-Filesystem-CephFS/filesystem-storage/">Ceph Filesystem</a>, so it’s easier to share volumes between pods. Again, the project <a href="https://github.com/wb14123/k3s-vm-cluster">k3s-vm-cluster</a> has an example about it. Try to play it if you are interested in it. Along the way I actually contributed to Rook project by improving doc (<a href="https://github.com/rook/rook/pull/13045">#13045</a>) and its error message (<a href="https://github.com/rook/rook/pull/13046">#13046</a>).</p>

<h2 id="network-gateway">Network Gateway</h2>

<p>In the previous article, I talked about using Cloudflare tunnel, or NodePort and Keepalived to expose services to the Internet. But there are some other things a network gateway can do other than just expose the service: it can also do things like terminate SSL encryption and so on. Cloudflare tunnel support terminate SSL at their end so I don’t need to worry about that. But for some services, I don’t want Cloudflare to see the traffic, so I need to terminate SSL and expose service by myself.</p>

<p>As I said, expose service part was done by NodePort and Keepalived, which is not very elegant but works. For the terminate SSL part, I was using Nginx as reverse proxy. But updating SSL certificates is a little bit more complex. I don’t want to talk it in details here because the setup is pretty complex and explaining it will be very lengthy. The point is, with this migration, I want to revisit this part to make it simpler and more elegant.</p>

<p>Kubernetes has a concept of <a href="https://kubernetes.io/docs/concepts/services-networking/ingress/">Ingress</a>, and newer but less mature, <a href="https://gateway-api.sigs.k8s.io/">Gateway</a>. What they are doing is essentially reverse proxy like Nginx. In fact, Nginx Ingress is a thing. The advantage is that you don’t need to configure all the services in a single place like Nginx’s configuration files. You can create Kubernetes resources for each of the service. So that the deployment and configuration of each service is totally self contained. This is a very good feature, especially for a company: when I first started to use Kubernetes at 2015 in a previous company, I felt the pain of not having it. But the feature of Ingress is pretty limited. For example, it can only bind to 443. It cannot modify the http content, and so on. So that I may still need a layer of Nginx for my use cases. The design of gateway is too complex and the features don’t really meet all my requirements as well.</p>

<p>There are some players like <a href="https://traefik.io/">Traefik</a>(shipped with K3s by default) and <a href="https://istio.io/">Istio</a> which overcome the limitations by having their own custom resources. But Traefik cannot get new certificates from Let’s Encrypt with a HA setup. Istio is just too complex and include features like service mesh that I don’t need. I can see how service mesh can be useful in big companies, but I prefer not to have another layer on my own service. At the end, I don’t think the complexity worth it.</p>

<p>But while I exploring Traefik and Istio, I found <a href="https://cert-manager.io/">cert-manager</a>, which can be deployed into Kubernetes. It can get certificates from Let’s Encrypt and put them into Kubernetes secrets, which then can be mount into each pods. It supports Cloudflare DNS API for <a href="https://letsencrypt.org/docs/challenge-types/#dns-01-challenge">ACME DNS challenge</a>, so I don’t need to export a http service for Let’s Encrypt to verify the ownership of the domain name. With all of this features, I decided to use it and mount the certificates into Nginx pods. It resolves the problem of update certificates from Let’s Encrypt.</p>

<p>For the other problem of exposing the services to Internet in a HA way, I want to use a more Kubernetes native way instead of setup Keepalived outside of the Kubernetes cluster. Kubernetes supports <a href="https://kubernetes.io/docs/tasks/access-application-cluster/create-external-load-balancer/">external load balancers</a>. But most of the load balancers it supports are from cloud. Then I found <a href="https://metallb.org/">MetalLB</a>, which supports creating a HA load balancer without special hardware in a bare metal cluster. I use it with <a href="https://metallb.org/concepts/layer2/">layer 2 mode</a>, which creates a virtual IP like keepalived and can failover to another node.</p>

<h2 id="deploy-services-with-code">Deploy Services with Code</h2>

<p>What I didn’t talk in the previous blog is, I define the deployment of my services as code instead yaml files. It gives lots of advantages: first, you can create models for your own deployment pattern so that you can avoid lots of redundant code. Traditionally it’s hard to define the deployment as code. There are lots of frameworks to do it but none of them is easy to use. But with Kubernetes, all you need is generating a resource object for Kubernetes to use at the end. You can construct it in any way with your favorite language, and either output a YAML or call Kubernetes API directly. It’s using a high level language instead of writing machine code directly. It’s much more elegant and the maintenance is much easier. Be aware: use a real language instead of some template language. Why limit your power to do things?</p>

<p>This approach works so well especially during this migration. For example, I abstracted all the storage layer for my services, so that when I migrated from GlusterFS to CephFS, I just need to change the storage class to define the CephFS volume, and the code for services don’t need to change much.</p>

<p>Hope you enjoy my experience of setting up a HA cluster. Happy hacking and have fun with your own cluster!</p>]]></content><author><name></name></author><category term="Kubernetes" /><category term="CephFS" /><category term="MetalLB" /><category term="k3s" /><category term="Infrastructure" /><category term="devops" /><summary type="html"><![CDATA[In a previous blog Infrastructure Setup for High Availability, I talked about how I setup a cluster infrastructure for high availability applications. I have made a few changes since then. This blog is to talk about them in details.]]></summary></entry><entry><title type="html">Update on RSS Brain to Find Related Articles with Machine Learning</title><link href="https://www.binwang.me/2023-11-14-Update-On-RSS-Brain-to-Find-Related-Articles-with-Machine-Learning.html" rel="alternate" type="text/html" title="Update on RSS Brain to Find Related Articles with Machine Learning" /><published>2023-11-14T00:00:00-05:00</published><updated>2023-11-14T00:00:00-05:00</updated><id>https://www.binwang.me/Update-On-RSS-Brain-to-Find-Related-Articles-with-Machine-Learning</id><content type="html" xml:base="https://www.binwang.me/2023-11-14-Update-On-RSS-Brain-to-Find-Related-Articles-with-Machine-Learning.html"><![CDATA[<p>In the previous blog about RSS, <a href="/2022-12-03-How-RSS-Brain-Shows-Related-Articles.html">How RSS Brain Shows Related Articles</a>, I talked about how RSS Brain finds the related articles. I’ve updated the algorithm recently. This blog is about the details about the update. The basic idea is to replace tf-idf algorithm with text embeddings to represent the articles as vectors, and use ElastcSearch to store and query those vectors.</p>

<h2 id="the-disadvantages-of-previous-algorithm">The Disadvantages of Previous Algorithm</h2>

<p>First let’s do a quick revisit on the algorithm before the update: it’s using tf-idf algorithm. Which is basically an algorithm to represent each document as a vector by using the words’ frequency in it. It’s an algorithm that is easy to understand, and works well enough in practice to power lots of searching engines for a long time. However, it has a few shortcomings:</p>

<p>First, it doesn’t understand the meaning of the word. A word can mean different things based on context, order, combinations and so on. Different words can also have the same meaning. Word frequency along doesn’t catch that.</p>

<p>Second, “word” needs to be defined. Which is a relatively easy task for languages like English, since it has a built-in word separator character (space). However, for languages like Chinese, there is no obvious way to separate the words. The performance of tf-idf algorithm largely depends on the performance of word separating algorithm, which itself is much more complex than tf-idf and often involves machine learning as well. Even for languages like English, in order to minimize the first disadvantage above, the words are usually broke down so that some similar words can be matched.</p>

<p>Last, which is an extension of the first disadvantage: it’s hard to do multi language matches. Word frequency along doesn’t know that different words in different languages can mean the same thing. Of course you can translate the document to other languages and index the translated documents, but it doesn’t scale well when you need to support more and more languages. And translation algorithms are usually much more complex than tf-idf, and mostly use machine learning too.</p>

<h2 id="word-and-document-embeddings">Word and Document Embeddings</h2>

<p>With the advancement of machine learning, a new method to represent words as vectors has been developed in the paper <a href="https://arxiv.org/abs/1301.3781">Efficient Estimation of Word Representations in Vector Space</a>. The vector is called word embedding. Then based on the idea, <a href="https://arxiv.org/abs/1405.4053">Distributed Representations of Sentences and Documents</a> explores representing paragraphs as a vectors. Without go into the details, the basic idea is to get a layer from neural network for a NLP task.</p>

<p>For example, if we have a neural network to predict the nth word given previous words, then we may have a neural network like this:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>word[1]   --&gt; vector[1]
word[2]   --&gt; vector[2]    --&gt; layer2 --&gt; ... -&gt; classifier -&gt; output
...
word[n-1] --&gt; vector[n-1]
</code></pre></div></div>

<p>Words are mapped to vectors at the first layer, with something like</p>

\[v = w * W + b\]

<p>Which \(v\) is the vector, \(w\) is the one-hot encoded word. And matrix \(W\) and \(b\) is the trained parameters. There are many other parameters in the later layers of the neural network but we don’t care. We only take \(W\) and \(b\) so that we can compute the vector for any word. With this method, the represented vectors can measure similarities between words by computing similarity of the vectors. Also surprisingly, quoted from the paper <a href="https://arxiv.org/abs/1301.3781">Efficient Estimation of Word Representations in Vector Space</a>: “To find a word that is similar to small in the same sense as biggest is similar to big, we can simply compute vector \(X = vector(biggest) − vector(big) + vector(small)\).” What a beautiful result!</p>

<p>I was aware of this research not long after it came out. I believe some commercial search engines started to use it since then. But the ecosystem like models, tools, databases really picked up since GPT3 came out. So recently, I decided to use it in RSS Brain because how easy to do it nowadays.</p>

<h2 id="select-a-model-to-use">Select a Model to Use</h2>

<p>The first step is to select a model to use. I think OpenAI may have the best model that is available to public. You cannot access the real model but there are APIs you can call to use the model. But I don’t like it for 2 reasons: First, I don’t like OpenAI as a company: it presents itself as a non-profit organization first with the goal to make AI accessible to everyone, then stopped publish models or even the algorithm details. Second, I don’t want vendor lock-in.</p>

<p>There is also Llama. But it’s not really a multilingual model. I see some attempts to train it on some other languages, but the result are not that good in my experience. The license of the model is not commercial friendly as well. And there is no easy to use API to get the embeddings.</p>

<p>At the end I found <a href="https://www.sbert.net/index.html">SentenceTransformers</a>. There are lots of <a href="https://www.sbert.net/docs/pretrained_models.html in the project">pretrained models</a>. After all I selected the model <code class="language-plaintext highlighter-rouge">paraphrase-multilingual-mpnet-base-v2</code> since it’s a multilingual model. But it’s called “sentence” transformers for a reason: there is a size limit on the length of document that you can feed in to the models. I ended up to just get the embeddings for the article title. I think it’s a good enough for my use case.</p>

<h2 id="implementation-details-for-model-server">Implementation Details for Model Server</h2>

<p>The library SentenceTransformer is very easy to use. However it’s implemented in Python so it needs a way to communicate with RSS Brain server, which is written in Scala. Since this is a computation heavy task, the first though is to have a buffer queue in between so that the Python program can process the articles in a speed it can handle. Kafka is a good choice for external task queue but I don’t think it worth the complexity to import another component into the system. So I created buffer queue at both end to avoid creating too many requests while maintain some parallelism. Here is what the whole architecture looks like:</p>

<p><img src="/static/images/2023-11-14-Update-On-RSS-Brain-to-Find-Related-Articles-with-Machine-Learning/article-embedding-arch.png" alt="embedding-arch" /></p>

<p>The green parts in the diagram means the workers in them can work concurrently. On the Scala side, it follows the pattern I experimented in <a href="/2023-08-27-Compare-Task-Processing-Approaches-in-Scala.html">Compare Task Processing Approaches in Scala</a>. On the Python side, it’s more tricky since Python’s async handling is far worth than Scala’s plain old Future, not to mention effect systems like Cats Effect. I may write another blog in the future about it.</p>

<p>The reason I go great detail into this relatively simple problem is that it represents a category of problems: problems that need Python to do some async work because of the library supports. For example, in the future, Python server may have more features like fetching Youtube transcriptions. The architecture to integrate it into RSS Brain would be the same.</p>

<h2 id="database-to-store-and-query-embeddings">Database to Store and Query Embeddings</h2>

<p>There are a few vector databases that can store vectors and query nearest vectors if given one. ElasticSearch added vector fields support at 7.0 and approximate nearest neighbor search (ANN) at 8.0. Since RSS Brain is already using ElasticSearch heavily for searching, I can just use it without add another database into the dependency. It also supports machine learning models so that you don’t need to insert the embedding vectors from the outside world, but I find it’s not as flexible.</p>

<p>Once the vectors are inserted into ElastiSearch, it’s just an API call to get the most similar documents. The details of vector insert and query are in the <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/knn-search.html">ElasticSearch KNN search document</a>. One tricky part is that even though ElasticSearch supports <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/knn-search.html#_combine_approximate_knn_with_other_features">combining ANN search with other features like term searches (tf-idf algorithm)</a> by using a boost factor, it doesn’t work well unless you are willing to tune it. That’s because the embedding vector and term vector mean different things, and the similarity score is not really comparable. So I ended up enable vector search only for finding related articles, instead of combining with term searches.</p>

<h2 id="result">Result</h2>

<p>It’s actually hard to have some metrics for the performance of finding related articles. I don’t believe metrics like click rate, since it doesn’t necessarily show the articles are related. I think the only way for me is to review the results manually and compute the score based on it. But I don’t think it has much value since supporting multiple language along would make it much better than the previous algorithm. But if you are using RSS Brain, you can see the results yourself and let me know what you think about the new algorithm!</p>]]></content><author><name></name></author><category term="RSS Brain" /><category term="Machine Learning" /><category term="Nerual Network" /><category term="Embeddings" /><category term="Python" /><summary type="html"><![CDATA[In the previous blog about RSS, How RSS Brain Shows Related Articles, I talked about how RSS Brain finds the related articles. I’ve updated the algorithm recently. This blog is about the details about the update. The basic idea is to replace tf-idf algorithm with text embeddings to represent the articles as vectors, and use ElastcSearch to store and query those vectors.]]></summary></entry><entry><title type="html">Add Index Sidebar to My Blog</title><link href="https://www.binwang.me/2023-11-10-Index-Sidebar-on-My-Blog.html" rel="alternate" type="text/html" title="Add Index Sidebar to My Blog" /><published>2023-11-10T00:00:00-05:00</published><updated>2023-11-10T00:00:00-05:00</updated><id>https://www.binwang.me/Index-Sidebar-on-My-Blog</id><content type="html" xml:base="https://www.binwang.me/2023-11-10-Index-Sidebar-on-My-Blog.html"><![CDATA[<p>In a previous blog <a href="/2021-10-31-Add-Index-to-My-Blog.html">Add Index to My Blog</a>, I talked about how I added an index page to my blog that put all the articles into categories. I always wanted the index to be a sidebar instead of a single page, but I guess I didn’t wrap my head around about how to implement so I gave up at last. But recently, when I started to use <a href="https://obsidian.md/">Obsidian</a> and checked some demos of <a href="https://obsidian.md/publish">Obsidian Publish</a>, I found having a sidebar is so useful and beautiful so I decide I should implement it.</p>

<p>You can see the result right now: if you are on a big screen device, the index is on the left side of the page. If you are on a small screen device like a mobile phone, it will show a menu button at the top left corner instead. Clicking it will take you to the index.</p>

<p>When I implement it, I want to keep it simple and stupid. That means:</p>

<ul>
  <li>I want to be as simple as possible as long as it has the function: show articles in nested categories.</li>
  <li>I want to use as little Javascript as possible so people can still use it with Javascript disabled.</li>
</ul>

<p>I found the design of Obsidian Publish is very good. So I copied lots of details from them with some modifications: I didn’t implement showing/hiding sub items when click on the index entry since I think it’s not necessary, and I like how it looks when all the articles are listed there: feels like I’ve written lots of things. The categories are sorted by alphabet order and the posts are ordered by publish date. I also added the publish year for each article entry: some articles can look outdated but if people noticed the published year they can understand the context.</p>

<p>Since I’m using Jeykyll, I can generate plain HTML when possible to avoid the usage of Javascript. So the sidebar is generated for each page instead of using Javascript to keep the sidebar and replace the article content on the fly. Javascript is only used for 2 features:</p>

<ol>
  <li>Remember the position of the sidebar when jump pages.</li>
  <li>Scroll the sidebar to show the entry for the current page if it’s not in the viewpoint.</li>
</ol>

<p>Both of the features are not that important so the sidebar is still usable without Javascript. Even for the menu button on small screens, it’s not popping up a dialog. It just jumps to a new static page that has all the index so no Javascript is needed.</p>

<p>The previous implementation of the index page uses recursive templates: Since the nested index is a tree, rendering the content in a recursive manner is a nature thought. However, I made that mistake to put the complex logic into the template engine. So this time, I traverse the tree with Ruby code and generates a list for the template to render. It has all the information like entry type, the depth of the entry and so on. It makes the template code much simpler so it’s easier to implement other features on top of it.</p>

<p>If you want to checkout the detailed implementation, go to my <a href="https://github.com/wb14123/blog">Github repo for the blog</a> and check <a href="https://github.com/wb14123/blog/blob/master/jekyll/_plugins/Index.rb"><code class="language-plaintext highlighter-rouge">jekyll/_plugins/Index.rb</code></a> and <a href="https://github.com/wb14123/blog/blob/master/jekyll/_includes/index_menu.html"><code class="language-plaintext highlighter-rouge">jekyll/_includes/index_menu.html</code></a>.</p>]]></content><author><name></name></author><category term="blog" /><category term="Jekyll" /><category term="Javascript" /><category term="desgin" /><summary type="html"><![CDATA[In a previous blog Add Index to My Blog, I talked about how I added an index page to my blog that put all the articles into categories. I always wanted the index to be a sidebar instead of a single page, but I guess I didn’t wrap my head around about how to implement so I gave up at last. But recently, when I started to use Obsidian and checked some demos of Obsidian Publish, I found having a sidebar is so useful and beautiful so I decide I should implement it.]]></summary></entry><entry><title type="html">How to Cleanup Ceph Filesystem for Deleted Kubernetes Persistent Volume</title><link href="https://www.binwang.me/2023-11-04-How-to-Cleanup-Ceph-Filesystem-for-Deleted-Kubernetes-Persistent-Volume.html" rel="alternate" type="text/html" title="How to Cleanup Ceph Filesystem for Deleted Kubernetes Persistent Volume" /><published>2023-11-04T00:00:00-04:00</published><updated>2023-11-04T00:00:00-04:00</updated><id>https://www.binwang.me/How-to-Cleanup-Ceph-Filesystem-for-Deleted-Kubernetes-Persistent-Volume</id><content type="html" xml:base="https://www.binwang.me/2023-11-04-How-to-Cleanup-Ceph-Filesystem-for-Deleted-Kubernetes-Persistent-Volume.html"><![CDATA[<p><a href="https://docs.ceph.com">Ceph</a> is a distributed file system. <a href="https://rook.io/">Rook</a> is a project to deploy it with Kubernetes. I recently replaced GlusterFS in my Kubernetes cluster with Ceph. I will write a blog (or a series of blogs) for the migration. But in this article, I will just talk about a problem I encountered, just in case I forget it.</p>

<p>Once Rook is deployed in Kubernetes, you can create a <a href="https://rook.io/docs/rook/v1.11/Storage-Configuration/Shared-Filesystem-CephFS/filesystem-storage/">Ceph Filesystem</a> and use it to <a href="https://kubernetes.io/docs/concepts/storage/persistent-volumes">persistent volume (PV)</a>. Each PV’s data will be stored in a folder in the filesystem. If the PV’s reclaiming policy is set to <a href="https://kubernetes.io/docs/concepts/storage/persistent-volumes/#retain">retain</a>, the data will not be deleted after the persistent volume is manually deleted. It’s safer in this way. But what could you do if you want to cleanup the data? Normally you should change the PV’s reclaim policy before you delete the PV, then Rook’s operator will auto reclaim the storage in Ceph. But what if you forget or didn’t know that (like me), and want to cleanup the data after?</p>

<p>First, we need to the folder/subvolume names in Ceph that store’s each PV’s data. We an get that by using <code class="language-plaintext highlighter-rouge">kubectl describe pv &lt;pv-name&gt;</code> and look for the field <code class="language-plaintext highlighter-rouge">subvolumeName</code>. But since the PV is deleted, we need to find the mappings for existing PVs and compare that with the folders/subvolumes in Ceph. This is the command to show all of the existing ones:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>kubectl get pv -o yaml | grep subvolumeName  | sort
</code></pre></div></div>

<p>Then we need to find all the existing folders/subvolumes in Ceph’s filesystem: Start a Ceph toolbox pod based on the <a href="https://rook.github.io/docs/rook/v1.11/Troubleshooting/ceph-toolbox/?h=toolbox">doc</a>. Then go into the pod and find the filesystem’s name first:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ceph fs ls
</code></pre></div></div>

<p>After getting the filesystem’s name, get all the subvolumegroup from it:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ceph fs subvolume ls &lt;fs-name&gt; csi | grep 'name' | sort
</code></pre></div></div>

<p>Compare this list with the list above, you should be able to find a subvolume that exists in Ceph but not shown in Kubernetes’ PV mapping. Use this command to check its info:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ceph fs subvolume info &lt;fs-name&gt; &lt;subvolume-name&gt; csi
</code></pre></div></div>

<p>If you are sure this is the folder you want to delete, use this command to delete it:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ceph fs subvolume rm &lt;fs-name&gt; &lt;subvolume-name&gt; csi
</code></pre></div></div>]]></content><author><name></name></author><category term="Kubernetes" /><category term="Ceph" /><category term="Distributed file system" /><summary type="html"><![CDATA[Ceph is a distributed file system. Rook is a project to deploy it with Kubernetes. I recently replaced GlusterFS in my Kubernetes cluster with Ceph. I will write a blog (or a series of blogs) for the migration. But in this article, I will just talk about a problem I encountered, just in case I forget it.]]></summary></entry></feed>