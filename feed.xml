<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="https://www.binwang.me/feed.xml" rel="self" type="application/atom+xml" /><link href="https://www.binwang.me/" rel="alternate" type="text/html" /><updated>2024-07-13T10:53:53-04:00</updated><id>https://www.binwang.me/feed.xml</id><title type="html">Bin Wang - My Personal Blog</title><subtitle>This is my personal blog about computer science, technology and my life.</subtitle><entry><title type="html">A Review of Linux on Surface Pro 4</title><link href="https://www.binwang.me/2024-07-12-A-Review-of-Linux-on-Surface-Pro-4.html" rel="alternate" type="text/html" title="A Review of Linux on Surface Pro 4" /><published>2024-07-12T00:00:00-04:00</published><updated>2024-07-12T00:00:00-04:00</updated><id>https://www.binwang.me/A-Review-of-Linux-on-Surface-Pro-4</id><content type="html" xml:base="https://www.binwang.me/2024-07-12-A-Review-of-Linux-on-Surface-Pro-4.html"><![CDATA[<h2 id="background">Background</h2>

<p>I bought a Surface Pro 4 at 2016. It has an Intel Core m3-6Y30 CPU and 4GB memory. The spec is not that impressive even compared to an average laptop released years earlier. On the other hand, the form factor is very attractive to me: at a very low price, you get a tablet with a beautiful HiDPI 2k screen, a pressure sensitive stylus and an useable keyboard. It is on the heavier side if used as a tablet, but compared to other laptops, it’s very light. It served me very well for my limited use cases. The blog <a href="/2016-11-28-Config-Development-Environment-on-Windows.html">Build a Unix Like Environment on Windows</a> was written at that era. Some years later, I bought a more powerful laptop when I needed to work while traveling. So I gave the Surface away to a family member.</p>

<p>However, during the past years, I couldn’t stop thinking about having a Linux tablet. At first I checked <a href="https://pine64.org/devices/pinetab/">Pinetab</a>, then I realized I had a Surface which would be perfect if I could install Linux on it. I searched online and found some successful stories. So when I <a href="/2024-03-19-Travel-Back-to-China.html">travelled back to my hometown</a> at the beginning of this year, I brought the Surface back with me and started to experiment with it.</p>

<h2 id="use-cases">Use Cases</h2>

<p>Before I go further, I need to mention my intended use cases:</p>

<ul>
  <li>Browse Internet. Mainly <a href="https://www.rssbrain.com/">RSS Brain</a>, the RSS reader I built by myself.</li>
  <li>Media consumption: watch videos from my Samba share and online websites like Youtube.</li>
  <li>PDF reading: reading only is enough for me but it’s better if I can take notes in the PDF.</li>
  <li>Sketches: I don’t have a habit to do handwriting notes even at students era. Nowadays it’s more efficient and readable/searchable to take text notes with Markdown. However, I do like drawing sketches on paper when brain storming or resolving some hard problem. Moving it to digital has a lot of benefits if it works.</li>
  <li>Drawing: this is a good to have feature. I don’t really have needs to draw things but it’s always fun. Especially with the development of AI, if I draw something and send it to a more powerful machine to generate images, it could open doors to many possibilities.</li>
</ul>

<h2 id="installation">Installation</h2>

<p>The installation of Linux is actually very easy. I tried two distros and the installation process went very smooth for both of them. The distros I tried are <a href="https://endeavouros.com/">EndeavourOS</a> and Fedora workstation 40.</p>

<p>The installation steps are well documented in <a href="https://github.com/linux-surface/linux-surface/wiki/Installation-and-Setup#installation">linux-surface’s wiki</a>. <a href="https://github.com/linux-surface/linux-surface">linux-surface</a> is the Linux kernel and tools for Surface devices. The wiki page has its installation steps as well.</p>

<p>In general, if only used as a laptop, the experience is almost perfect even without the linux-surface kernel. But using it as a tablet is another story.</p>

<h2 id="what-works">What Works</h2>

<p>Let’s talk about what works first. Even without linux-surface kernel, almost everything works except touch screen and stylus. That includes things like wireless network, bluetooth, keyboard, power profile, UI scaling for Hi-DPI and so on. Multi touch and pressure sensitive stylus works as well (sort of, see sections below) after installed linux-surface kernel. Battery life is good enough: about 5-6 hours of light usage like web browsing, PDF reading, and about 3 hours of video watching. (Just some estimated time from my experience, no serious benchmarking was done).</p>

<p>On the software side, automatic screen rotation is enabled on both distros I tried. KDE with EndeavourOS is very fast and responsive. When the keyboard is detached, it enters tablet mode which makes some UI larger and more user friendly with touch gestures. For example, you can just touch on a folder to open it in Dolphin instead of double click it.</p>

<p>For Gnome, it’s less responsive than KDE but the UI is really beautiful when used as a tablet. I was never a fan after Gnome 3 but I guess the UI changes it made makes more sense on a tablet than on a laptop or a desktop. The overall layout really reminds you about the iPad or Android tablet (in a good way), but with the power of a real desktop OS at the same time. I would really like it if it uses less resource.</p>

<p>Even though the overall experience is positive and has the potential to meet all my use cases, one serious problem made it very unusable and made me gave up Linux on Surface at the end.</p>

<h2 id="the-problems-in-both-distros">The Problems in Both Distros</h2>

<p>The deal breaker problem is touch recognition. The problem is in the surface-linux tools so it affects all the distros. The biggest problem is ghost touch: touches are registered randomly even when I do nothing. I tried a lot of workarounds including the ones mentioned in <a href="https://github.com/linux-surface/linux-surface/wiki/Surface-Pro-5">linux-surface’s wiki page</a>, but none of them actually resolved it completely. Sometimes it’s fixed after reboot but reappeared after next reboot. Sometimes it get fixed for a period of time but reappeared after a system upgrade. Sometimes the touch screen doesn’t work at all after resume from sleep. The randomness and the serious of the problem is really annoying so I gave up using it with Linux at last.</p>

<p>Other than the ghost touching, another big problem about touch recognition is palm rejection. It’s really annoying when draw things with the pen. In iptsd (surface-linux’s deamon for touch recognition), there is a configuration to disable touch screen when using a pen but it doesn’t work well. So it makes drawing very unusable.</p>

<p>Both KDE and Gnome has virtual keyboards when the physical keyboard is detached, and works most of the time despite the problems I’ll mention in the following sections. But if you have setup disk encryption with a password, there is no virtual keyboard when you input the disk password, so a physical keyboard is always needed during the boot. Which can be annoying but not really a deal breaker.</p>

<p>The last big problem is battery drain during sleep. It uses about 30% battery for one night even it has been put into sleep. I had similar issues for other laptops. I believe there maybe some configurations I can tune to fix that. But after I gave up Linux on it because of the ghost touch, I didn’t dig deeper into that.</p>

<p>Other than the problems shared by both distros, each distro/desktop environment also has their own problems.</p>

<h2 id="the-problems-in-kde-with-endeavouros">The Problems in KDE with EndeavourOS</h2>

<p>The biggest problem in KDE other than the ones I talked above, is the virtual keyboard. It’s buggy and not very stable. Sometimes it kept pop up and sometimes it doesn’t show up. It’s annoying especially at the login screen: if it’s not popped up you will still need a physical keyboard, which prevent it to be a real tablet. Sometimes when the keyboard is popped up, the panel at the bottom cannot be touched. The bugs happened randomly that makes it hard to be properly reported.</p>

<p>Another problem is the touch gesture for right click. Naturally, with a touch screen, long press should be treated like a right click. But that is not the case for KDE. So a lot of operations just cannot be done without a mouse when you need a right click.</p>

<p>Resize a window is also very tricky with touch only operation: you need to touch on the boarder precisely on the first try.</p>

<p>At last, the scroll behaviour is not very smooth. It makes me a little bit dizzy just by scrolling through web pages and PDFs.</p>

<p>So I thought give another distro and desktop environment a try, to see if they can resolve my problems.</p>

<h2 id="the-problems-in-gnome-with-fedora-workstation-40">The Problems in Gnome with Fedora Workstation 40</h2>

<p>I choose Fedora because it comes with Gnome, and I had good experience with it before. After the installation, the first impression is it’s much slower than KDE with EndeavourOS. I found it enables swap and ZRam by default so I disabled them. It’s better but still slower than KDE. It uses more memory at around 40-50% percentage while idel. And I got a lot of OOM kills which almost never happened with KDE on EndeavourOS.</p>

<p>Maybe because of the slowness, it’s also buggy for lots of operations. For example, when switch to the workspace view from PDF viewer with 4 fingers swipe up, the PDF keeps scrolling at the background. And when scroll in the file manager, the context menu keeps popping up.</p>

<p>Other than the slowness, there is a problem on the virtual keyboard as well: the backspace key doesn’t work properly. I found a workaround by install a third-party Gnome addon, but sometimes the old keyboard still popped up.</p>

<h2 id="go-back-to-windows-10">Go Back to Windows 10</h2>

<p>I’d say if the touch recognition works well enough, all the other problems are acceptable with KDE. But with those problems, I finally decided to fallback to Windows 10 again. It works well enough, just as I remembered from years ago. However I abandoned OneNotes and some other Microsoft products and use the following software instead:</p>

<ul>
  <li>Firefox as the browser.</li>
  <li>Nextcloud to sync the files.</li>
  <li>Samba for video sharing.</li>
  <li>Built in video player for local video playing.</li>
  <li>Krita for drawing and sketches.</li>
  <li>Drawboard PDF for PDF reading.</li>
</ul>

<p>It’s pretty disappointing that this device cannot be used with Linux properly. But using Windows is still better to just let the device sitting there doing nothing. Maybe I will re-evaluate it after Windows 10 is end of life next year.</p>]]></content><author><name></name></author><category term="Linux" /><category term="Surface" /><category term="Microsoft" /><category term="Operating system" /><category term="tech" /><summary type="html"><![CDATA[Background]]></summary></entry><entry><title type="html">Create a Checkbox That Returns Boolean Value for htmx</title><link href="https://www.binwang.me/2024-06-08-Create-a-Checkbox-That-Returns-Boolean-Value-for-htmx.html" rel="alternate" type="text/html" title="Create a Checkbox That Returns Boolean Value for htmx" /><published>2024-06-08T00:00:00-04:00</published><updated>2024-06-08T00:00:00-04:00</updated><id>https://www.binwang.me/Create-a-Checkbox-That-Returns-Boolean-Value-for-htmx</id><content type="html" xml:base="https://www.binwang.me/2024-06-08-Create-a-Checkbox-That-Returns-Boolean-Value-for-htmx.html"><![CDATA[<h2 id="the-problem-of-checkbox">The Problem of Checkbox</h2>

<p><a href="https://htmx.org/">htmx</a> is a lightweight Javascript framework. We all know in native HTML, a <code class="language-plaintext highlighter-rouge">form</code> element can send a HTTP request to a server with the values of <code class="language-plaintext highlighter-rouge">input</code> elements. In htmx, this feature is made more powerful and flexible: you can include the value of any element, and with the help with htmx extensions like <a href="https://htmx.org/extensions/json-enc/">json-enc</a>, it can also post JSON data.</p>

<p>However, there is one thing that htmx inherited from the native HTML form behaviour: for checkboxes, it only includes its value when the checkbox is checked. And the default value for checkbox is <code class="language-plaintext highlighter-rouge">"on"</code> instead of <code class="language-plaintext highlighter-rouge">true</code> (even though you can change it to another value). I understand this decision because it wants to keep the same behaviour so there is no surprise, but it also makes the backend parsing very inconvenient. The checkbox field needs some special treatment at the backend: you need to know there is a checkbox field so that you can set it to false when it’s not submitted with the request, and set it to true otherwise.</p>

<p>In this article, we will explore how to define a custom checkbox element so that it has a boolean value and will always be submitted with the HTTP request. We first explore the implementation for htmx and then for native HTML.</p>

<h2 id="how-htmx-submit-the-checkbox-value">How htmx Submit the Checkbox Value</h2>

<p>In order to make it work with htmx, we first need to know how htmx do the HTTP request with parameters. The document doesn’t have a lot of details but we can always check the source code. The code that processes input values is in the function <a href="https://github.com/bigskysoftware/htmx/blob/d6afc5b8dbd7213037d0bc4213aa0b7b469bcd62/src/htmx.js#L2549"><code class="language-plaintext highlighter-rouge">processInputValue</code></a>:</p>

<div class="language-javascript highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kd">function</span> <span class="nf">processInputValue</span><span class="p">(</span><span class="nx">processed</span><span class="p">,</span> <span class="nx">values</span><span class="p">,</span> <span class="nx">errors</span><span class="p">,</span> <span class="nx">elt</span><span class="p">,</span> <span class="nx">validate</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">if </span><span class="p">(</span><span class="nx">elt</span> <span class="o">==</span> <span class="kc">null</span> <span class="o">||</span> <span class="nf">haveSeenNode</span><span class="p">(</span><span class="nx">processed</span><span class="p">,</span> <span class="nx">elt</span><span class="p">))</span> <span class="p">{</span>
        <span class="k">return</span><span class="p">;</span>
    <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
        <span class="nx">processed</span><span class="p">.</span><span class="nf">push</span><span class="p">(</span><span class="nx">elt</span><span class="p">);</span>
    <span class="p">}</span>
    <span class="k">if </span><span class="p">(</span><span class="nf">shouldInclude</span><span class="p">(</span><span class="nx">elt</span><span class="p">))</span> <span class="p">{</span>
        <span class="kd">var</span> <span class="nx">name</span> <span class="o">=</span> <span class="nf">getRawAttribute</span><span class="p">(</span><span class="nx">elt</span><span class="p">,</span><span class="dl">"</span><span class="s2">name</span><span class="dl">"</span><span class="p">);</span>
        <span class="kd">var</span> <span class="nx">value</span> <span class="o">=</span> <span class="nx">elt</span><span class="p">.</span><span class="nx">value</span><span class="p">;</span>
        <span class="k">if </span><span class="p">(</span><span class="nx">elt</span><span class="p">.</span><span class="nx">multiple</span> <span class="o">&amp;&amp;</span> <span class="nx">elt</span><span class="p">.</span><span class="nx">tagName</span> <span class="o">===</span> <span class="dl">"</span><span class="s2">SELECT</span><span class="dl">"</span><span class="p">)</span> <span class="p">{</span>
            <span class="nx">value</span> <span class="o">=</span> <span class="nf">toArray</span><span class="p">(</span><span class="nx">elt</span><span class="p">.</span><span class="nf">querySelectorAll</span><span class="p">(</span><span class="dl">"</span><span class="s2">option:checked</span><span class="dl">"</span><span class="p">)).</span><span class="nf">map</span><span class="p">(</span><span class="nf">function </span><span class="p">(</span><span class="nx">e</span><span class="p">)</span> <span class="p">{</span> <span class="k">return</span> <span class="nx">e</span><span class="p">.</span><span class="nx">value</span> <span class="p">});</span>
        <span class="p">}</span>
        <span class="c1">// include file inputs</span>
        <span class="k">if </span><span class="p">(</span><span class="nx">elt</span><span class="p">.</span><span class="nx">files</span><span class="p">)</span> <span class="p">{</span>
            <span class="nx">value</span> <span class="o">=</span> <span class="nf">toArray</span><span class="p">(</span><span class="nx">elt</span><span class="p">.</span><span class="nx">files</span><span class="p">);</span>
        <span class="p">}</span>
        <span class="nf">addValueToValues</span><span class="p">(</span><span class="nx">name</span><span class="p">,</span> <span class="nx">value</span><span class="p">,</span> <span class="nx">values</span><span class="p">);</span>
        <span class="k">if </span><span class="p">(</span><span class="nx">validate</span><span class="p">)</span> <span class="p">{</span>
            <span class="nf">validateElement</span><span class="p">(</span><span class="nx">elt</span><span class="p">,</span> <span class="nx">errors</span><span class="p">);</span>
        <span class="p">}</span>
    <span class="p">}</span>
    <span class="k">if </span><span class="p">(</span><span class="nf">matches</span><span class="p">(</span><span class="nx">elt</span><span class="p">,</span> <span class="dl">'</span><span class="s1">form</span><span class="dl">'</span><span class="p">))</span> <span class="p">{</span>
        <span class="kd">var</span> <span class="nx">inputs</span> <span class="o">=</span> <span class="nx">elt</span><span class="p">.</span><span class="nx">elements</span><span class="p">;</span>
        <span class="nf">forEach</span><span class="p">(</span><span class="nx">inputs</span><span class="p">,</span> <span class="kd">function</span><span class="p">(</span><span class="nx">input</span><span class="p">)</span> <span class="p">{</span>
            <span class="nf">processInputValue</span><span class="p">(</span><span class="nx">processed</span><span class="p">,</span> <span class="nx">values</span><span class="p">,</span> <span class="nx">errors</span><span class="p">,</span> <span class="nx">input</span><span class="p">,</span> <span class="nx">validate</span><span class="p">);</span>
        <span class="p">});</span>
    <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div>

<p>So it checks whether the element should be included through function <code class="language-plaintext highlighter-rouge">shouldInclude(elt)</code> and get its value if so (some additional logic for <code class="language-plaintext highlighter-rouge">select</code> and <code class="language-plaintext highlighter-rouge">file</code> but it’s not a concern here). In <a href="https://github.com/bigskysoftware/htmx/blob/d6afc5b8dbd7213037d0bc4213aa0b7b469bcd62/src/htmx.js#L2512"><code class="language-plaintext highlighter-rouge">shouldInclude</code></a>, it will only include a checkbox if it’s checked:</p>

<div class="language-javascript highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kd">function</span> <span class="nf">shouldInclude</span><span class="p">(</span><span class="nx">elt</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">if</span><span class="p">(</span><span class="nx">elt</span><span class="p">.</span><span class="nx">name</span> <span class="o">===</span> <span class="dl">""</span> <span class="o">||</span> <span class="nx">elt</span><span class="p">.</span><span class="nx">name</span> <span class="o">==</span> <span class="kc">null</span> <span class="o">||</span> <span class="nx">elt</span><span class="p">.</span><span class="nx">disabled</span> <span class="o">||</span> <span class="nf">closest</span><span class="p">(</span><span class="nx">elt</span><span class="p">,</span> <span class="dl">"</span><span class="s2">fieldset[disabled]</span><span class="dl">"</span><span class="p">))</span> <span class="p">{</span>
        <span class="k">return</span> <span class="kc">false</span><span class="p">;</span>
    <span class="p">}</span>
    <span class="c1">// ignore "submitter" types (see jQuery src/serialize.js)</span>
    <span class="k">if </span><span class="p">(</span><span class="nx">elt</span><span class="p">.</span><span class="nx">type</span> <span class="o">===</span> <span class="dl">"</span><span class="s2">button</span><span class="dl">"</span> <span class="o">||</span> <span class="nx">elt</span><span class="p">.</span><span class="nx">type</span> <span class="o">===</span> <span class="dl">"</span><span class="s2">submit</span><span class="dl">"</span> <span class="o">||</span> <span class="nx">elt</span><span class="p">.</span><span class="nx">tagName</span> <span class="o">===</span> <span class="dl">"</span><span class="s2">image</span><span class="dl">"</span> <span class="o">||</span> <span class="nx">elt</span><span class="p">.</span><span class="nx">tagName</span> <span class="o">===</span> <span class="dl">"</span><span class="s2">reset</span><span class="dl">"</span> <span class="o">||</span> <span class="nx">elt</span><span class="p">.</span><span class="nx">tagName</span> <span class="o">===</span> <span class="dl">"</span><span class="s2">file</span><span class="dl">"</span> <span class="p">)</span> <span class="p">{</span>
        <span class="k">return</span> <span class="kc">false</span><span class="p">;</span>
    <span class="p">}</span>
    <span class="k">if </span><span class="p">(</span><span class="nx">elt</span><span class="p">.</span><span class="nx">type</span> <span class="o">===</span> <span class="dl">"</span><span class="s2">checkbox</span><span class="dl">"</span> <span class="o">||</span> <span class="nx">elt</span><span class="p">.</span><span class="nx">type</span> <span class="o">===</span> <span class="dl">"</span><span class="s2">radio</span><span class="dl">"</span> <span class="p">)</span> <span class="p">{</span>
        <span class="k">return</span> <span class="nx">elt</span><span class="p">.</span><span class="nx">checked</span><span class="p">;</span>
    <span class="p">}</span>
    <span class="k">return</span> <span class="kc">true</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div>

<h2 id="create-a-custom-checkbox-element-with-web-component">Create a Custom Checkbox Element with Web Component</h2>

<p>I tried to find or write an extension for htmx to include checkbox elements with boolean values, but from what I learnt in <a href="https://htmx.org/extensions/">the htmx extension doc</a>, there is no good way to do that. So I decided to create a custom HTML element that extends <code class="language-plaintext highlighter-rouge">input</code> to return boolean values for htmx to get.</p>

<p>With <a href="https://developer.mozilla.org/en-US/docs/Web/API/Web_components#attributechangedcallback">web component</a>, we can create a HTML tag that can be used just like any other built-in HTML tags. The <a href="https://developer.mozilla.org/en-US/docs/Web/API/Web_components/Using_custom_elements">MDN guide</a> does a good job to explain how to do it so I will not repeat it here. I’ll just put my implementation of the customized checkbox here:</p>

<div class="language-javascript highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kd">class</span> <span class="nc">BooleanCheckbox</span> <span class="kd">extends</span> <span class="nc">HTMLInputElement</span> <span class="p">{</span>
    <span class="nf">constructor</span><span class="p">()</span> <span class="p">{</span>
        <span class="k">super</span><span class="p">();</span>
    <span class="p">}</span>

    <span class="kd">get</span> <span class="nf">checked</span><span class="p">()</span> <span class="p">{</span>
        <span class="k">return</span> <span class="kc">true</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="kd">get</span> <span class="nf">value</span><span class="p">()</span> <span class="p">{</span>
        <span class="k">if </span><span class="p">(</span><span class="k">super</span><span class="p">.</span><span class="nx">checked</span><span class="p">)</span> <span class="p">{</span>
            <span class="k">return</span> <span class="kc">true</span><span class="p">;</span>
        <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
            <span class="k">return</span> <span class="kc">false</span><span class="p">;</span>
        <span class="p">}</span>
    <span class="p">}</span>
<span class="p">}</span>

<span class="nx">customElements</span><span class="p">.</span><span class="nf">define</span><span class="p">(</span><span class="dl">"</span><span class="s2">boolean-checkbox</span><span class="dl">"</span><span class="p">,</span> <span class="nx">BooleanCheckbox</span><span class="p">,</span> <span class="p">{</span> <span class="na">extends</span><span class="p">:</span> <span class="dl">"</span><span class="s2">input</span><span class="dl">"</span> <span class="p">});</span>
</code></pre></div></div>

<p>You can see it’s very simple. It extends the <code class="language-plaintext highlighter-rouge">input</code> element. It overwrite <code class="language-plaintext highlighter-rouge">checked</code> to always return <code class="language-plaintext highlighter-rouge">true</code> so that htmx will always include it in the request. And for <code class="language-plaintext highlighter-rouge">value</code>, it returns a boolean depends on <code class="language-plaintext highlighter-rouge">super.checked</code>. At last it register the customized element as a tag namedj<code class="language-plaintext highlighter-rouge">boolean-checkbox</code>, so that we can just use it like this in HTML:</p>

<div class="language-html highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nt">&lt;input</span> <span class="na">type=</span><span class="s">"checkbox"</span> <span class="na">is=</span><span class="s">"boolean-checkbox"</span> <span class="nt">/&gt;</span>Boolean checkbox
</code></pre></div></div>

<p>The <code class="language-plaintext highlighter-rouge">is="boolean-checkbox"</code> part tells the browser that this is a customized input element.</p>

<p>Here is a complete example:</p>

<div class="language-html highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">&lt;!DOCTYPE html&gt;</span>
<span class="nt">&lt;html&gt;</span>
  <span class="nt">&lt;head&gt;</span>
    <span class="nt">&lt;title&gt;</span>htmx boolean checkbox example<span class="nt">&lt;/title&gt;</span>
    <span class="nt">&lt;script </span><span class="na">src=</span><span class="s">"https://unpkg.com/htmx.org@1.9.12"</span><span class="nt">&gt;&lt;/script&gt;</span>
    <span class="nt">&lt;script </span><span class="na">src=</span><span class="s">"https://unpkg.com/htmx.org@1.9.12/dist/ext/json-enc.js"</span><span class="nt">&gt;&lt;/script&gt;</span>
    <span class="nt">&lt;script&gt;</span>
      <span class="kd">class</span> <span class="nc">BooleanCheckbox</span> <span class="kd">extends</span> <span class="nc">HTMLInputElement</span> <span class="p">{</span>
          <span class="nf">constructor</span><span class="p">()</span> <span class="p">{</span>
              <span class="k">super</span><span class="p">();</span>
          <span class="p">}</span>

          <span class="kd">get</span> <span class="nf">checked</span><span class="p">()</span> <span class="p">{</span>
              <span class="k">return</span> <span class="kc">true</span><span class="p">;</span>
          <span class="p">}</span>

          <span class="kd">get</span> <span class="nf">value</span><span class="p">()</span> <span class="p">{</span>
              <span class="k">if </span><span class="p">(</span><span class="k">super</span><span class="p">.</span><span class="nx">checked</span><span class="p">)</span> <span class="p">{</span>
                  <span class="k">return</span> <span class="kc">true</span><span class="p">;</span>
              <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
                  <span class="k">return</span> <span class="kc">false</span><span class="p">;</span>
              <span class="p">}</span>
          <span class="p">}</span>
      <span class="p">}</span>
      <span class="nx">customElements</span><span class="p">.</span><span class="nf">define</span><span class="p">(</span><span class="dl">"</span><span class="s2">boolean-checkbox</span><span class="dl">"</span><span class="p">,</span> <span class="nx">BooleanCheckbox</span><span class="p">,</span> <span class="p">{</span> <span class="na">extends</span><span class="p">:</span> <span class="dl">"</span><span class="s2">input</span><span class="dl">"</span> <span class="p">});</span>
    <span class="nt">&lt;/script&gt;</span>
  <span class="nt">&lt;/head&gt;</span>

  <span class="nt">&lt;body&gt;</span>
    <span class="nt">&lt;form&gt;</span>
      <span class="nt">&lt;div&gt;&lt;input</span> <span class="na">type=</span><span class="s">"checkbox"</span> <span class="na">name=</span><span class="s">"default-checkbox"</span> <span class="nt">/&gt;</span>Default checkbox<span class="nt">&lt;/div&gt;</span>
      <span class="nt">&lt;div&gt;&lt;input</span> <span class="na">type=</span><span class="s">"checkbox"</span> <span class="na">is=</span><span class="s">"boolean-checkbox"</span> <span class="na">name=</span><span class="s">"boolean-checkbox"</span> <span class="nt">/&gt;</span>Boolean checkbox<span class="nt">&lt;/div&gt;</span>
      <span class="nt">&lt;button</span> <span class="na">hx-post=</span><span class="s">"test-post"</span> <span class="na">hx-ext=</span><span class="s">"json-enc"</span><span class="nt">&gt;</span>Submit<span class="nt">&lt;/button&gt;</span>
    <span class="nt">&lt;/form&gt;</span>
  <span class="nt">&lt;/body&gt;</span>
<span class="nt">&lt;/html&gt;</span>
</code></pre></div></div>

<p>It defines two checkboxes: a native one and a customized one. We use the <code class="language-plaintext highlighter-rouge">json-enc</code> extension so it will post JSON as request body. When click the submit button, if both of them are unchecked, the post body looks like this:</p>

<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="nl">"boolean-checkbox"</span><span class="p">:</span><span class="kc">false</span><span class="p">}</span><span class="w">
</span></code></pre></div></div>

<p>And if both are selected, here is the post body:</p>

<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="nl">"default-checkbox"</span><span class="p">:</span><span class="s2">"on"</span><span class="p">,</span><span class="nl">"boolean-checkbox"</span><span class="p">:</span><span class="kc">true</span><span class="p">}</span><span class="w">
</span></code></pre></div></div>

<h2 id="what-about-the-native-html-form-action">What About the Native HTML Form Action</h2>

<p>The custom element <code class="language-plaintext highlighter-rouge">boolean-checkbox</code> only works with htmx to post boolean values. If you use native form action like this:</p>

<div class="language-html highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nt">&lt;form</span> <span class="na">action=</span><span class="s">"test-call"</span><span class="nt">&gt;</span>
  <span class="nt">&lt;input</span> <span class="na">is=</span><span class="s">"boolean-checkbox"</span> <span class="na">type=</span><span class="s">"checkbox"</span> <span class="na">name=</span><span class="s">"boolean-checkbox"</span><span class="nt">&gt;</span>Boolean Checkbox<span class="nt">&lt;/input&gt;</span>
  <span class="nt">&lt;button&gt;</span>Submit<span class="nt">&lt;/button&gt;</span>
<span class="nt">&lt;/form&gt;</span>
</code></pre></div></div>

<p>The behaviour is still like the native checkbox, which only posts value “on” when it’s checked.</p>

<p>Even though I don’t use the native form action, it still makes me wonder if I can support it. (Disclaimer: all the code below are experiments and I don’t recommend anyone uses it on production without careful tests.)</p>

<p>In fact, there is a way to set form value in web component through <a href="https://developer.mozilla.org/en-US/docs/Web/API/ElementInternals/setFormValue"><code class="language-plaintext highlighter-rouge">ElementInternals.setFormValue</code></a>:</p>

<div class="language-javascript highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">this</span><span class="p">.</span><span class="nx">internals</span> <span class="o">=</span> <span class="k">this</span><span class="p">.</span><span class="nf">attachInternals</span><span class="p">();</span>
<span class="k">this</span><span class="p">.</span><span class="nx">internals</span><span class="p">.</span><span class="nf">setFormValue</span><span class="p">(</span><span class="k">this</span><span class="p">.</span><span class="nx">value</span><span class="p">);</span>
</code></pre></div></div>

<p>However, in HTML standard, <code class="language-plaintext highlighter-rouge">ElementInternals</code> is not supported if the custom element is extending a built-in input element. Actually there is a <a href="https://github.com/whatwg/html/issues/5166">Github issue</a> asking for this feature, and the response to not support it doesn’t make sense to me:</p>

<blockquote>
  <p>Since Apple’s WebKit team’s position is that customized builtins shouldn’t exist in the first place, we don’t support this proposal.</p>
</blockquote>

<p>Anyway, it is what it is. So I need to workaround it. The solution I came up is to include another checkbox element as a child instead of inherit it. Here is the code:</p>

<div class="language-javascript highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kd">class</span> <span class="nc">BooleanCheckbox</span> <span class="kd">extends</span> <span class="nc">HTMLElement</span> <span class="p">{</span>

    <span class="kd">static</span> <span class="nx">formAssociated</span> <span class="o">=</span> <span class="kc">true</span><span class="p">;</span>

    <span class="nf">constructor</span><span class="p">()</span> <span class="p">{</span>
        <span class="k">super</span><span class="p">();</span>
        <span class="k">this</span><span class="p">.</span><span class="nx">internals</span> <span class="o">=</span> <span class="k">this</span><span class="p">.</span><span class="nf">attachInternals</span><span class="p">();</span>
    <span class="p">}</span>

    <span class="nf">connectedCallback</span><span class="p">()</span> <span class="p">{</span>
        <span class="k">this</span><span class="p">.</span><span class="nx">shadow</span> <span class="o">=</span> <span class="k">this</span><span class="p">.</span><span class="nf">attachShadow</span><span class="p">({</span><span class="na">mode</span><span class="p">:</span> <span class="dl">"</span><span class="s2">open</span><span class="dl">"</span><span class="p">});</span>
        <span class="kd">const</span> <span class="nx">internalCheckbox</span> <span class="o">=</span> <span class="nb">document</span><span class="p">.</span><span class="nf">createElement</span><span class="p">(</span><span class="dl">"</span><span class="s2">input</span><span class="dl">"</span><span class="p">);</span>
        <span class="nx">internalCheckbox</span><span class="p">.</span><span class="nf">setAttribute</span><span class="p">(</span><span class="dl">"</span><span class="s2">type</span><span class="dl">"</span><span class="p">,</span> <span class="dl">"</span><span class="s2">checkbox</span><span class="dl">"</span><span class="p">);</span>
        <span class="k">this</span><span class="p">.</span><span class="nf">getAttributeNames</span><span class="p">().</span><span class="nf">forEach</span><span class="p">((</span><span class="nx">name</span><span class="p">)</span> <span class="o">=&gt;</span> <span class="p">{</span>
            <span class="nx">internalCheckbox</span><span class="p">.</span><span class="nf">setAttribute</span><span class="p">(</span><span class="nx">name</span><span class="p">,</span> <span class="k">this</span><span class="p">.</span><span class="nf">getAttribute</span><span class="p">(</span><span class="nx">name</span><span class="p">));</span>
        <span class="p">});</span>
        <span class="k">this</span><span class="p">.</span><span class="nx">shadow</span><span class="p">.</span><span class="nf">appendChild</span><span class="p">(</span><span class="nx">internalCheckbox</span><span class="p">);</span>
        <span class="k">this</span><span class="p">.</span><span class="nx">internals</span><span class="p">.</span><span class="nf">setFormValue</span><span class="p">(</span><span class="nx">internalCheckbox</span><span class="p">.</span><span class="nx">value</span><span class="p">);</span>
        <span class="nx">internalCheckbox</span><span class="p">.</span><span class="nf">addEventListener</span><span class="p">(</span><span class="dl">'</span><span class="s1">change</span><span class="dl">'</span><span class="p">,</span> <span class="p">()</span> <span class="o">=&gt;</span> <span class="p">{</span>
            <span class="k">this</span><span class="p">.</span><span class="nx">internals</span><span class="p">.</span><span class="nf">setFormValue</span><span class="p">(</span><span class="k">this</span><span class="p">.</span><span class="nx">value</span><span class="p">);</span>
        <span class="p">});</span>
    <span class="p">}</span>

    <span class="kd">get</span> <span class="nf">checkbox</span><span class="p">()</span> <span class="p">{</span>
        <span class="k">return</span> <span class="k">this</span><span class="p">.</span><span class="nx">shadow</span><span class="p">.</span><span class="nf">querySelector</span><span class="p">(</span><span class="dl">"</span><span class="s2">input[type=checkbox]</span><span class="dl">"</span><span class="p">);</span>
    <span class="p">}</span>


    <span class="kd">get</span> <span class="nf">checked</span><span class="p">()</span> <span class="p">{</span>
        <span class="k">return</span> <span class="kc">true</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="kd">get</span> <span class="nf">value</span><span class="p">()</span> <span class="p">{</span>
        <span class="k">if </span><span class="p">(</span><span class="k">this</span><span class="p">.</span><span class="nx">checkbox</span><span class="p">.</span><span class="nx">checked</span><span class="p">)</span> <span class="p">{</span>
            <span class="k">return</span> <span class="kc">true</span><span class="p">;</span>
        <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
            <span class="k">return</span> <span class="kc">false</span><span class="p">;</span>
        <span class="p">}</span>
    <span class="p">}</span>

<span class="p">}</span>

<span class="nx">customElements</span><span class="p">.</span><span class="nf">define</span><span class="p">(</span><span class="dl">"</span><span class="s2">boolean-checkbox</span><span class="dl">"</span><span class="p">,</span> <span class="nx">BooleanCheckbox</span><span class="p">);</span>
</code></pre></div></div>

<p>It listens on the <code class="language-plaintext highlighter-rouge">checked</code> attribute on the child checkbox and update the form value based on it. <code class="language-plaintext highlighter-rouge">static formAssociated = true;</code> is needed so that we can set form values.</p>

<p>Then in HTML, we can use it like this:</p>

<div class="language-html highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nt">&lt;form</span> <span class="na">action=</span><span class="s">"/test-call"</span><span class="nt">&gt;</span>
  <span class="nt">&lt;div&gt;&lt;input</span> <span class="na">type=</span><span class="s">"checkbox"</span> <span class="na">name=</span><span class="s">"default-checkbox"</span> <span class="nt">/&gt;</span>Default Checkbox<span class="nt">&lt;/div&gt;</span>
  <span class="nt">&lt;div&gt;&lt;boolean-checkbox</span> <span class="na">name=</span><span class="s">"boolean-checkbox"</span><span class="nt">&gt;&lt;/boolean-checkbox&gt;</span>Boolean Checkbox<span class="nt">&lt;/div&gt;</span>
  <span class="nt">&lt;div&gt;&lt;button&gt;</span>Submit<span class="nt">&lt;/button&gt;&lt;/div&gt;</span>
<span class="nt">&lt;/form&gt;</span>
</code></pre></div></div>

<p>When click the submit button, it calls <code class="language-plaintext highlighter-rouge">/test-call?boolean-checkbox=false</code> if both checkboxes are unchecked and <code class="language-plaintext highlighter-rouge">/test-call?default-checkbox=on&amp;boolean-checkbox=true</code> if both are checked.</p>]]></content><author><name></name></author><category term="HTML" /><category term="htmx" /><category term="Javascript" /><category term="frontend" /><category term="tech" /><summary type="html"><![CDATA[The Problem of Checkbox]]></summary></entry><entry><title type="html">Random Playlists for Self Hosted Videos</title><link href="https://www.binwang.me/2024-06-03-Random-Video-Playlists-for-Self-Hosted-Videos.html" rel="alternate" type="text/html" title="Random Playlists for Self Hosted Videos" /><published>2024-06-03T00:00:00-04:00</published><updated>2024-06-03T00:00:00-04:00</updated><id>https://www.binwang.me/Random-Video-Playlists-for-Self-Hosted-Videos</id><content type="html" xml:base="https://www.binwang.me/2024-06-03-Random-Video-Playlists-for-Self-Hosted-Videos.html"><![CDATA[<p>With the development of computer systems and online streaming services, it’s never easier to play TV shows or movies on demand. There are some shows that I watch over and over when I want to relax. But the action of finding a show and selecting an episode makes it less causal. To some extent, I miss the old days to causally open a TV channel just to watch some random things. In this article, I will explain my journey to achieve that. More specifically, I want something like this:</p>

<ul>
  <li>Be able to add videos into collections and play videos randomly from a collection.</li>
  <li>Be able to share the collections and videos to other devices including:
    <ul>
      <li>Other desktops and laptops, including Linux and MacOS.</li>
      <li>Mobile devices including Android and iOS.</li>
      <li>TVs like Android TV box.</li>
    </ul>
  </li>
  <li>No transcoding on the server.</li>
  <li>The solution needs to be self hosted, free and open.</li>
</ul>

<p>I think I need to add more details about “no transcoding on the server” since a lot of solutions need that. All my devices are compatible to play the formats in my video collection. So it’s a waste of resource to do another transcoding on the server, especially my video server is also the desktop PC I use the most everyday. If this is not a requirement to you, you may be able to find much better solutions. That’s why I listed everything I’ve tried so it may help someone even it’s not the solution I chose at last.</p>

<p>So here you go. If you just want to see my final solution, go to the last section.</p>

<h2 id="ersatztv">ErsatzTV</h2>

<p><a href="https://ersatztv.org/">ErsatzTV</a> is a self hosted service to create live TV channels and stream them. You can add videos to collections, and put them into schedules. It works very much like a real TV channel. It has a Docker image and doesn’t need any external databases, so it’s really easy to try it out. Once you create channels it can generate m3u8 playlists so that you can stream it on any client that supports it.</p>

<p>It has great features. However, without transcoding on the server and use HLS Direct to stream the videos, there are some problems: I cannot open the stream in VLC. I could open it in Jellyfin, but once it jumps to another video with different format, it stops playing. I need to restart the client which is very annoying.</p>

<h2 id="jellyfin">Jellyfin</h2>

<p><a href="https://jellyfin.org/">Jellyfin</a> is a very popular media server. It’s like the more popular <a href="https://www.plex.tv/">Plex</a> but is free and open source. I was never a fan of Plex since it just doesn’t feel right to self host something you cannot really control. Jellyfin has gone a long way since I tried it a few years ago. You can add TV shows and movies to collections and play random videos from there. Even though it’s not as powerful as the schedule feature in ErsatzTV, it’s still great for my use case.</p>

<p>However, it falls short on “no transcoding on server” part again. The web client can only play a very limited video format. Its Linux client can play most video formats fairly well, but I still need my mobile devices be able to play the videos. The official Android and iOS clients are not any better than the web client. A third party iOS client <a href="https://github.com/jellyfin/Swiftfin">Swiftlin</a> does much better, but somehow it cannot play from a collection.</p>

<h2 id="kodi-with-samba">Kodi with Samba</h2>

<p>I use Kodi on my Android TV box all the time. The videos are shared through Samba. Kodi has <a href="https://kodi.wiki/view/Add-on:Play_Random_Videos">an offical add-on</a> to play random videos from TV shows, movies, folders and so on. However Kodi doesn’t have the concept of collection. It has playlist but it’s very hard to use. In theory you can symbol link all the videos to different folders as collections and play from there, but it’s too hacky. Kodi has an iOS client but it’s not in App Store so it needs to be compiled and resigned every a few days.</p>

<p>While I was exploring these ideas, I realized even Kodi doesn’t have any good built in playlist or collection feature, there are some file formats for video playlists. With that, we can even use other video clients. m3u file came to mind at first but the videos paths should be relative paths so it can be played from any device even though the mount point is different. At last I found <a href="https://en.wikipedia.org/wiki/XML_Shareable_Playlist_Format">XSPF</a> which allows relative path for the videos. With that, I came up with my final solution.</p>

<h2 id="xspf-playlist-on-samba-with-kodi-and-vlc">XSPF Playlist on Samba with Kodi and VLC</h2>

<p>So based on my exploration above, I came out an idea to use XSPF playlist to create collections. I just put the XSPF files in my videos folder to share through Samba together. Since the video paths are relative in the playlist, once you mount the Samba folder on other devices, you can just click the playlist and play it through supported clients.</p>

<p>For the clients, I use Kodi on the Android TV box and VLC on other devices. For Kodi, once <a href="https://kodi.wiki/view/Add-on:Play_Random_Videos">Play Random Videos add-on</a> is installed, you can long press on the playlist file to play a random video. VLC on desktops <a href="https://superuser.com/a/1808182">can be configured</a> to always play videos randomly from a playlist. On Android, there is an option to shuffle play once you open the playlist. But strangely, the VLC on my iPad is not able to play the XSPF file. I may dig into that in the future but it’s good enough for me now.</p>

<p>The only part left is to create the XSPF playlist. It’s a xml file so you can edit it manually but that takes too much time. So I created a Scala script to add or remove videos from a folder. Even though I used Scala for a long time and write my side projects with it, it’s the first time I use it as scripting and it’s such a pleasant with the help of <a href="https://ammonite.io/">Ammonite</a>. The script is on <a href="https://github.com/wb14123/xspf-editor">Github</a> so that you can also use it if needed.</p>]]></content><author><name></name></author><category term="video" /><category term="selfhost" /><category term="vlc" /><category term="kodi" /><category term="media" /><summary type="html"><![CDATA[With the development of computer systems and online streaming services, it’s never easier to play TV shows or movies on demand. There are some shows that I watch over and over when I want to relax. But the action of finding a show and selecting an episode makes it less causal. To some extent, I miss the old days to causally open a TV channel just to watch some random things. In this article, I will explain my journey to achieve that. More specifically, I want something like this:]]></summary></entry><entry><title type="html">Make Flutter Web Apps More Native Like</title><link href="https://www.binwang.me/2024-04-18-Make-Flutter-Web-App-More-Native-Like.html" rel="alternate" type="text/html" title="Make Flutter Web Apps More Native Like" /><published>2024-04-18T00:00:00-04:00</published><updated>2024-04-18T00:00:00-04:00</updated><id>https://www.binwang.me/Make-Flutter-Web-App-More-Native-Like</id><content type="html" xml:base="https://www.binwang.me/2024-04-18-Make-Flutter-Web-App-More-Native-Like.html"><![CDATA[<h2 id="background">Background</h2>

<p>I’ve built the client app of <a href="https://rssbrain.com">RSS Brain</a> with Flutter so that I don’t need to write different code for different platforms. It’s a pleasant to write Flutter code. And the app works good enough for Android and iOS. However, Flutter web support is a different story. You can feel the app is just not a normal website. I’m not satisfy with that. After attempts to make it more like a native web page and failed, I’m rewriting it with web technology again. That’s why the <a href="/2024-03-26-Prevent-HTMX-Lazy-Loaded-Content-From-Reload.html">last blog post</a> is about htmx.</p>

<p>Before I move on, I’d like to record what I have tried, as a note for myself and hopefully it can also help someone else. It’s really sad this article as my first blog about Flutter, maybe the only one for a long time.</p>

<h2 id="how-flutter-renders-a-web-page">How Flutter Renders a Web Page</h2>

<p>In Flutter, you define the UI widgets in Dart. And Flutter the engine will parse the widgets and render it to different targets: iOS, Android, web and even Windows and Linux applications. In principle, I think that is a good idea and I really enjoy writing Flutter code compared to Javascript frameworks like AngularJS or ReactJS. It’s really unfortunate the web support is not good enough to me.</p>

<p>The core problem is how Flutter renders the web pages. We all know a web page is represented in HTML. Even if we don’t write HTML directly but use a Javascript framework, it is manipulating HTML tags at the end. Flutter renders widgets to different HTML elements like <code class="language-plaintext highlighter-rouge">div</code> at first. However, it was later changed to draw all the widgets in a canvas. (The old render method is still available through <code class="language-plaintext highlighter-rouge">--web-render html</code> but I encountered multiple bugs and seems it’s given less and less care). This makes Flutter web apps doesn’t really behave like a native app, because a normal web page doesn’t have everything in a canvas.</p>

<p>For the problems it brings, I found solutions for some of them. For some others, I didn’t find one. The sections below are some of the problems and some of the solutions.</p>

<h2 id="make-text-selectable">Make Text Selectable</h2>

<p>By default, the text in Flutter app is not selectable. You can use the <a href="https://api.flutter.dev/flutter/material/SelectableText-class.html">SeletableText</a> widget to make text selectable.</p>

<h2 id="make-links-and-buttons-recognized-by-browser">Make Links And Buttons Recognized by Browser</h2>

<p>I use <a href="https://vimium.github.io/">Vimium</a> heavily. But Flutter rendering all the content into a canvas makes the clickable links and buttons not recognized by the browser, thus makes Vimium not working. This is a deal breaker for me, especially it’s something I built that breaks my workflow.</p>

<p>I found a solution at the end to make links and buttons recognizable. It can be done by enabling semantics support. Add this line in the main function after <code class="language-plaintext highlighter-rouge">runApp</code>:</p>

<div class="language-dart highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">SemanticsBinding</span><span class="o">.</span><span class="na">instance</span><span class="o">.</span><span class="na">ensureSemantics</span><span class="p">();</span>
</code></pre></div></div>

<p>This will render extra information in HTML instead of only drawing the canvas. It will make widgets like <code class="language-plaintext highlighter-rouge">Button</code> recognizable.</p>

<p>However, if you are using something more lower level like <code class="language-plaintext highlighter-rouge">GestureDetector</code>, you need to wrap the widgets with <code class="language-plaintext highlighter-rouge">Semantics</code>. Here is an example:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Semantics(button: true, enabled: true, child: myCustomClickable)
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">myCustomClickable</code> will be recognized as a clickable element with that.</p>

<h2 id="scrolling-behaviour">Scrolling Behaviour</h2>

<p>The scrolling feels choppy sometimes. And because the browser has no idea about the scroll position of the page, it just makes the scrolling behaviour feels different. For example, <a href="https://github.com/flutter/flutter/issues/69529">here</a> is a Github issue opened 4 years ago describing this kind of problem and is still not resolved. For me, this is the last straw to make me give up Flutter, since it breaks scrolling keyboard shortcuts of Vimium.</p>

<h2 id="conclusion">Conclusion</h2>

<p>The idea behind Flutter is great. I hope the web support can be better and better so that I can finally come back to it one day. But for now, I cannot wait for it and need to take another route. Stay tuned for more updates about that journey.</p>]]></content><author><name></name></author><category term="Flutter" /><category term="web" /><category term="UI" /><category term="Dart" /><summary type="html"><![CDATA[Background]]></summary></entry><entry><title type="html">Prevent htmx Lazy Loaded Content From Reloading</title><link href="https://www.binwang.me/2024-03-26-Prevent-HTMX-Lazy-Loaded-Content-From-Reload.html" rel="alternate" type="text/html" title="Prevent htmx Lazy Loaded Content From Reloading" /><published>2024-03-26T00:00:00-04:00</published><updated>2024-03-26T00:00:00-04:00</updated><id>https://www.binwang.me/Prevent-HTMX-Lazy-Loaded-Content-From-Reload</id><content type="html" xml:base="https://www.binwang.me/2024-03-26-Prevent-HTMX-Lazy-Loaded-Content-From-Reload.html"><![CDATA[<p>This is a short article about some tricks in <a href="https://htmx.org">htmx</a>. I have more to say about htmx but I’ll save that to another blog. In this one, I will skip the basics about htmx and assume you already know that.</p>

<h2 id="1-problem">1. Problem</h2>

<p>I’ll briefly introduce two features of htmx in order the explain the problem. You can go to official website for more details about the features.</p>

<h3 id="11-browser-history">1.1. Browser History</h3>

<p>htmx has <a href="https://htmx.org/docs/#history">a feature to interact with browser history</a>. Here is an example in the official document:</p>

<div class="language-html highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nt">&lt;a</span> <span class="na">hx-get=</span><span class="s">"/blog"</span> <span class="na">hx-push-url=</span><span class="s">"true"</span><span class="nt">&gt;</span>Blog<span class="nt">&lt;/a&gt;</span>
</code></pre></div></div>

<p>This will change the url in browser to <code class="language-plaintext highlighter-rouge">/blog</code> when you click the link and save a snapshot of current page into local storage. When you click back button in browser, htmx will try to find the cache in local storage, and swap it out so you don’t need to reload the whole page.</p>

<h3 id="12-lazy-load">1.2. Lazy Load</h3>

<p>htmx sends requests when an event is triggered on an element. The rule is defined by <a href="https://htmx.org/attributes/hx-trigger/">hx-trigger</a> attribute. There are some special events can be used for lazy loading:</p>

<ul>
  <li>load - triggered on load (useful for lazy-loading something).</li>
  <li>revealed - triggered when an element is scrolled into the viewport (also useful for lazy-loading).</li>
  <li>intersect - fires once when an element first intersects the viewport.</li>
</ul>

<p>However, when combined this with history support, the lazy loaded elements will be requested again when the pages are navigated in history. Here is an example:</p>

<div class="language-html highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nt">&lt;a</span> <span class="na">hx-get=</span><span class="s">"/page1"</span> <span class="na">hx-push-url=</span><span class="s">"true"</span> <span class="na">hx-target=</span><span class="s">"#content"</span><span class="nt">&gt;</span>page1<span class="nt">&lt;/a&gt;</span>
<span class="nt">&lt;div</span> <span class="na">id=</span><span class="s">"content"</span> <span class="na">hx-get=</span><span class="s">"/content"</span> <span class="na">hx-trigger=</span><span class="s">"load"</span><span class="nt">&gt;&lt;/div&gt;</span>
</code></pre></div></div>

<p>When you click on <code class="language-plaintext highlighter-rouge">page1</code>, it will replace <code class="language-plaintext highlighter-rouge">#content</code> with the response from <code class="language-plaintext highlighter-rouge">/page1</code> and change the URL. However, when you click on back in browser, htmx will send a request to <code class="language-plaintext highlighter-rouge">/content</code> again even though it’s already in history cache, because technically, <code class="language-plaintext highlighter-rouge">#content</code> <strong>is</strong> loaded again so <code class="language-plaintext highlighter-rouge">hx-get</code> is triggered based on <code class="language-plaintext highlighter-rouge">hx-trigger</code> rule. This results a waste of resource and can sometimes make the webpage lost previous scroll position.</p>

<p>In this article, I’ll show some tricks to prevent this. They are very simple once you know them but sometimes it’s just hard to get when you are new to the framework.</p>

<h2 id="2-best-solution-swap-outer-html-instead-of-inner-html">2. Best Solution: Swap Outer HTML instead of Inner HTML</h2>

<p>I think this is the best solution. It’s so simple that I don’t know why I didn’t get it earlier. Anyway, that’s why I write this blog so that it can help more people like me.</p>

<p>By default, htmx swap the inner HTML of the element. So the <code class="language-plaintext highlighter-rouge">hx-trigger="load"</code> attribute is still there after the content is loaded and will be triggered again when load from history. The solution is to just let htmx swap the outer HTML instead. Using the same example, the code will be changed to this:</p>

<div class="language-html highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nt">&lt;a</span> <span class="na">hx-get=</span><span class="s">"/page1"</span> <span class="na">hx-push-url=</span><span class="s">"true"</span> <span class="na">hx-target=</span><span class="s">"#content"</span><span class="nt">&gt;</span>page1<span class="nt">&lt;/a&gt;</span>
<span class="nt">&lt;div</span> <span class="na">id=</span><span class="s">"content"</span> <span class="na">hx-get=</span><span class="s">"/content"</span><span class="nt">&gt;</span>
  <span class="nt">&lt;div</span> <span class="na">hx-get=</span><span class="s">"/content"</span> <span class="na">hx-trigger=</span><span class="s">"load"</span> <span class="na">hx-target=</span><span class="s">"this"</span> <span class="na">hx-swap=</span><span class="s">"outerHTML"</span><span class="nt">&gt;&lt;/div&gt;</span>
<span class="nt">&lt;/div&gt;</span>
</code></pre></div></div>

<p>In the new implementation, we have another <code class="language-plaintext highlighter-rouge">div</code> tag inside <code class="language-plaintext highlighter-rouge">#content</code> to do the lazy load. After the response is loaded, it will swap out the whole <code class="language-plaintext highlighter-rouge">div</code> element so <code class="language-plaintext highlighter-rouge">hx-get</code> and <code class="language-plaintext highlighter-rouge">hx-trigger</code> are not there anymore when the snapshot is taken and loaded from history.</p>

<p>As I said, this is the best solution in my mind and I think it fits all the cases. So if you only care about the solution, you can stop reading here. I record the following solutions simply because I figured them out earlier than this one.</p>

<h2 id="3-solution-b-dont-snapshot-the-whole-body">3. Solution B: Don’t Snapshot the Whole Body</h2>

<p>The solution above removes the htmx attributes. The solution in section tackles the problem in another direction: it prevents the element from loading again when go back in history.</p>

<p>By default, htmx will take the snapshot of <code class="language-plaintext highlighter-rouge">body</code> and put it into history cache. That’s why when go back in history, the <code class="language-plaintext highlighter-rouge">load</code> event of the element is triggered again. To prevent it, we can let htmx only snapshot children of <code class="language-plaintext highlighter-rouge">#content</code>. <a href="https://htmx.org/docs/#specifying-history-snapshot-element">Here</a> is the official doc about how to do it. Using the same example, the code will be changed into:</p>

<div class="language-html highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nt">&lt;a</span> <span class="na">hx-get=</span><span class="s">"/page1"</span> <span class="na">hx-push-url=</span><span class="s">"true"</span> <span class="na">hx-target=</span><span class="s">"#content"</span><span class="nt">&gt;</span>page1<span class="nt">&lt;/a&gt;</span>
<span class="nt">&lt;div</span> <span class="na">id=</span><span class="s">"content-load"</span> <span class="na">hx-get=</span><span class="s">"/content"</span> <span class="na">hx-trigger=</span><span class="s">"load"</span> <span class="na">hx-target=</span><span class="s">"#content"</span><span class="nt">&gt;&lt;/div&gt;</span>&gt;
<span class="nt">&lt;div</span> <span class="na">id=</span><span class="s">"content"</span> <span class="na">hx-history-elt</span><span class="nt">&gt;&lt;/div&gt;</span>
</code></pre></div></div>

<p>Here we load the content with <code class="language-plaintext highlighter-rouge">#content-load</code> element. htmx will only swap out <code class="language-plaintext highlighter-rouge">#content</code> when we forward or go back in browser history since we added <code class="language-plaintext highlighter-rouge">hx-history-elt</code> on <code class="language-plaintext highlighter-rouge">#content</code>. This prevents <code class="language-plaintext highlighter-rouge">load</code> event from being triggered on <code class="language-plaintext highlighter-rouge">#content-load</code> so it will not send a new request.</p>

<p>But this solution has great limitations: you need to change the snapshot element which is not always possible.</p>

<h2 id="4-solution-c-remove-htmx-action-attributes-before-taking-snapshot">4. Solution C: Remove htmx Action Attributes Before Taking Snapshot</h2>

<p>This is a solution that could work in theory but I didn’t test it, because I came up with the best solution when thinking about it.</p>

<p>The idea is similar: we don’t want htmx action attributes like <code class="language-plaintext highlighter-rouge">hx-get</code> when we load the history. Other than swap the whole outerHTML, there is a htmx event you can catch in Javascript to remove the attribute before taking a snapshot:</p>

<div class="language-javascript highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nx">htmx</span><span class="p">.</span><span class="nf">on</span><span class="p">(</span><span class="dl">'</span><span class="s1">htmx:beforeHistorySave</span><span class="dl">'</span><span class="p">,</span> <span class="kd">function</span><span class="p">()</span> <span class="p">{</span>
  <span class="nb">document</span><span class="p">.</span><span class="nf">getElementById</span><span class="p">(</span><span class="dl">'</span><span class="s1">#content</span><span class="dl">'</span><span class="p">).</span><span class="nf">removeAttributes</span><span class="p">(</span><span class="dl">"</span><span class="s2">hx-get</span><span class="dl">"</span><span class="p">))</span>
<span class="p">})</span>
</code></pre></div></div>]]></content><author><name></name></author><category term="htmx" /><category term="web" /><category term="UI" /><category term="Javascript" /><summary type="html"><![CDATA[This is a short article about some tricks in htmx. I have more to say about htmx but I’ll save that to another blog. In this one, I will skip the basics about htmx and assume you already know that.]]></summary></entry><entry><title type="html">Travel Back to China</title><link href="https://www.binwang.me/2024-03-19-Travel-Back-to-China.html" rel="alternate" type="text/html" title="Travel Back to China" /><published>2024-03-19T00:00:00-04:00</published><updated>2024-03-19T00:00:00-04:00</updated><id>https://www.binwang.me/Travel-Back-to-China</id><content type="html" xml:base="https://www.binwang.me/2024-03-19-Travel-Back-to-China.html"><![CDATA[<p>After more than 4 years staying aboard without being able to go back to China because of Covid, I finally had the chance and spent this Chinese New Year at my hometown. Now I’ve come back to Toronto, it’s time to record it when my memory and feelings are still fresh.</p>

<h2 id="before-we-go">Before We Go</h2>

<p>Being able to travel back doesn’t mean it’s easy. The number of flights between China and other countries are still not recovered to pre Covid level. In order to keep our budget in a reasonable level, we need to fly through 2 stops, and then drive more than 3 hours to home from the airport. The flying time and the waiting time at airport combined is more than 24 hours. It’s a very long trip for any adult, not to mention traveling with a 6 months old baby. I was very nervous about that since our longest trip with the baby was taking her to the clinic. But since we haven’t been back for so many years, this is a travel that shouldn’t be delayed anymore. On the bright side, my sister in law will come to meet us at the first stop Tokyo. We will stay there for a few days for resting and sight seeing.</p>

<p>Things were not smooth before we go. First, our company had a bad outrage during the holiday season so I needed to work overtime. Following that was hot debates about the following steps to make our services better, which made me very frustrate for reasons I’d rather not to talk here. And during all these things, the whole family also caught cold and had fever for a few days. It’s the first time the baby is sick so it’s very stressful situation. The baby awoke every 2 hours at night while my wife and I were sick. When everyone finally recovered, we barely had the time to get new Covid vaccines and pack the baggages.</p>

<p>Anyway, we successfully handled everything before we go, took the 15 hours long flight and headed to our first stop, Tokyo.</p>

<h2 id="stay-in-tokyo">Stay in Tokyo</h2>

<p>I had been to Tokyo twice. But they are both many years ago and I didn’t have enough time to see the whole city. Even though it’s a relatively short visit again this time: just 3 - 4 days, it still got me excited to be there again.</p>

<p>We wanted to book a hotel near Asakusa (浅草) area since Sensō-ji is a must see site in Tokyo. We also want a subway station nearby. At last we found a place near Ueno (上野) station. It’s a traditional Japanese style hotel that has Tatamis, which is perfect for us: our baby doesn’t like to sleep in the crib anymore, so Tatamis is much safer since she cannot fall from it, and the mattress is also much firmer than the ones in regular hotels, which prevent the baby’s face from buried into the mattress. And she can also play on it during day time as well.</p>

<p>Only after I booked the hotel, I found out Ueno area is a place I wanted to visit but didn’t have enough time last time: when my wife and I visited Tokyo last time, we planned to take the train from Ueno station to the airport. We didn’t notice the schedule of that train is less frequent than subway. So we didn’t plan the time ahead and missed it. Disappointedly, we decided to have some food near Ueno station first. That’s when we found out the area around Ueno: there are many pedestrian streets filled with street food, outdoor eatings, restaurants, shops, and people. I was so fascinated by it and it was a shame that we didn’t have enough time to explore the area since we needed to head to Kyoto at that day. I forgot the name of that area since then because we were in such a hurry and we visited so many places in Japan after that. But when I was checking the surrounding area of the hotel on Google Maps, the Ueno station struck my memory and I was so excited that I had another opportunity to fully explore that area.</p>

<p>So Ueno and Asakusa are where we explored most when we were at Tokyo. We went to the Tokyo National Museum and enjoyed the ukiyo-e (浮世絵, wood block prints) exhibition that I wanted to see long before we went. We ate some delicious food at Ueno area. We also bought some electronic devices and manga books at Akihabara (秋葉原). What I didn’t expect was the experience at Asakusa: last time I only visited Sensō-ji and the street in the front of it. I didn’t know there is a larger area surrounding it that has lots of traditional Japanese style buildings, shops and restaurants. We found a shop by coincidence that sells high quality ukiyo-e prints. There are many places selling them in Tokyo, but they are either low quality or too expensive. I’m so glad to find a shop that sells lots of high quality prints in reasonable price range.</p>

<p>The whole experience in Tokyo is very positive. The mix of tradition Japanese and modern culture creates a very unique vibe. Because Japanese culture is largely impacted by Chinese culture in the past, I think I can appreciate more of the beauty of it. I have a fresh eye when I looked at the city after I explored more on the topic of city design in the past years: the non car centric culture, high quality public transit and high density of population makes it very different from North American cities. The city is more vibrant, much cleaner and safer, and have so many interesting places to explore. But unfortunately, Japan is a country better for visiting than long term living for foreigners because of its (almost non-exist of) immigration culture and stressful working environment.</p>

<p>The biggest happy surprise we got from Japan is our baby can sleep the whole night! It’s such a life changing improvement for my wife and me. After having the baby, I felt like there is nothing more important than being able to sleep a whole night. It’s so great to have that back!</p>

<p>On that happy note, we continued the trip back to home.</p>

<h2 id="back-to-hometown">Back to Hometown</h2>

<p>I thought there would be lots of feelings on the road to home. But there wasn’t. Maybe because of there are too many concrete things to worry about with a baby on the road so it left little room for feelings.</p>

<p>With the things happened in the past years in China: the lockdown of cities during Covid, the re-election of Xi which broke the political practice, the protests of both the re-eleciton and lockdowns, the broke of Evergrande Group, and the downhill of America-China relationship, you’d imagine China is in a pretty bad place. However, when I went back to home, I found things were not as bad as I thought. Yes, economic has gone bad: there are lots of unfinished buildings, small businesses are struggling, it’s harder to find a job for new grad, nationalism is on the rise and so on. But on another hand, at least from my limited experience, people’s life is still going on. I saw there is disapproval when people talk about the economic and government policies, but I saw little desperation feelings. When there are fewer ways to make life better, people continue to find new ways. For good or for bad, that’s the resilience of Chinese people. Maybe it looks better than normal because it’s holiday season: the malls and restaurants are packed with people. Beautiful decoration lights are everywhere. There are fireworks everyday.</p>

<p>Theoretically, fireworks have been banned for many years in China. However, with the lift of lockdown at the end of last year, there were lots of celebrations with fireworks at the new year (not the Chinese New Year) and created some conflicts between the crowd and the police in some cities. After that, the ban of fireworks still exists but is rarely enforced. Fireworks in the new year’s eve has been a tradition since ancient time. But in my opinion, the mixed feelings it brings represents the complexity of contemporary China perfectly: It’s believed to be able to dispel bad luck, which is much needed after the Covid and the following weak economic. It extends to some level of superstitious that some people believe it can cleanup the virus in the air. It also seems to be a subtle way to express disapproval of government policies because the ban is still in place. Of cause there is also pure excitement about the lights and sounds, the happiness about holiday, and wishes for a better year ahead.</p>

<p>Another reason of the weak economic not showing much trace may be my hometown is a small city so the trend is kind of lagged behind. It’s still benefiting from the development of the bigger cities in the past years: more and more big brands and chain stores are opening so there are more choices when buying things. Food delivery is more convenient. There are also more culture innovation products with better traditional Chinese aesthetic. If not considering education and healthcare system, the everyday life has little difference from big cities, or even better because of the less stressful working environment.</p>

<p>Not all things are good. Not mentioning the things that were already there before I left China, there is one new development that would trouble me a lot if I lived for a longer time: the lack of privacy both in the real world and in the cyber space. In the real world, cameras are everywhere. Lots of people start to use smart locks on the door that has a camera that you cannot avoid when you pass by. You must have scan the face in order to enter some residential compounds. Every crossing has high resolution cameras recording license numbers of cars and are able to recognize the drivers. In Beijing, face is recorded when entering every subway station. Even worse, when I was playing arcade games in a mall, the arcade machine has a camera that took a photo of me without reminding me first. On the cyber space side, there is little service you can use without installing an app and register an account that linked to your phone number and in turn linked to your ID. The worst experience I had is at a parking lot: there was no person at the exit and you need to scan the QR code to register an account, input personal details and pay the fee in order to leave. Again, there was nothing reminds you that before you actually try to leave and scan the QR code. I guess it’s not like there is no one in China cares about the privacy, it’s more like an already lost battle because the desire of surveillance from both the government and tech giants, and the lack of power to balance that.</p>

<p>Another thing I dislike is the trend of city planning. I think the city did a very good job in the past: reasonable density and mixed use was very well maintained. There are dedicated bike lanes, wide sidewalks and reasonable public transit coverage. However, with the widely adoption of cars, things got worth and the city seems just want to change things in the name of changing. That’s kind of understandable because there are more opportunity for corrupt when there are more projects. But at the end, parking lots replaced lots of green spaces on sidewalks. Roads has been re-designed with confusing turning lanes which replaced some bike lanes. Traffic lights replaced lots of roundabouts, and even worse, sometimes traffic lights are combined with roundabouts which is totally unnecessary. If the changes are limited because of the old foundation, then it’s not surprise that the worse place happens at the newly developed areas. It’s mostly all high rise residential buildings with little commercial uses. That’s kind of understandable as well since one of the main income of government is by selling land to developers. Seems like there were some commercial uses planned but the progress get delayed because of the real estate crisis. But the most ridiculous part is the roadway network design: there are many very wide roads. Many of them have 10 lanes! And some of them even have additional 2-3 lanes service road on each side. Be aware those are not highways. In a grid layout, those very wide roads are just beside residential buildings and are connected without skipping any crossing. It’s such a waste of resource because if there are so many cars that such wide roads are needed, then the non exist of road hierarchy doesn’t make any sense. Combined with the lack of commercial uses, it makes people rely more on cars and makes traffic very bad for commercial areas. Just go outside for a walk like the old days is not enjoyable anymore in the newly developed areas.</p>

<p>Despite all those things, it’s still a vacation at my hometown. So my mind was laid back even though I was very busy physically: my wife’s sister got married just days after we arrived. My wife and I also had the wedding that was planned years ago but got pushed because of Covid. I’m very happy how the wedding went considering we need to take care of the baby at the same time. If we were not preparing for the wedding, we took the baby to my parents and my in-law’s places. Between the gaps, I also needed to find some time to meet with friends that I haven’t seen for a long time. So it’s a very packed schedule but it’s so different (in a good way) to be close with family and friends again. Being aboard so many years and having a baby gave me a new perspective of the importance of family and friends.</p>

<p>However, I couldn’t stay there for long. I left half a month’s parental leave for the travel. But even combined with that, one month is basically the most I can have for a vacation and the company doesn’t allow work from China. So even we felt like we haven’t spent much time at home yet, we needed to go back. The trip back to Toronto has 3 stops on the way. So it’s another battle to fight. Our first stop is Beijing and we will stay at the airport for one night.</p>

<h2 id="one-night-in-beijing">One Night in Beijing</h2>

<p>I lived in Beijing for 8 years. It’s the second longest city I’ve lived in, just behind my hometown. It’s the longest if considering only the time of adulthood. So I have lots of memory and friends there. It’s unfortunate that I can only stay there for one night but it’s better than nothing.</p>

<p>Just before the day of leaving for Beijing, there was a snowstorm and most highways were closed as a result. We booked the train from a nearby city because the time of the train is better. But since the highway was closed, we changed the departure station to our hometown city. It was a very cold morning and we needed to leave for the railway station at 5:00am. When we were waiting at the station, there was an announcement that said the train was delayed. Following that, there were more announcements and the train was delayed longer and longer. Luckily, while debating if it’s better to go home instead of waiting in the station, the delay got shorter and we were finally able to aboard the train.</p>

<p>Things got better after this rocky start. We took the subway to the airport after arrived at Beijing since we didn’t have the baby’s car seat with us. It’s mostly underground on the way so I had little opportunity to see the city. It’s almost time for dinner when we arrived the hotel in the airport. If not because of the delay of train, we could arrive at noon. I made the plan to meet some friends and have dinner together. I left early from the hotel to walk around the city before I meet them.</p>

<p>I took the subway to Sanyuan Bridge (三元桥). It’s the northeast corner of the Third Ring Road and only one stop away from the airport by the airport express line. I went to a mall first. It’s still early for a weekday so it’s a little bit quite there. I decided to walked to a nearby subway station Liangma Bridge (亮马桥), which is a place surrounded by many embassies. I met my friends there and walked to the nearby restaurant together. Two of my jobs were at that area so I have lots of memory there. Walking along the streets at night, everything feels very familiar but also has a sense of distance. There are lots of restaurants and shops disappeared or changed owners, but the base layout is the same. While taking the subway, walking along the narrow road that has barriers to separate it from the Third Ring Road, going through the underground tunnel, I recognized the familiar feeling: Beijing is like a big machine or beast that doesn’t care about normal human beings. The city is not designed with human scale. Multiple ring road highways cut through the city with giant crossing bridges. But that doesn’t make driving easier because the traffic is still bad and only limited cars can be on the road at weekdays based on the license number. The public transit is wonderful compared to North American cities and most of the people use it. But the subway is usually packed with people during commute hours and stations have maze like paths for exits and connection to another station. It can suck all the remaining energy out after a work day. The pace of life is fast and people are busy. It’s not an enjoyable city to live. But it’s still the capital of China and is the biggest city of the north. There is no shortage of people live there with the hope of a better life. I was one of them and it gave me valuable adventures. I don’t love the city but I love the memory with it.</p>

<h2 id="back-to-toronto">Back to Toronto</h2>

<p>We left early next morning for the flight to Tokyo, then to Montreal, then to Toronto. We had the opportunity to fully explore the airports at Tokyo and Montreal because we left enough time in between of the flights. The longest flight from Tokyo to Montreal is full but fortunately the baby was able to sleep most of the time. We arrived at Toronto at night which means it’s another morning in China and it has been more than 24 hours since we took the first flight from Beijing.</p>

<p>The whole travel went much better than I thought. We not only see the family and friends after 4 years, we also have the experience of traveling a long distance with the baby so it opens so many possibilities in the future. It would be great if I can stay longer with family every year in the future.</p>]]></content><author><name></name></author><category term="life" /><category term="travel" /><category term="China" /><category term="Japan" /><category term="Beijing" /><category term="Tokyo" /><summary type="html"><![CDATA[After more than 4 years staying aboard without being able to go back to China because of Covid, I finally had the chance and spent this Chinese New Year at my hometown. Now I’ve come back to Toronto, it’s time to record it when my memory and feelings are still fresh.]]></summary></entry><entry><title type="html">Scala 2 Macro Tutorial</title><link href="https://www.binwang.me/2023-12-29-Scala-Macro-Tutorial.html" rel="alternate" type="text/html" title="Scala 2 Macro Tutorial" /><published>2023-12-29T00:00:00-05:00</published><updated>2023-12-29T00:00:00-05:00</updated><id>https://www.binwang.me/Scala-Macro-Tutorial</id><content type="html" xml:base="https://www.binwang.me/2023-12-29-Scala-Macro-Tutorial.html"><![CDATA[<p>Macros are powerful but complex. Especially when the language itself like Scala is already complex. The lack of learning resource and documents makes it more so. In this article, I’ll write down some of my learnings and hopefully it can help someone else who is new to it as well. I’ll keep the examples small and simple so it’s easier to understand. Since I’m still learning it, I may continue to update this article on the way, or write a new article if there is a big topic. Either way, I’ll make notes here so you know there are updates.</p>

<p>Scala’s macro syntax and APIs can be different from version to version. Especially it’s almost completely redesigned in Scala 3. This article only targets Scala 2 and I’ve only tested the examples on Scala 2.13.</p>

<h2 id="1-what-is-macro">1. What is Macro</h2>

<p>The basic idea of macro is to modify the code with code. For example, let’s imagine a macro <code class="language-plaintext highlighter-rouge">plusToMinus</code> that modifies all the plus operations of integers to minus:</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plusToMinus</span> <span class="o">{</span> <span class="mi">1</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">}</span>
</code></pre></div></div>

<p>This will be compiled to <code class="language-plaintext highlighter-rouge">1 - 1</code> and ends up as <code class="language-plaintext highlighter-rouge">0</code>.</p>

<p>Of cause this is not a practical example and not all the languages’ macro system can do it. But this demonstrate what macros can do where normal code cannot. Here is a more practical example: when we log something in different log levels, the API usually looks like this:</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">v</span> <span class="k">=</span> <span class="o">...</span>
<span class="nv">logger</span><span class="o">.</span><span class="py">info</span><span class="o">(</span><span class="n">s</span><span class="s">"This is a info log. Value: $v"</span><span class="o">)</span>
<span class="nv">logger</span><span class="o">.</span><span class="py">warn</span><span class="o">(</span><span class="n">s</span><span class="s">"This is a warning. Value: $v"</span><span class="o">)</span>
</code></pre></div></div>

<p>However, with this kind of interface, the string <code class="language-plaintext highlighter-rouge">s"..."</code> need to be computed before passed in to the method, which is a waste since not all the strings need to be logged based on the log level configuration. Especially when <code class="language-plaintext highlighter-rouge">v.toString</code> needs a lot of resource to compute. So in language like Java, the values are usually passed in as separate parameters:</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nc">String</span> <span class="n">v</span> <span class="o">=</span> <span class="o">...</span>
<span class="n">logger</span><span class="o">.</span><span class="na">info</span><span class="o">(</span><span class="s">"This is a info log. Value: {}"</span><span class="o">,</span> <span class="n">v</span><span class="o">);</span>
<span class="n">logger</span><span class="o">.</span><span class="na">warn</span><span class="o">(</span><span class="s">"This is a warning. Value: {}"</span><span class="o">,</span> <span class="n">v</span><span class="o">);</span>
</code></pre></div></div>

<p>Even though it resolves the problem, the interface is kind of awful. And not all the users know this kind of details so they may still just construct the string directly instead of pass in separate parameters. However, with the help of macros, you can still keep the logger interface in the intuitive way. As macros, <code class="language-plaintext highlighter-rouge">logger.info</code> and <code class="language-plaintext highlighter-rouge">logger.warn</code> can modify the code directly during the compile time. For example, it can modify the code like this:</p>

<p>From</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">logger</span><span class="o">.</span><span class="py">info</span><span class="o">(</span><span class="n">s</span><span class="s">"This is a info log. Value: $v"</span><span class="o">)</span>
</code></pre></div></div>

<p>To</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">if</span> <span class="o">(</span><span class="n">loggerLevel</span> <span class="o">&gt;=</span> <span class="nc">INFO</span><span class="o">)</span> <span class="o">{</span>
  <span class="nf">println</span><span class="o">(</span><span class="n">s</span><span class="s">"This is a info log. Value: $v"</span><span class="o">)</span>
<span class="o">}</span>
</code></pre></div></div>

<p>So that the actually string computation is not done unless log level is configured to print it.</p>

<h2 id="2-how-to-write-a-macro">2. How to Write a Macro</h2>

<p>Different languages have different syntaxes to write a macro. On the simpler side, macros in C can only do text substitution. On the powerful side, Lisp languages can modify the AST (abstract syntax tree) very easily because the code itself is written as a tree structure. The macro in Scala is on the powerful side since it is able to modify the AST even though it may not be as intuitive as Lisp. There are multiple ways to do it. But essentially, the process it to take the current AST as input and output a new AST. The APIs of reading AST input is very similar to reflection APIs (and in fact, sometimes they share some APIs). Generating a new AST part is more complex. In the following sections, we will walk through how to setup a SBT project to write macros, how to read an AST and how to generate a new AST.</p>

<h2 id="3-project-setup-with-sbt">3. Project Setup with SBT</h2>

<p>In Scala, the implementation of macros and the use of macros need to be compiled separately. So if you are using SBT, they need to be in different sub projects. Here is an example of <code class="language-plaintext highlighter-rouge">build.sbt</code>:</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">lazy</span> <span class="k">val</span> <span class="nv">root</span> <span class="k">=</span> <span class="o">(</span><span class="n">project</span> <span class="n">in</span> <span class="nf">file</span><span class="o">(</span><span class="s">"."</span><span class="o">))</span>
  <span class="o">.</span><span class="py">aggregate</span><span class="o">(</span><span class="n">core</span><span class="o">,</span> <span class="n">coretest</span>
  <span class="o">.</span><span class="py">settings</span><span class="o">(</span>
    <span class="n">name</span> <span class="o">:=</span> <span class="s">"archmage"</span>
  <span class="o">)</span>

<span class="k">lazy</span> <span class="k">val</span> <span class="nv">core</span> <span class="k">=</span> <span class="o">(</span><span class="n">project</span> <span class="n">in</span> <span class="nf">file</span><span class="o">(</span><span class="s">"core"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">settings</span><span class="o">(</span>
    <span class="n">name</span> <span class="o">:=</span> <span class="s">"core"</span><span class="o">,</span>
    <span class="n">libraryDependencies</span> <span class="o">++=</span> <span class="nc">Seq</span><span class="o">(</span>
      <span class="s">"org.scala-lang"</span> <span class="o">%</span> <span class="s">"scala-reflect"</span> <span class="o">%</span> <span class="s">"2.13.12"</span><span class="o">,</span>
      <span class="s">"co.fs2"</span> <span class="o">%%</span> <span class="s">"fs2-core"</span> <span class="o">%</span> <span class="s">"3.9.3"</span><span class="o">,</span>
    <span class="o">)</span>
  <span class="o">)</span>

<span class="k">lazy</span> <span class="k">val</span> <span class="nv">coretest</span> <span class="k">=</span> <span class="o">(</span><span class="n">project</span> <span class="n">in</span> <span class="nf">file</span><span class="o">(</span><span class="s">"coretest"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">settings</span><span class="o">(</span>
    <span class="n">name</span> <span class="o">:=</span> <span class="s">"core-test"</span>
  <span class="o">)</span> <span class="n">dependsOn</span> <span class="n">core</span>
</code></pre></div></div>

<p>It creates two sub projects. You can implement the macros in <code class="language-plaintext highlighter-rouge">core</code> and use them in <code class="language-plaintext highlighter-rouge">coretest</code>.</p>

<p>If you want to debug the generated code from macros, add debug flags to Scala like this in <code class="language-plaintext highlighter-rouge">build.sbt</code>:</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nc">ThisBuild</span> <span class="o">/</span> <span class="n">scalacOptions</span> <span class="o">+=</span> <span class="s">"-Ymacro-debug-lite"</span>
</code></pre></div></div>

<h2 id="4-how-to-read-ast">4. How to Read AST</h2>

<h3 id="41-read-macro-parameters">4.1 Read macro parameters:</h3>

<p>Here is the basic syntax of a macro. First, define a macro implementation:</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">macroImpl</span><span class="o">(</span><span class="n">c</span><span class="k">:</span> <span class="kt">blackbox.Context</span><span class="o">)(</span><span class="n">s</span><span class="k">:</span> <span class="kt">c.Expr</span><span class="o">[</span><span class="kt">String</span><span class="o">])</span> <span class="k">:</span> <span class="kt">c.Expr</span><span class="o">[</span><span class="kt">String</span><span class="o">]</span> <span class="k">=</span> <span class="o">{</span>
  <span class="nf">println</span><span class="o">(</span><span class="nv">s</span><span class="o">.</span><span class="py">tree</span><span class="o">.</span><span class="py">symbol</span><span class="o">.</span><span class="py">fullName</span><span class="o">)</span>
  <span class="n">s</span>
<span class="o">}</span>
</code></pre></div></div>

<p>The first parameter <code class="language-plaintext highlighter-rouge">c: blackbox.Context</code> is a must have for a macro implementation. There is also a <code class="language-plaintext highlighter-rouge">whitebox.Context</code> but we will not cover it in this article. More details about whitebox can be found in <a href="https://docs.scala-lang.org/overviews/macros/blackbox-whitebox.html">the official document</a>.</p>

<p>The remaining parameters of the implementation method are parameters for the macro. For example, if you want to take a parameter of type <code class="language-plaintext highlighter-rouge">String</code> for the macro, then the implementation of macro will take <code class="language-plaintext highlighter-rouge">c.Expr[String]</code> as a parameter, which <code class="language-plaintext highlighter-rouge">c.Expr[String]</code> is the tree representation of the macro’s <code class="language-plaintext highlighter-rouge">String</code> parameter. The same applies to the return type of the macro. You can also  use <code class="language-plaintext highlighter-rouge">c.Tree</code> instead of <code class="language-plaintext highlighter-rouge">c.Expr[T]</code>. They can be converted between each other, which we will see in section 4.4.</p>

<p>This example prints out the variable name of the passed in parameter and return the parameter without modification. Note that the printing happens at compile time since that’s when the implementation of the macro is ran. Only the returned tree or <code class="language-plaintext highlighter-rouge">c.Expr</code> is used at run time. So this macro is not doing anything useful, it’s just a demo of how to read the input tree.</p>

<p>Once we have the macro implementation, we can define the macro like this:</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">macroTest</span><span class="o">(</span><span class="n">arg</span><span class="k">:</span> <span class="kt">String</span><span class="o">)</span><span class="k">:</span> <span class="kt">String</span> <span class="o">=</span> <span class="n">macro</span> <span class="n">macroImpl</span>
</code></pre></div></div>

<p>Then we can use it in another (sub) project so that the compilation is separated:</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">a</span> <span class="k">=</span> <span class="s">"abc"</span>
<span class="nf">macroTest</span><span class="o">(</span><span class="n">a</span><span class="o">)</span>
</code></pre></div></div>

<p>It will print out the full name of <code class="language-plaintext highlighter-rouge">a</code> like this during compilation:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>me.binwang.archmage.coretest.MethodMetaTest.a
</code></pre></div></div>

<p>The API of <code class="language-plaintext highlighter-rouge">c.Expr</code> is very similar as reflection API. You can experiment with it by print out different things from it and see what you can get.</p>

<h3 id="42-read-type-parameters">4.2 Read type parameters:</h3>

<p>Macro can also take generic type as parameters. The example below takes a parameter of any type and print out its type at compile time.</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">macroImpl</span><span class="o">[</span><span class="kt">T:</span> <span class="kt">c.WeakTypeTag</span><span class="o">](</span><span class="n">c</span><span class="k">:</span> <span class="kt">blackbox.Context</span><span class="o">)(</span><span class="n">s</span><span class="k">:</span> <span class="kt">c.Expr</span><span class="o">[</span><span class="kt">T</span><span class="o">])</span> <span class="k">:</span> <span class="kt">c.Expr</span><span class="o">[</span><span class="kt">T</span><span class="o">]</span> <span class="k">=</span> <span class="o">{</span>
  <span class="nf">println</span><span class="o">(</span><span class="nv">c</span><span class="o">.</span><span class="py">weakTypeOf</span><span class="o">[</span><span class="kt">T</span><span class="o">])</span>
  <span class="n">s</span>
<span class="o">}</span>

<span class="k">def</span> <span class="nf">macroTest</span><span class="o">[</span><span class="kt">T</span><span class="o">](</span><span class="n">s</span><span class="k">:</span> <span class="kt">T</span><span class="o">)</span><span class="k">:</span> <span class="kt">T</span> <span class="o">=</span> <span class="n">macro</span> <span class="n">macroImpl</span><span class="o">[</span><span class="kt">T</span><span class="o">]</span>
</code></pre></div></div>

<p>Which can be used like this:</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">macroTest</span><span class="o">(</span><span class="s">"abc"</span><span class="o">)</span>
<span class="nf">macroTest</span><span class="o">(</span><span class="mi">1</span><span class="o">)</span>
</code></pre></div></div>

<p>The output during compilation will be:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>String
Int
</code></pre></div></div>

<h3 id="43-read-implicit-parameters">4.3 Read implicit parameters:</h3>

<p>Macro can have implicit parameters, but the macro implementation shouldn’t define them as implicit. Otherwise Scala compiler will give confusing errors. See <a href="https://github.com/scala/bug/issues/6494">this issue</a> for more details.</p>

<p>In the following example, <code class="language-plaintext highlighter-rouge">macroTest</code> takes an implicit double variable and return it as the new generated tree:</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">macroImpl</span><span class="o">(</span><span class="n">c</span><span class="k">:</span> <span class="kt">blackbox.Context</span><span class="o">)(</span><span class="n">s</span><span class="k">:</span> <span class="kt">c.Expr</span><span class="o">[</span><span class="kt">String</span><span class="o">])(</span><span class="n">num</span><span class="k">:</span> <span class="kt">c.Expr</span><span class="o">[</span><span class="kt">Double</span><span class="o">])</span> <span class="k">:</span> <span class="kt">c.Expr</span><span class="o">[</span><span class="kt">Double</span><span class="o">]</span> <span class="k">=</span> <span class="o">{</span>
  <span class="nf">println</span><span class="o">(</span><span class="n">s</span><span class="s">"Name of implicit num: ${num.tree.symbol.fullName}"</span><span class="o">)</span>
  <span class="n">num</span>
<span class="o">}</span>

<span class="k">def</span> <span class="nf">macroTest</span><span class="o">(</span><span class="n">s</span><span class="k">:</span> <span class="kt">String</span><span class="o">)(</span><span class="k">implicit</span> <span class="n">num</span><span class="k">:</span> <span class="kt">Double</span><span class="o">)</span><span class="k">:</span> <span class="kt">Double</span> <span class="o">=</span> <span class="n">macro</span> <span class="n">macroImpl</span>
</code></pre></div></div>

<p>Note how <code class="language-plaintext highlighter-rouge">num</code> in <code class="language-plaintext highlighter-rouge">macroImpl</code> doesn’t have any <code class="language-plaintext highlighter-rouge">implicit</code> definition.</p>

<p>Then the test code:</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">implicit</span> <span class="k">val</span> <span class="nv">num</span><span class="k">:</span> <span class="kt">Double</span> <span class="o">=</span> <span class="mf">1.1</span>
<span class="nf">println</span><span class="o">(</span><span class="nf">macroTest</span><span class="o">(</span><span class="s">"abc"</span><span class="o">))</span>
</code></pre></div></div>

<p>It will print this during the compile time:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Name of implicit num: me.binwang.archmage.coretest.MethodMetaTest.num
</code></pre></div></div>

<p>And this during the run time:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>1.1
</code></pre></div></div>

<h3 id="44-read-code-block-with-by-name-parameter">4.4 Read code block with by-name parameter</h3>

<p>Macros can also take <a href="https://docs.scala-lang.org/tour/by-name-parameters.html">by-name parameter</a>. However, it needs to use <code class="language-plaintext highlighter-rouge">c.Tree</code> instead of <code class="language-plaintext highlighter-rouge">c.Expr</code> as parameter in the macro implementation:</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">macroImpl</span><span class="o">(</span><span class="n">c</span><span class="k">:</span> <span class="kt">blackbox.Context</span><span class="o">)(</span><span class="n">s</span><span class="k">:</span> <span class="kt">c.Tree</span><span class="o">)</span> <span class="k">:</span> <span class="kt">c.Expr</span><span class="o">[</span><span class="kt">String</span><span class="o">]</span> <span class="k">=</span> <span class="o">{</span>
  <span class="nf">println</span><span class="o">(</span><span class="n">s</span><span class="o">)</span>
  <span class="nv">c</span><span class="o">.</span><span class="py">Expr</span><span class="o">[</span><span class="kt">String</span><span class="o">](</span><span class="n">s</span><span class="o">)</span>
<span class="o">}</span>

<span class="k">def</span> <span class="nf">macroTest</span><span class="o">(</span><span class="n">s</span><span class="k">:</span> <span class="o">=&gt;</span> <span class="nc">String</span><span class="o">)</span><span class="k">:</span> <span class="kt">String</span> <span class="o">=</span> <span class="n">macro</span> <span class="n">macroImpl</span>
</code></pre></div></div>

<p>See how <code class="language-plaintext highlighter-rouge">c.Tree</code> is converted to <code class="language-plaintext highlighter-rouge">c.Expr</code>. You can also convert <code class="language-plaintext highlighter-rouge">c.Expr</code> to <code class="language-plaintext highlighter-rouge">c.Tree</code> by using the <code class="language-plaintext highlighter-rouge">.tree</code> method, which we’ve seen in the examples above.</p>

<p>Test it with this code:</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">macroTest</span> <span class="o">{</span>
  <span class="k">val</span> <span class="nv">a</span> <span class="k">=</span> <span class="s">"a"</span>
  <span class="k">val</span> <span class="nv">b</span> <span class="k">=</span> <span class="s">"b"</span>
  <span class="nf">println</span><span class="o">(</span><span class="s">"hello!"</span><span class="o">)</span>
  <span class="n">a</span> <span class="o">+</span> <span class="n">b</span>
<span class="o">}</span>
</code></pre></div></div>

<p>It will print out this during compile time:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{
  val a: String = "a";
  val b: String = "b";
  scala.Predef.println("hello!");
  a.+(b)
}
</code></pre></div></div>

<h3 id="45-use-quasiquotes">4.5 Use Quasiquotes</h3>

<p><a href="https://docs.scala-lang.org/overviews/quasiquotes/intro.html">Quasiquotes</a>, or <code class="language-plaintext highlighter-rouge">q"..."</code>, is a very powerful syntax for Scala macro. It can both match a tree and generate a tree. For example, the following code can match different parts of a if else clause to <code class="language-plaintext highlighter-rouge">c.Tree</code> variables:</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">macroImpl</span><span class="o">(</span><span class="n">c</span><span class="k">:</span> <span class="kt">blackbox.Context</span><span class="o">)(</span><span class="n">s</span><span class="k">:</span> <span class="kt">c.Tree</span><span class="o">)</span><span class="k">:</span> <span class="kt">c.Tree</span> <span class="o">=</span> <span class="o">{</span>
  <span class="k">import</span> <span class="nn">c.universe._</span>
  <span class="k">val</span> <span class="nv">q</span><span class="s">"if ($cond) $thenp else $elsep"</span> <span class="k">=</span> <span class="n">s</span>
  <span class="nf">println</span><span class="o">(</span><span class="n">cond</span><span class="o">)</span>
  <span class="nf">println</span><span class="o">(</span><span class="n">thenp</span><span class="o">)</span>
  <span class="nf">println</span><span class="o">(</span><span class="n">elsep</span><span class="o">)</span>
  <span class="n">q</span><span class="s">"$cond"</span>
<span class="o">}</span>

<span class="k">def</span> <span class="nf">macroTest</span><span class="o">(</span><span class="n">s</span><span class="k">:</span> <span class="o">=&gt;</span> <span class="nc">Any</span><span class="o">)</span><span class="k">:</span> <span class="kt">Any</span> <span class="o">=</span> <span class="n">macro</span> <span class="n">macroImpl</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">cond</code>, <code class="language-plaintext highlighter-rouge">thenp</code> and <code class="language-plaintext highlighter-rouge">elsep</code> are all matched parts from the input tree.</p>

<p><code class="language-plaintext highlighter-rouge">q"$cond"</code> generates a new tree using the matched condition part of the tree. We will see more details in how to use quasiquotes to generate trees in section 5.4.</p>

<p>Test it with this code:</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">bigNum</span> <span class="k">=</span> <span class="mi">2</span>
<span class="k">val</span> <span class="nv">smallNum</span> <span class="k">=</span> <span class="mi">1</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="n">macroTest</span> <span class="o">{</span>
  <span class="nf">if</span> <span class="o">(</span><span class="n">bigNum</span> <span class="o">&gt;</span> <span class="n">smallNum</span><span class="o">)</span> <span class="o">{</span>
    <span class="s">"no surprise"</span>
  <span class="o">}</span> <span class="k">else</span> <span class="o">{</span>
    <span class="s">"surprise!"</span>
  <span class="o">}</span>
<span class="o">}</span>
<span class="nf">println</span><span class="o">(</span><span class="n">result</span><span class="o">)</span>
</code></pre></div></div>

<p>During the compile time, it will print out the different parts of the tree that we have asked it to match:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>bigNum.&gt;(smallNum)
"no surprise"
"surprise!"
</code></pre></div></div>

<p>And during the run time, it will print out the value of condition instead of either if or else clause:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>true
</code></pre></div></div>

<p>More examples about how to match the tree can be found in <a href="https://docs.scala-lang.org/overviews/quasiquotes/syntax-summary.html">the document</a>. Click on each example to see more details.</p>

<h2 id="5-how-to-generate-tree">5. How to Generate Tree</h2>

<h3 id="51-construct-tree-directly-with-api">5.1 Construct Tree Directly with API</h3>

<p>An AST can be constructed from the classes that represent the tree. For example, a constant of string can be created by <code class="language-plaintext highlighter-rouge">Literal(Constant("I replaced you!"))</code>. The following example replace any string to <code class="language-plaintext highlighter-rouge">I replaced you</code>:</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">macroImpl</span><span class="o">(</span><span class="n">c</span><span class="k">:</span> <span class="kt">blackbox.Context</span><span class="o">)(</span><span class="n">s</span><span class="k">:</span> <span class="kt">c.Expr</span><span class="o">[</span><span class="kt">String</span><span class="o">])</span> <span class="k">:</span> <span class="kt">c.Expr</span><span class="o">[</span><span class="kt">String</span><span class="o">]</span> <span class="k">=</span> <span class="o">{</span>
  <span class="k">import</span> <span class="nn">c.universe._</span>
  <span class="nv">c</span><span class="o">.</span><span class="py">Expr</span><span class="o">[</span><span class="kt">String</span><span class="o">](</span><span class="nc">Literal</span><span class="o">(</span><span class="nc">Constant</span><span class="o">(</span><span class="s">"I replaced you!"</span><span class="o">)))</span>
<span class="o">}</span>

<span class="k">def</span> <span class="nf">macroTest</span><span class="o">(</span><span class="n">s</span><span class="k">:</span> <span class="kt">String</span><span class="o">)</span><span class="k">:</span> <span class="kt">String</span> <span class="o">=</span> <span class="n">macro</span> <span class="n">macroImpl</span>
</code></pre></div></div>

<p>With the code below, it will print <code class="language-plaintext highlighter-rouge">I replaced you!</code> instead of <code class="language-plaintext highlighter-rouge">abc</code>:</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">println</span><span class="o">(</span><span class="nf">macroTest</span><span class="o">(</span><span class="s">"abc"</span><span class="o">))</span>
</code></pre></div></div>

<p>This is a very simple example. When the tree becomes larger and larger , it’s more and more difficult to construct a tree with this approach. It’s like a much worse version of lisp. So in the following sections, we will see some easier ways to construct a tree.</p>

<h3 id="52-use-cparse">5.2 Use <code class="language-plaintext highlighter-rouge">c.parse</code>:</h3>

<p><code class="language-plaintext highlighter-rouge">c.parse</code> can parse a string as Scala code and generate an AST. For example, the following macro returns the variable name of a <code class="language-plaintext highlighter-rouge">String</code>:</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">macroImpl</span><span class="o">(</span><span class="n">c</span><span class="k">:</span> <span class="kt">blackbox.Context</span><span class="o">)(</span><span class="n">s</span><span class="k">:</span> <span class="kt">c.Expr</span><span class="o">[</span><span class="kt">String</span><span class="o">])</span><span class="k">:</span> <span class="kt">c.Expr</span><span class="o">[</span><span class="kt">String</span><span class="o">]</span> <span class="k">=</span> <span class="o">{</span>
  <span class="k">val</span> <span class="nv">name</span> <span class="k">=</span> <span class="nv">s</span><span class="o">.</span><span class="py">tree</span><span class="o">.</span><span class="py">symbol</span><span class="o">.</span><span class="py">fullName</span>
  <span class="nv">c</span><span class="o">.</span><span class="py">Expr</span><span class="o">(</span><span class="nv">c</span><span class="o">.</span><span class="py">parse</span><span class="o">(</span><span class="n">s</span><span class="s">""" "Name of var is: $name" """</span><span class="o">))</span>
<span class="o">}</span>

<span class="k">def</span> <span class="nf">macroTest</span><span class="o">(</span><span class="n">s</span><span class="k">:</span> <span class="kt">String</span><span class="o">)</span><span class="k">:</span> <span class="kt">String</span> <span class="o">=</span> <span class="n">macro</span> <span class="n">macroImpl</span>
</code></pre></div></div>

<p>Then use it like this:</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">a</span> <span class="k">=</span> <span class="s">"abc"</span>
<span class="nf">println</span><span class="o">(</span><span class="nf">macroTest</span><span class="o">(</span><span class="n">a</span><span class="o">))</span>
</code></pre></div></div>

<p>It will print out:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Name of var is: me.binwang.archmage.coretest.MethodMetaTest.a
</code></pre></div></div>

<p>Note the output is at run time instead of compile time like the examples in the last section, because we’ve replaced the tree with new code.</p>

<h3 id="53-use-reify">5.3 Use <code class="language-plaintext highlighter-rouge">reify</code></h3>

<p><code class="language-plaintext highlighter-rouge">c.parse</code> is easy to use and understand. But when generating more and more code with it, it can be pretty messy since it is just a string. There is no syntax checks in IDE. Even worse, you cannot get any run time information to use in the generated tree.</p>

<p><code class="language-plaintext highlighter-rouge">reify</code> is a much better option. You can write code as usual. The code in <code class="language-plaintext highlighter-rouge">reify</code> block is the code that will be generated. You can refer to another <code class="language-plaintext highlighter-rouge">Expr</code> (in the old tree) by using its <code class="language-plaintext highlighter-rouge">.splice</code> method. Here is an example to print out both the variable name and it’s value:</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">macroImpl</span><span class="o">(</span><span class="n">c</span><span class="k">:</span> <span class="kt">blackbox.Context</span><span class="o">)(</span><span class="n">s</span><span class="k">:</span> <span class="kt">c.Expr</span><span class="o">[</span><span class="kt">String</span><span class="o">])</span><span class="k">:</span> <span class="kt">c.Expr</span><span class="o">[</span><span class="kt">String</span><span class="o">]</span> <span class="k">=</span> <span class="o">{</span>
  <span class="k">import</span> <span class="nn">c.universe._</span>
  <span class="k">val</span> <span class="nv">name</span> <span class="k">=</span> <span class="nv">c</span><span class="o">.</span><span class="py">Expr</span><span class="o">(</span><span class="nv">c</span><span class="o">.</span><span class="py">parse</span><span class="o">(</span><span class="s">"\""</span> <span class="o">+</span> <span class="nv">s</span><span class="o">.</span><span class="py">tree</span><span class="o">.</span><span class="py">symbol</span><span class="o">.</span><span class="py">fullName</span> <span class="o">+</span> <span class="s">"\""</span><span class="o">))</span>
  <span class="n">reify</span> <span class="o">{</span>
    <span class="n">s</span><span class="s">"${name.splice}: ${s.splice}"</span>
  <span class="o">}</span>
<span class="o">}</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">macroTest</code> and the test code is the same above. Running the test code will get output like this:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>me.binwang.archmage.coretest.MethodMetaTest.a: abc
</code></pre></div></div>

<h3 id="54-use-quasiquotes">5.4 Use Quasiquotes</h3>

<p>As we’ve seen in section 4.5, <code class="language-plaintext highlighter-rouge">q"..."</code> can be used to match a tree. It can be used to generate a tree as well. For example, in the following code:</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">macroImpl</span><span class="o">(</span><span class="n">c</span><span class="k">:</span> <span class="kt">blackbox.Context</span><span class="o">)(</span><span class="n">s</span><span class="k">:</span> <span class="kt">c.Tree</span><span class="o">)</span> <span class="k">=</span> <span class="o">{</span>
  <span class="k">import</span> <span class="nn">c.universe._</span>
  <span class="k">val</span> <span class="nv">q</span><span class="s">"if ($cond) $thenp else $elsep"</span> <span class="k">=</span> <span class="n">s</span>
  <span class="n">q</span><span class="s">"if ($cond) $elsep else $thenp"</span>
<span class="o">}</span>

<span class="k">def</span> <span class="nf">macroTest</span><span class="o">[</span><span class="kt">T</span><span class="o">](</span><span class="n">s</span><span class="k">:</span> <span class="kt">T</span><span class="o">)</span><span class="k">:</span> <span class="kt">T</span> <span class="o">=</span> <span class="n">macro</span> <span class="n">macroImpl</span>
</code></pre></div></div>

<p>It uses the parts that have been matched by <code class="language-plaintext highlighter-rouge">q"..."</code> and generates a new tree using those parts. It swaps the if and else clause. Run it with this test code:</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">macroTest</span><span class="o">(</span><span class="nf">if</span> <span class="o">(</span><span class="kc">true</span><span class="o">)</span> <span class="nf">println</span><span class="o">(</span><span class="s">"a"</span><span class="o">)</span> <span class="k">else</span> <span class="nf">println</span><span class="o">(</span><span class="s">"b"</span><span class="o">))</span>
</code></pre></div></div>

<p>It will print <code class="language-plaintext highlighter-rouge">b</code> instead of <code class="language-plaintext highlighter-rouge">a</code>.</p>

<h3 id="55-avoid-name-conflict">5.5 Avoid Name Conflict</h3>

<p>When generating a new tree, we may generate some variables that have conflict names with the existing ones. Use <code class="language-plaintext highlighter-rouge">c.freshName</code> to get a unique name to avoid the conflict.</p>

<h3 id="56-type-checked-and-unchecked-tree">5.6 Type Checked and Unchecked Tree</h3>

<p>There are two kinds of AST in Scala’s internal compiler: type checked and unchecked. See more details in <a href="https://stackoverflow.com/questions/20936509/scala-macros-what-is-the-difference-between-typed-aka-typechecked-and-untyped">this Stack Overflow answer</a>. Some APIs can only accept either type checked or unchecked tree. And sometimes the compiler throws out weird errors if using the wrong type of tree. If that’s the case, try to use <code class="language-plaintext highlighter-rouge">c.untypecheck</code> and <code class="language-plaintext highlighter-rouge">c.typecheck</code> to covert trees.</p>

<p>For example, here is some code that cannot be compiled:</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">macroImpl</span><span class="o">(</span><span class="n">c</span><span class="k">:</span> <span class="kt">blackbox.Context</span><span class="o">)(</span><span class="n">blockTree</span><span class="k">:</span> <span class="kt">c.Tree</span><span class="o">)</span> <span class="k">:</span> <span class="kt">c.Expr</span><span class="o">[</span><span class="kt">Seq</span><span class="o">[</span><span class="kt">String</span><span class="o">]]</span> <span class="k">=</span> <span class="o">{</span>
  <span class="k">import</span> <span class="nn">c.universe._</span>
  <span class="k">val</span> <span class="nv">block</span> <span class="k">=</span> <span class="nv">c</span><span class="o">.</span><span class="py">Expr</span><span class="o">[</span><span class="kt">Seq</span><span class="o">[</span><span class="kt">String</span><span class="o">]](</span><span class="n">blockTree</span><span class="o">)</span>
  <span class="n">reify</span> <span class="o">{</span>
    <span class="nc">Seq</span><span class="o">(</span><span class="s">"a"</span><span class="o">).</span><span class="py">flatMap</span><span class="o">{</span><span class="k">_</span> <span class="k">=&gt;</span> <span class="nv">block</span><span class="o">.</span><span class="py">splice</span><span class="o">}</span>
  <span class="o">}</span>
<span class="o">}</span>

<span class="k">def</span> <span class="nf">macroTest</span><span class="o">(</span><span class="n">blockTree</span><span class="k">:</span> <span class="o">=&gt;</span> <span class="nc">Seq</span><span class="o">[</span><span class="kt">String</span><span class="o">])</span><span class="k">:</span> <span class="kt">Seq</span><span class="o">[</span><span class="kt">String</span><span class="o">]</span> <span class="k">=</span> <span class="n">macro</span> <span class="n">macroImpl</span>

<span class="c1">// Testing code in another sub project:</span>
<span class="k">val</span> <span class="nv">s</span> <span class="k">=</span> <span class="s">"abc"</span>
<span class="n">macroTest</span> <span class="o">{</span>
  <span class="k">val</span> <span class="nv">a</span> <span class="k">=</span> <span class="n">s</span>
  <span class="nc">Seq</span><span class="o">(</span><span class="n">a</span><span class="o">)</span>
<span class="o">}</span>
</code></pre></div></div>

<p>The compiler will throw error:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[error] Error while emitting XXX.scala
[error] value a
[error] one error found
</code></pre></div></div>

<p>To fix this, we need to convert <code class="language-plaintext highlighter-rouge">blockTree</code> to unchecked tree:</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">macroImpl</span><span class="o">(</span><span class="n">c</span><span class="k">:</span> <span class="kt">blackbox.Context</span><span class="o">)(</span><span class="n">blockTree</span><span class="k">:</span> <span class="kt">c.Tree</span><span class="o">)</span> <span class="k">:</span> <span class="kt">c.Expr</span><span class="o">[</span><span class="kt">Seq</span><span class="o">[</span><span class="kt">String</span><span class="o">]]</span> <span class="k">=</span> <span class="o">{</span>
  <span class="k">import</span> <span class="nn">c.universe._</span>
  <span class="k">val</span> <span class="nv">cleanedBlock</span> <span class="k">=</span> <span class="nv">c</span><span class="o">.</span><span class="py">untypecheck</span><span class="o">(</span><span class="nv">blockTree</span><span class="o">.</span><span class="py">duplicate</span><span class="o">)</span>
  <span class="k">val</span> <span class="nv">block</span> <span class="k">=</span> <span class="nv">c</span><span class="o">.</span><span class="py">Expr</span><span class="o">[</span><span class="kt">Seq</span><span class="o">[</span><span class="kt">String</span><span class="o">]](</span><span class="n">cleanedBlock</span><span class="o">)</span>
  <span class="n">reify</span> <span class="o">{</span>
    <span class="nc">Seq</span><span class="o">(</span><span class="s">"a"</span><span class="o">).</span><span class="py">flatMap</span><span class="o">{</span><span class="k">_</span> <span class="k">=&gt;</span> <span class="nv">block</span><span class="o">.</span><span class="py">splice</span><span class="o">}</span>
  <span class="o">}</span>
<span class="o">}</span>
</code></pre></div></div>]]></content><author><name></name></author><category term="Scala" /><category term="macro" /><category term="meta programming" /><category term="AOP" /><summary type="html"><![CDATA[Macros are powerful but complex. Especially when the language itself like Scala is already complex. The lack of learning resource and documents makes it more so. In this article, I’ll write down some of my learnings and hopefully it can help someone else who is new to it as well. I’ll keep the examples small and simple so it’s easier to understand. Since I’m still learning it, I may continue to update this article on the way, or write a new article if there is a big topic. Either way, I’ll make notes here so you know there are updates.]]></summary></entry><entry><title type="html">ZFS Profiling on Arch Linux</title><link href="https://www.binwang.me/2023-12-14-ZFS-Profiling-on-Arch-Linux.html" rel="alternate" type="text/html" title="ZFS Profiling on Arch Linux" /><published>2023-12-14T00:00:00-05:00</published><updated>2023-12-14T00:00:00-05:00</updated><id>https://www.binwang.me/ZFS-Profiling-on-Arch-Linux</id><content type="html" xml:base="https://www.binwang.me/2023-12-14-ZFS-Profiling-on-Arch-Linux.html"><![CDATA[<p>I bought a new video game recently but found <code class="language-plaintext highlighter-rouge">z_rd_int</code> processes took almost all the CPU time when I was playing it. That doesn’t make much sense to me since I install games on a non compressed ZFS dataset. Even though I don’t have a powerful CPU, I don’t expect ZFS to use all of them and only reads about 60-70MiB/s from each of the NVME SSDs. To double check, I used <code class="language-plaintext highlighter-rouge">iostat -x 1</code> to confirm the iowait is very low. So disk IO is not the bottleneck.</p>

<p>Without finding any root cause from Internet, I decide to do some profiling by myself. From OpenZFS’ Github issues, people are using <a href="https://perf.wiki.kernel.org/index.php/Main_Page">perf</a> to do profiling. It is trivial enough to do it from a glance. But let <code class="language-plaintext highlighter-rouge">perf</code> showing debug symbols for ZFS spent me a lot of time. So in this article, I will document the steps to enable debug symbols for ZFS and hopefully it can help more people that facing difficulties to do it. After that, I will continue with how do I find the root cause and the solution. If you’ve seen my previous blog <a href="/2023-09-30-A-Boring-JVM-Memory-Profiling-Story.html">A Boring JVM Memory Profiling Story</a>, this is an even more boring profiling story. But the tool set is important. Use them efficiently and hopefully all the profiling stories become boring.</p>

<h2 id="1-enable-debug-info-for-zfs">1. Enable Debug Info for ZFS</h2>

<p>On Arch Linux, if you run <code class="language-plaintext highlighter-rouge">perf top</code>, you can see kernel has debug symbols attached like this:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>2.95%  [kernel]                                        [k] entry_SYSCALL_64
</code></pre></div></div>

<p>But for some other processes like zfs ones, it only has an address like this:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>2.65%  [zfs]                                           [k] 0x00000000002990cf
</code></pre></div></div>

<p>This is because perf cannot find debug info for zfs module. Let’s enable it now.</p>

<h3 id="11-use-dkms-package">1.1 Use DKMS Package</h3>

<p>First we need to use <a href="https://wiki.archlinux.org/title/Dynamic_Kernel_Module_Support">DKMS</a> package instead a pre compiled one so that we can control the compiling behaviour when build the zfs kernel module. In Arch Linux, the package name is <code class="language-plaintext highlighter-rouge">zfs-dkms</code> either in AUR or <a href="https://github.com/archzfs/archzfs">archzfs</a> repo. Be aware packages are different from those different repos even they have the same name. Personally I like archzfs repo more since it’s more well maintained and has better dependency management.</p>

<h3 id="12-enable-debuginfo-flags">1.2 Enable debuginfo Flags</h3>

<h4 id="tldr">TL;DR:</h4>

<p>Add these three lines to <code class="language-plaintext highlighter-rouge">/etc/sysconfig/zfs</code>, (re)install the zfs dkms package and reboot.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">ZFS_DKMS_ENABLE_DEBUG</span><span class="o">=</span>y
<span class="nv">ZFS_DKMS_ENABLE_DEBUGINFO</span><span class="o">=</span>y
<span class="nv">ZFS_DKMS_DISABLE_STRIP</span><span class="o">=</span>y
</code></pre></div></div>

<p>Decompress the installed ko file.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo </span>unzstd /lib/modules/&lt;your kernel version&gt;/updates/dkms/zfs.ko.zst
</code></pre></div></div>

<p>Now you should be able to see zfs symbols in <code class="language-plaintext highlighter-rouge">perf top</code>.</p>

<p>Remember to cleanup the files after profiling.</p>

<p>If you care about the reason behind these changes, continue reading. Otherwise you can skip the remaining of this section.</p>

<h4 id="what-is-etcsysconfigzfs">What is <code class="language-plaintext highlighter-rouge">/etc/sysconfig/zfs</code>?</h4>

<p>The package <code class="language-plaintext highlighter-rouge">zfs-dkms</code> only installs the code that will be compiled by dkms to <code class="language-plaintext highlighter-rouge">/usr/src/zfs-&lt;zfs-version&gt;</code>. (I learned this by reading <code class="language-plaintext highlighter-rouge">PKGBUILD</code> of the aur package). Then when <code class="language-plaintext highlighter-rouge">dkms</code> commands are run, <code class="language-plaintext highlighter-rouge">dkms</code> copies the files to <code class="language-plaintext highlighter-rouge">/var/lib/dkms/zfs/&lt;zfs-version&gt;/build</code> to build it and then install the built ko files to <code class="language-plaintext highlighter-rouge">/lib/modules/&lt;your kernel version&gt;/updates/dkms</code>. So in order to build zfs module with debug symbols, we need to let dkms uses correct compile flags.</p>

<p>Under <code class="language-plaintext highlighter-rouge">/usr/src/zfs-&lt;zfs-version&gt;</code>, there is <code class="language-plaintext highlighter-rouge">dkms.conf</code> that tells DKMS how to use the source code to build and install modules. We can find some key information there:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">PRE_BUILD</span><span class="o">=</span><span class="s2">"configure
  --prefix=/usr
  --with-config=kernel
  --with-linux=</span><span class="se">\$</span><span class="s2">(
    if [ -e "</span><span class="se">\$</span><span class="o">{</span>kernel_source_dir/%build/source<span class="o">}</span><span class="s2">" ]
    then
      echo "</span><span class="se">\$</span><span class="o">{</span>kernel_source_dir/%build/source<span class="o">}</span><span class="s2">"
    else
      echo "</span><span class="se">\$</span><span class="o">{</span>kernel_source_dir<span class="o">}</span><span class="s2">"
    fi
  )
  --with-linux-obj="</span><span class="se">\$</span><span class="o">{</span>kernel_source_dir<span class="o">}</span><span class="s2">"
  </span><span class="se">\$</span><span class="s2">(
    [[ -n </span><span class="se">\"\$</span><span class="s2">{ICP_ROOT}</span><span class="se">\"</span><span class="s2"> ]] &amp;&amp; </span><span class="se">\\</span><span class="s2">
    {
      echo --with-qat=</span><span class="se">\"\$</span><span class="s2">{ICP_ROOT}</span><span class="se">\"</span><span class="s2">
    }
  )
  </span><span class="se">\$</span><span class="s2">(
    [[ -r </span><span class="se">\$</span><span class="s2">{PACKAGE_CONFIG} ]] </span><span class="se">\\</span><span class="s2">
    &amp;&amp; source </span><span class="se">\$</span><span class="s2">{PACKAGE_CONFIG} </span><span class="se">\\</span><span class="s2">
    &amp;&amp; shopt -q -s extglob </span><span class="se">\\</span><span class="s2">
    &amp;&amp; </span><span class="se">\\</span><span class="s2">
    {
      if [[ </span><span class="se">\$</span><span class="s2">{ZFS_DKMS_ENABLE_DEBUG,,} == @(y|yes) ]]
      then
        echo --enable-debug
      fi
      if [[ </span><span class="se">\$</span><span class="s2">{ZFS_DKMS_ENABLE_DEBUGINFO,,} == @(y|yes) ]]
      then
        echo --enable-debuginfo
      fi
    }
  )
"</span>
</code></pre></div></div>

<p>There is <code class="language-plaintext highlighter-rouge">--enable-debug</code> and <code class="language-plaintext highlighter-rouge">--enable-debuginfo</code>. Run <code class="language-plaintext highlighter-rouge">./configure --help</code> shows the meaning of these two flags:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  --enable-debug          Enable compiler and code assertions [default=no]
  --enable-debuginfo      Force generation of debuginfo [default=no]
</code></pre></div></div>

<p>So if those two flags are enabled, the zfs module should be built with debug info. The code above checks <code class="language-plaintext highlighter-rouge">ZFS_DKMS_ENABLE_DEBUG</code> and <code class="language-plaintext highlighter-rouge">ZFS_DKMS_ENABLE_DEBUGINFO</code> in file <code class="language-plaintext highlighter-rouge">${PACKAGE_CONFIG}</code>. If they are <code class="language-plaintext highlighter-rouge">y</code> or <code class="language-plaintext highlighter-rouge">yes</code>, the corresponding flags are enabled. At the beginning of <code class="language-plaintext highlighter-rouge">dkms.conf</code> we can find <code class="language-plaintext highlighter-rouge">PACKAGE_CONFIG</code> is defined as <code class="language-plaintext highlighter-rouge">/etc/sysconfig/zfs</code>.</p>

<p>However, only defining <code class="language-plaintext highlighter-rouge">ZFS_DKMS_ENABLE_DEBUG</code> and <code class="language-plaintext highlighter-rouge">ZFS_DKMS_ENABLE_DEBUGINFO</code> is not enough. I learnt it the hard way. Checking <code class="language-plaintext highlighter-rouge">dkms.conf</code> more closely, we can see these code below:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>STRIP[0]<span class="o">=</span><span class="s2">"</span><span class="se">\$</span><span class="s2">(
  [[ -r </span><span class="se">\$</span><span class="s2">{PACKAGE_CONFIG} ]] </span><span class="se">\\</span><span class="s2">
  &amp;&amp; source </span><span class="se">\$</span><span class="s2">{PACKAGE_CONFIG} </span><span class="se">\\</span><span class="s2">
  &amp;&amp; shopt -q -s extglob </span><span class="se">\\</span><span class="s2">
  &amp;&amp; [[ </span><span class="se">\$</span><span class="s2">{ZFS_DKMS_DISABLE_STRIP,,} == @(y|yes) ]] </span><span class="se">\\</span><span class="s2">
  &amp;&amp; echo -n no
)"</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">man dkms</code> shows the meaning of <code class="language-plaintext highlighter-rouge">STRIP</code>:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>STRIP[#]=
       By default strip is considered to be "yes". If set to  "no",  DKMS  will
       not  run strip -g against your built module to remove debug symbols from
       it.  STRIP[0] is used as the default for any unset entries in the  STRIP
       array.
</code></pre></div></div>

<p>If <code class="language-plaintext highlighter-rouge">STRIP</code> is not set to <code class="language-plaintext highlighter-rouge">no</code>, <code class="language-plaintext highlighter-rouge">dkms</code> will stripe the debug info! So we also need to set <code class="language-plaintext highlighter-rouge">ZFS_DKMS_DISABLE_STRIP</code> in <code class="language-plaintext highlighter-rouge">/etc/sysconfig/zfs</code> to <code class="language-plaintext highlighter-rouge">y</code> or <code class="language-plaintext highlighter-rouge">yes</code> so that <code class="language-plaintext highlighter-rouge">STRIP[0]</code> will be <code class="language-plaintext highlighter-rouge">no</code>.</p>

<h4 id="why-unzstd">Why unzstd?</h4>

<p>In my system, the dkms modules are compressed with zstd when installing. But it seems <code class="language-plaintext highlighter-rouge">perf</code> is not able to read the compressed module file in order to find the debug symbols, so we need to uncompress it at the same location.</p>

<h2 id="2-profiling-zfs">2. Profiling ZFS</h2>

<p><code class="language-plaintext highlighter-rouge">perf top</code> can show the CPU usage for each function in real time. But in order to analysis it better, we can record it with <code class="language-plaintext highlighter-rouge">perf record -g -p &lt;pid&gt;</code>. It should generate <code class="language-plaintext highlighter-rouge">perf.data</code> file in the current directory. Press <code class="language-plaintext highlighter-rouge">Ctrl + C</code> to stop the recording and flush the file.</p>

<p>Then use <code class="language-plaintext highlighter-rouge">sudo perf report</code> to show the report of the recording. Mine is like this (press <code class="language-plaintext highlighter-rouge">+</code> to extend a row of interest in <code class="language-plaintext highlighter-rouge">perf report</code>):</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Samples: 277K of event 'cycles:P', Event count (approx.): 244633155596
Children      Self  Command   Shared Object     Symbol
+   96.59%     0.01%  z_rd_int  [zfs]             [k] zio_do_crypt_uio
+   96.58%     0.00%  z_rd_int  [zfs]             [k] crypto_decrypt
+   96.57%     0.01%  z_rd_int  [zfs]             [k] aes_decrypt_atomic
+   75.53%     8.17%  z_rd_int  [zfs]             [k] aes_encrypt_block
+   49.76%     0.00%  z_rd_int  [zfs]             [k] crypto_update_uio
+   49.76%     0.00%  z_rd_int  [zfs]             [k] aes_decrypt_contiguous_blocks
+   49.76%     4.52%  z_rd_int  [zfs]             [k] ccm_mode_decrypt_contiguous_blocks
+   46.42%     2.08%  z_rd_int  [zfs]             [k] ccm_decrypt_final
+   42.15%     6.94%  z_rd_int  [zfs]             [k] aes_aesni_encrypt
-   24.72%    24.36%  z_rd_int  [zfs]             [k] kfpu_end
     24.36% ret_from_fork_asm
        ret_from_fork
        kthread
        0xffffffffc02b15eb
        zio_execute
        zio_done
        zio_pop_transforms
        zio_decrypt
        spa_do_crypt_abd
        zio_do_crypt_data
        zio_do_crypt_uio
        crypto_decrypt
      + aes_decrypt_atomic
-   21.20%    20.96%  z_rd_int  [zfs]             [k] kfpu_begin
     20.96% ret_from_fork_asm
        ret_from_fork
        kthread
        0xffffffffc02b15eb
        zio_execute
        zio_done
        zio_pop_transforms
        zio_decrypt
        spa_do_crypt_abd
        zio_do_crypt_data
        zio_do_crypt_uio
        crypto_decrypt
      + aes_decrypt_atomic
+   14.42%    14.21%  z_rd_int  [zfs]             [k] aes_encrypt_intel
+    7.36%     7.14%  z_rd_int  [zfs]             [k] aes_xor_block
+    6.31%     6.16%  z_rd_int  [zfs]             [k] aes_copy_block
+    1.27%     0.03%  z_rd_int  [zfs]             [k] arc_read_done
+    1.17%     0.02%  z_rd_int  [zfs]             [k] zio_vdev_io_done
+    1.14%     0.00%  z_rd_int  [zfs]             [k] abd_iterate_func
</code></pre></div></div>

<h2 id="3-find-root-cause">3. Find Root Cause</h2>

<p>From the profiling report, we can easily see that the CPU is mostly used on decrypting the content on ZFS. That makes some sense because decryption do need CPU power. But there is no reason it uses so much CPU at that throughput. In fact found some performance issues related encryption and did something to rule out some causes:</p>

<ol>
  <li>I made sure the AES hardware acceleration is enabled for my CPU by checking <code class="language-plaintext highlighter-rouge">lscpu | grep aes</code>.</li>
  <li>My system can decrypt and encrypt at a much higher speed (2000+ MB/s) by running <code class="language-plaintext highlighter-rouge">cryptsetup benchmark</code>.</li>
</ol>

<p>That’s why I need the profiling to confirm where the bottleneck comes from.</p>

<p>Even though the code path is related to decryption, the hotspot is at <code class="language-plaintext highlighter-rouge">kfpu_begin</code> and <code class="language-plaintext highlighter-rouge">kfpu_end</code>. I read the code and have totally no idea what they are doing. I asked ChatGPT and it explains to me that it’s saving and restoring FPU state. I don’t know if its answer is correct or not, but that at least gave me some direction to search issues. At last I found this Github issue <a href="https://github.com/openzfs/zfs/pull/9749">ICP: Improve AES-GCM performance</a>. It says exactly that there is performance issue with saving FPU state when doing encryption. And the PR improves it for AES-GCM algorithm. It states AES-CCM can benifit from similar fix but the performance improvement will not be as great. So in the discussion of the PR, they decide to change the default encryption algorithm to AES-GCM instead of AES-CCM.</p>

<p>I <a href="/2020-01-28-Migrate-Arch-Linux-to-Zfs.html">started use zfs</a> before this PR. So I checked the encryption algorithm on my system by <code class="language-plaintext highlighter-rouge">zfs get all &lt;dataset&gt; | grep encryption</code>. And it is indeed using AES-CCM. In order to confirm it is causing performance issue, I did some benchmark on AES-CCM, AES-GCM and not encrypted datasets.</p>

<p>First, created the datasets:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo </span>zfs create <span class="nt">-o</span> <span class="nv">encryption</span><span class="o">=</span>aes-256-ccm <span class="nt">-o</span> <span class="nv">compression</span><span class="o">=</span>off <span class="nt">-o</span> <span class="nv">atime</span><span class="o">=</span>off zroot/root/ccm-test
<span class="nb">sudo </span>zfs create <span class="nt">-o</span> <span class="nv">encryption</span><span class="o">=</span>aes-256-gcm <span class="nt">-o</span> <span class="nv">compression</span><span class="o">=</span>off <span class="nt">-o</span> <span class="nv">atime</span><span class="o">=</span>off zroot/root/gcm-test
<span class="nb">sudo </span>zfs create <span class="nt">-o</span> <span class="nv">encryption</span><span class="o">=</span>off <span class="nt">-o</span> <span class="nv">compression</span><span class="o">=</span>off <span class="nt">-o</span> <span class="nv">atime</span><span class="o">=</span>off zroot/local_steam_unencrypt
</code></pre></div></div>

<p>Then I write a script to benchmark it:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/bin/bash</span>

<span class="nb">set</span> <span class="nt">-e</span>

<span class="k">function </span>print_cputime<span class="o">()</span> <span class="o">{</span>
	<span class="nv">pname</span><span class="o">=</span><span class="nv">$1</span>
	<span class="k">for </span>pid <span class="k">in</span> <span class="sb">`</span>pgrep <span class="nv">$pname</span><span class="sb">`</span> <span class="p">;</span> <span class="k">do
		</span>ps <span class="nt">-p</span> <span class="nv">$pid</span> <span class="nt">-o</span> cputime,etime
	<span class="k">done</span>
<span class="o">}</span>


<span class="k">function </span>benchmark <span class="o">{</span>
	<span class="nv">test_name</span><span class="o">=</span><span class="nv">$1</span>
	<span class="nv">test_file</span><span class="o">=</span><span class="nv">$2</span>

	<span class="nv">file_size</span><span class="o">=</span><span class="s2">"20480"</span>

	<span class="nb">echo</span> <span class="s2">"### Start benchmark </span><span class="nv">$test_name</span><span class="s2">"</span>

	<span class="nb">echo</span> <span class="s2">"### Print z_wr_iss cpu time before the write test"</span>
	print_cputime z_wr_iss
	<span class="nb">echo</span> <span class="s2">"### Start write test"</span>
	<span class="nb">time dd </span><span class="k">if</span><span class="o">=</span>/dev/random <span class="nv">of</span><span class="o">=</span><span class="nv">$test_file</span> <span class="nv">bs</span><span class="o">=</span>1M <span class="nv">count</span><span class="o">=</span><span class="nv">$file_size</span> <span class="nv">oflag</span><span class="o">=</span>direct
	<span class="nb">echo</span> <span class="s2">"### Pring z_wr_iss cpu time afte the write test"</span>
	print_cputime z_wr_iss

	<span class="nb">echo</span> <span class="s2">"### Print z_rd_int cpu time before the read test"</span>
	print_cputime z_rd_int
	<span class="nb">echo</span> <span class="s2">"### Start read test"</span>
	<span class="nb">time dd </span><span class="k">if</span><span class="o">=</span><span class="nv">$test_file</span> <span class="nv">of</span><span class="o">=</span>/dev/null <span class="nv">bs</span><span class="o">=</span>1M <span class="nv">count</span><span class="o">=</span><span class="nv">$file_size</span>
	<span class="nb">echo</span> <span class="s2">"### Print z_rd_int cpu time before the read test"</span>
	print_cputime z_rd_int
<span class="o">}</span>

benchmark ccm-test /ccm-test/test-file
benchmark gcm-test /gcm-test/test-file
benchmark non-encrypt-test /data/local_steam/test-file
</code></pre></div></div>

<p>My ZFS cache is set to 8GB. So I write and read files with 20GB. It uses dd to write and read a file. Before the read and write, it uses <code class="language-plaintext highlighter-rouge">ps -o cputime,etime</code> to print out CPU time and wall time used by each related ZFS processes.</p>

<p>Running this script creates lots of output. The full output can be found in the appendix at the end. Here are the key lines:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>### Start benchmark ccm-test
// ... output omitted ...
21474836480 bytes (21 GB, 20 GiB) copied, 107.307 s, 200 MB/s
// ... output omitted ...
### Start benchmark gcm-test
// ... output omitted ...
21474836480 bytes (21 GB, 20 GiB) copied, 13.7417 s, 1.6 GB/s
// ... output omitted ...
### Start benchmark non-encrypt-test
// ... output omitted ...
21474836480 bytes (21 GB, 20 GiB) copied, 9.03496 s, 2.4 GB/s
// ... output omitted ...
</code></pre></div></div>

<p>During the test, AES-CCM makes <code class="language-plaintext highlighter-rouge">z_rd_int</code> takes all CPU time as observed before. For AES-GCM, it’s much better, <code class="language-plaintext highlighter-rouge">z_rd_int</code> takes less than 50% and for non encrypted it’s less than 20%. The testing output prints the CPU time and wall time for each of the <code class="language-plaintext highlighter-rouge">z_rd_int</code> processes before and after the test. So you can count the percentage.</p>

<p>From the test result, we can see AES-CCM indeed affect read performance a lot. It’s even slower than writes. We can confirm this is the root cause for our problem.</p>

<h2 id="4-solution-and-workaround">4. Solution and Workaround</h2>

<p>The solution is obvious: just change the encryption from AES-CCM to AES-GCM. But it cannot be done without migrating the dataset to another place and then move it back. It takes time. At the mean time, I moved my Steam library to a non encrypted dataset since I have enough disk space to do the migration. It doesn’t have sensitive information. Yes it exposes the machine to <a href="https://en.wikipedia.org/wiki/Evil_maid_attack">evil maid attack</a>, but my setup on the machine doesn’t prevent it anyway. See my previous blog <a href="/2021-09-19-Personal-ZFS-Offsite-Online-Backup-Solution.html">Personal ZFS Offsite Backup Solution</a> for more information on putting a machine into a not trusted environment.</p>

<p>I’ll do the migration from AES-CCM to AES-GCM in the future and report back how it works. Stay tuned!</p>

<h2 id="5-appendix">5. Appendix</h2>

<p>Here is the full output from the benchmark script:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>### Start benchmark ccm-test
### Print z_wr_iss cpu time before the write test
    TIME     ELAPSED
00:47:56  3-03:39:21
    TIME     ELAPSED
00:22:34  3-03:39:21
    TIME     ELAPSED
00:47:54  3-03:39:21
    TIME     ELAPSED
00:47:55  3-03:39:21
    TIME     ELAPSED
00:00:01  3-03:39:17
    TIME     ELAPSED
00:00:00  3-03:39:17
    TIME     ELAPSED
00:04:50    15:30:06
    TIME     ELAPSED
00:04:49    15:29:57
    TIME     ELAPSED
00:04:51    15:29:56
    TIME     ELAPSED
00:04:51    15:29:18
    TIME     ELAPSED
00:00:00    10:07:30
    TIME     ELAPSED
00:00:00       55:49
### Start write test
20480+0 records in
20480+0 records out
21474836480 bytes (21 GB, 20 GiB) copied, 91.4066 s, 235 MB/s

real	1m31.414s
user	0m0.059s
sys	0m53.252s
### Pring z_wr_iss cpu time afte the write test
    TIME     ELAPSED
00:49:23  3-03:40:53
    TIME     ELAPSED
00:22:34  3-03:40:53
    TIME     ELAPSED
00:49:21  3-03:40:53
    TIME     ELAPSED
00:49:22  3-03:40:53
    TIME     ELAPSED
00:00:01  3-03:40:49
    TIME     ELAPSED
00:00:00  3-03:40:49
    TIME     ELAPSED
00:04:50    15:31:38
    TIME     ELAPSED
00:04:50    15:31:28
    TIME     ELAPSED
00:04:51    15:31:28
    TIME     ELAPSED
00:04:51    15:30:50
    TIME     ELAPSED
00:00:00    10:09:01
    TIME     ELAPSED
00:00:00       57:21
### Print z_rd_int cpu time before the read test
    TIME     ELAPSED
00:24:46  3-03:40:53
    TIME     ELAPSED
00:00:02  3-03:40:49
    TIME     ELAPSED
00:01:50       06:47
    TIME     ELAPSED
00:01:49       06:47
### Start read test
20480+0 records in
20480+0 records out
21474836480 bytes (21 GB, 20 GiB) copied, 107.307 s, 200 MB/s

real	1m47.372s
user	0m0.060s
sys	0m8.091s
### Print z_rd_int cpu time after the read test
    TIME     ELAPSED
00:26:24  3-03:42:41
    TIME     ELAPSED
00:00:02  3-03:42:37
    TIME     ELAPSED
00:03:28       08:34
    TIME     ELAPSED
00:03:27       08:34
### Start benchmark gcm-test
### Print z_wr_iss cpu time before the write test
    TIME     ELAPSED
00:49:35  3-03:42:41
    TIME     ELAPSED
00:22:34  3-03:42:41
    TIME     ELAPSED
00:49:33  3-03:42:41
    TIME     ELAPSED
00:49:33  3-03:42:41
    TIME     ELAPSED
00:00:01  3-03:42:37
    TIME     ELAPSED
00:00:00  3-03:42:37
    TIME     ELAPSED
00:04:50    15:33:26
    TIME     ELAPSED
00:04:50    15:33:16
    TIME     ELAPSED
00:04:51    15:33:16
    TIME     ELAPSED
00:04:51    15:32:38
    TIME     ELAPSED
00:00:00    10:10:49
    TIME     ELAPSED
00:00:00       59:08
### Start write test
20480+0 records in
20480+0 records out
21474836480 bytes (21 GB, 20 GiB) copied, 56.9529 s, 377 MB/s

real	0m56.960s
user	0m0.045s
sys	0m53.566s
### Pring z_wr_iss cpu time afte the write test
    TIME     ELAPSED
00:49:42  3-03:43:38
    TIME     ELAPSED
00:22:35  3-03:43:38
    TIME     ELAPSED
00:49:39  3-03:43:38
    TIME     ELAPSED
00:49:39  3-03:43:38
    TIME     ELAPSED
00:00:01  3-03:43:34
    TIME     ELAPSED
00:00:00  3-03:43:34
    TIME     ELAPSED
00:04:51    15:34:23
    TIME     ELAPSED
00:04:50    15:34:14
    TIME     ELAPSED
00:04:52    15:34:13
    TIME     ELAPSED
00:04:52    15:33:35
    TIME     ELAPSED
00:00:00    10:11:46
    TIME     ELAPSED
00:00:00    01:00:06
### Print z_rd_int cpu time before the read test
    TIME     ELAPSED
00:26:24  3-03:43:38
    TIME     ELAPSED
00:00:02  3-03:43:34
    TIME     ELAPSED
00:00:00       00:05
    TIME     ELAPSED
00:00:00       00:05
### Start read test
20480+0 records in
20480+0 records out
21474836480 bytes (21 GB, 20 GiB) copied, 13.7417 s, 1.6 GB/s

real	0m13.743s
user	0m0.071s
sys	0m11.215s
### Print z_rd_int cpu time after the read test
    TIME     ELAPSED
00:26:31  3-03:43:52
    TIME     ELAPSED
00:00:02  3-03:43:48
    TIME     ELAPSED
00:00:07       00:19
    TIME     ELAPSED
00:00:07       00:19
### Start benchmark non-encrypt-test
### Print z_wr_iss cpu time before the write test
    TIME     ELAPSED
00:49:42  3-03:43:52
    TIME     ELAPSED
00:22:35  3-03:43:52
    TIME     ELAPSED
00:49:40  3-03:43:52
    TIME     ELAPSED
00:49:39  3-03:43:52
    TIME     ELAPSED
00:00:01  3-03:43:48
    TIME     ELAPSED
00:00:00  3-03:43:48
    TIME     ELAPSED
00:04:51    15:34:37
    TIME     ELAPSED
00:04:50    15:34:28
    TIME     ELAPSED
00:04:52    15:34:28
    TIME     ELAPSED
00:04:52    15:33:49
    TIME     ELAPSED
00:00:00    10:12:01
    TIME     ELAPSED
00:00:00    01:00:20
### Start write test
20480+0 records in
20480+0 records out
21474836480 bytes (21 GB, 20 GiB) copied, 56.0508 s, 383 MB/s

real	0m56.052s
user	0m0.042s
sys	0m53.060s
### Pring z_wr_iss cpu time afte the write test
    TIME     ELAPSED
00:49:46  3-03:44:49
    TIME     ELAPSED
00:22:35  3-03:44:49
    TIME     ELAPSED
00:49:44  3-03:44:49
    TIME     ELAPSED
00:49:43  3-03:44:49
    TIME     ELAPSED
00:00:01  3-03:44:44
    TIME     ELAPSED
00:00:00  3-03:44:44
    TIME     ELAPSED
00:04:51    15:35:33
    TIME     ELAPSED
00:04:50    15:35:24
    TIME     ELAPSED
00:04:52    15:35:24
    TIME     ELAPSED
00:04:52    15:34:46
    TIME     ELAPSED
00:00:00    10:12:57
    TIME     ELAPSED
00:00:00    01:01:16
### Print z_rd_int cpu time before the read test
    TIME     ELAPSED
00:26:31  3-03:44:49
    TIME     ELAPSED
00:00:02  3-03:44:45
    TIME     ELAPSED
00:00:07       01:16
    TIME     ELAPSED
00:00:07       01:16
### Start read test
20480+0 records in
20480+0 records out
21474836480 bytes (21 GB, 20 GiB) copied, 9.03496 s, 2.4 GB/s

real	0m9.036s
user	0m0.032s
sys	0m8.207s
### Print z_rd_int cpu time after the read test
    TIME     ELAPSED
00:26:33  3-03:44:58
    TIME     ELAPSED
00:00:02  3-03:44:54
    TIME     ELAPSED
00:00:09       01:25
    TIME     ELAPSED
00:00:09       01:25
</code></pre></div></div>]]></content><author><name></name></author><category term="ZFS" /><category term="Linux" /><category term="Profiling" /><category term="dkms" /><category term="kernel" /><summary type="html"><![CDATA[I bought a new video game recently but found z_rd_int processes took almost all the CPU time when I was playing it. That doesn’t make much sense to me since I install games on a non compressed ZFS dataset. Even though I don’t have a powerful CPU, I don’t expect ZFS to use all of them and only reads about 60-70MiB/s from each of the NVME SSDs. To double check, I used iostat -x 1 to confirm the iowait is very low. So disk IO is not the bottleneck.]]></summary></entry><entry><title type="html">Introduce K3s, CephFS and MetalLB to My High Avaliable Cluster</title><link href="https://www.binwang.me/2023-11-28-Introduce-K3s-CephFS-and-MetalLB-to-My-High-Avaliable-Cluster.html" rel="alternate" type="text/html" title="Introduce K3s, CephFS and MetalLB to My High Avaliable Cluster" /><published>2023-11-28T00:00:00-05:00</published><updated>2023-11-28T00:00:00-05:00</updated><id>https://www.binwang.me/Introduce-K3s-CephFS-and-MetalLB-to-My-High-Avaliable-Cluster</id><content type="html" xml:base="https://www.binwang.me/2023-11-28-Introduce-K3s-CephFS-and-MetalLB-to-My-High-Avaliable-Cluster.html"><![CDATA[<p>In a previous blog <a href="/2023-03-13-Infrastructure-Setup-for-High-Availability.html">Infrastructure Setup for High Availability</a>, I talked about how I setup a cluster infrastructure for high availability applications. I have made a few changes since then. This blog is to talk about them in details.</p>

<h2 id="updated-architecture-overview">Updated Architecture Overview</h2>

<p><img src="/static/images/2023-11-28-Introduce-K3s-CephFS-and-MetalLB-to-My-High-Avaliable-Cluster/ha-cluster-infrastructure-k3s.png" alt="arch-diagram" /></p>

<p>Comparing the diagram with the one in <a href="/2023-03-13-Infrastructure-Setup-for-High-Availability.html">Infrastructure Setup for High Availability</a>, the overall structure remains the same, with a few modifications:</p>

<ul>
  <li>Not shown in the graph, but replaced official Kubernetes with K3s.</li>
  <li>Replaced GlusterFS with CephFS.</li>
  <li>Included cert-manager to get SSL certificates.</li>
  <li>Replaced Keepalived on each node with MetalLB.</li>
</ul>

<h2 id="replace-kubernetes-with-k3s">Replace Kubernetes with K3s</h2>

<p>I didn’t know <a href="https://k3s.io/">K3s</a> back when I setup my Kubernetes cluster for the first time. But since then I heard a lot of good things about it at various places. However, the complexity of migration and its installation method through a script from Internet instead of an OS package made me think twice before adopt it. But after I watched the video <a href="https://www.youtube.com/watch?v=k58WnbKmjdA">Talk About K3s Internals from Darren Shepherd</a>, I realized how simple k3s is compared to Kubernetes. I highly recommend everyone who is interested in K3s watch this video.</p>

<p>In short, K3s is a distribution of Kubernetes instead of a fork. It does these things with a few patches: combined the components of Kubernetes into one binary and process, and removed some components not needed in a bare metal environment. By doing so, it makes its binary size and memory footprint smaller than Kubernetes, and makes it easier to deploy and manage. It only needs a binary <code class="language-plaintext highlighter-rouge">k3s</code> and a configuration file under <code class="language-plaintext highlighter-rouge">/etc/rancher/k3s/config.yaml</code> to start, and all of its content is under <code class="language-plaintext highlighter-rouge">/var/lib/rancher/k3s</code>. The official install script adds a little bit more than just the binary file: it has a few scripts to kill and uninstall k3s. It also includes systemd file to start/stop k3s through systemd. So even though it’s not packaged into a standard OS package, I think the complexity is manageable so I started to experiment with it.</p>

<p>It’s very easy to config K3s since all it needs is a configuration file on each machine. I created a virtual machine cluster with Vagrant in the project <a href="https://github.com/wb14123/k3s-vm-cluster">k3s-vm-cluster</a> to experiment with it. Feel free to play with it to get a feel with it before go all in. The setup is based on the official guide for <a href="https://docs.k3s.io/datastore/ha-embedded">High Availability Embedded etcd</a>. It’s the easiest way to setup a high available K3s cluster.</p>

<p>No load balancer setup is needed if no external Kubernetes API server HA is needed. That means, you can access to Kubernetes API server within the cluster if any of the machine fails. But if you still want to access it outside of the cluster during a failure, check <a href="https://docs.k3s.io/datastore/cluster-loadbalancer">this doc</a>. Alternatively, I think load balancer like MentalLB can also do it, but I don’t need it so I didn’t experiment with it.</p>

<h2 id="distributed-storage-system-glusterfs-to-cephfs">Distributed Storage System: GlusterFS to CephFS</h2>

<p>The biggest motivation drives this migration is the deprecation of GlusterFS. I’m using distributed file system for a few use cases:</p>

<ul>
  <li>Configuration files: this can be migrated to <a href="https://kubernetes.io/docs/concepts/configuration/configmap/">Kubernetes ConfigMaps</a>.</li>
  <li>Logs: this can be migrated to a centralized log management system like ElasticSearch. But some of them like <a href="https://grafana.com/oss/loki/">Loki</a> in turn depends on another distributed storage.</li>
  <li>Data files: this is most complex one. Some of the services support saving files into S3 compatible systems. But some of them don’t. (I cannot control the services since I only self host them instead of developed them). One option is to not having HA and just bind those services into a specific host and use local storage.</li>
  <li>Docker registry: this belongs to the point “Data files” above, but this is very import so I separate into another point. I’m using <a href="https://www.sonatype.com/products/sonatype-nexus-repository">Sonatype Nexus</a> as the docker registry. It supports to put packages into S3 but still pretty tricky to get rid of all the local files. This is a service that absolutely needs HA if I want to have a HA cluster. Or I can change to another Docker registry implementation, but I feel pretty comfortable using it so I don’t want to change it.</li>
</ul>

<p>So it basically comes down to these 2 options:</p>

<ol>
  <li>Use a S3 compatible storage like <a href="https://min.io/">MinIO</a> but do a lot of work to configure services to store files into that, and make services cannot do that not HA anymore.</li>
  <li>Go ahead and uses a real distributed file system like CephFs or <a href="https://longhorn.io/">Longhorn</a>.</li>
</ol>

<p><em>Update: I also explored <a href="https://linbit.com/">LINBIT</a> which I forgot to write it here. It got more and more complex when I went into the rabbit hole. But its architecture looks very interesting to me. So I may explore it more in the future for other use cases.</em></p>

<p>Option 1 sounds appealing to me at first since I really don’t want to deal with the complexity of setting up CephFS. But as I go into the rabbit hole, I found configuring the services to use S3 may be a more complex process and less portable than just setup CephFS. So at the end I decide to go option 2.</p>

<p>I’ve heard of CephFS long time ago but decided to use GlusterFS at previous setups because of the level of user friendly. So CephFS seems like a nature choice after GlusterFs is deprecated. Especially when I found other than the distributed block device, it also supports file system and S3 compatible storage system. It’s also easier to install than before because of <a href="https://rook.io/">Rook</a>. Longhorn is another choice I looked a little bit but because of wider adoption of CephFS and more features of it, I decide to use CephFS at the end.</p>

<p>The way I use it is mainly <a href="https://rook.io/docs/rook/v1.11/Storage-Configuration/Shared-Filesystem-CephFS/filesystem-storage/">Ceph Filesystem</a>, so it’s easier to share volumes between pods. Again, the project <a href="https://github.com/wb14123/k3s-vm-cluster">k3s-vm-cluster</a> has an example about it. Try to play it if you are interested in it. Along the way I actually contributed to Rook project by improving doc (<a href="https://github.com/rook/rook/pull/13045">#13045</a>) and its error message (<a href="https://github.com/rook/rook/pull/13046">#13046</a>).</p>

<h2 id="network-gateway">Network Gateway</h2>

<p>In the previous article, I talked about using Cloudflare tunnel, or NodePort and Keepalived to expose services to the Internet. But there are some other things a network gateway can do other than just expose the service: it can also do things like terminate SSL encryption and so on. Cloudflare tunnel support terminate SSL at their end so I don’t need to worry about that. But for some services, I don’t want Cloudflare to see the traffic, so I need to terminate SSL and expose service by myself.</p>

<p>As I said, expose service part was done by NodePort and Keepalived, which is not very elegant but works. For the terminate SSL part, I was using Nginx as reverse proxy. But updating SSL certificates is a little bit more complex. I don’t want to talk it in details here because the setup is pretty complex and explaining it will be very lengthy. The point is, with this migration, I want to revisit this part to make it simpler and more elegant.</p>

<p>Kubernetes has a concept of <a href="https://kubernetes.io/docs/concepts/services-networking/ingress/">Ingress</a>, and newer but less mature, <a href="https://gateway-api.sigs.k8s.io/">Gateway</a>. What they are doing is essentially reverse proxy like Nginx. In fact, Nginx Ingress is a thing. The advantage is that you don’t need to configure all the services in a single place like Nginx’s configuration files. You can create Kubernetes resources for each of the service. So that the deployment and configuration of each service is totally self contained. This is a very good feature, especially for a company: when I first started to use Kubernetes at 2015 in a previous company, I felt the pain of not having it. But the feature of Ingress is pretty limited. For example, it can only bind to 443. It cannot modify the http content, and so on. So that I may still need a layer of Nginx for my use cases. The design of gateway is too complex and the features don’t really meet all my requirements as well.</p>

<p>There are some players like <a href="https://traefik.io/">Traefik</a>(shipped with K3s by default) and <a href="https://istio.io/">Istio</a> which overcome the limitations by having their own custom resources. But Traefik cannot get new certificates from Let’s Encrypt with a HA setup. Istio is just too complex and include features like service mesh that I don’t need. I can see how service mesh can be useful in big companies, but I prefer not to have another layer on my own service. At the end, I don’t think the complexity worth it.</p>

<p>But while I exploring Traefik and Istio, I found <a href="https://cert-manager.io/">cert-manager</a>, which can be deployed into Kubernetes. It can get certificates from Let’s Encrypt and put them into Kubernetes secrets, which then can be mount into each pods. It supports Cloudflare DNS API for <a href="https://letsencrypt.org/docs/challenge-types/#dns-01-challenge">ACME DNS challenge</a>, so I don’t need to export a http service for Let’s Encrypt to verify the ownership of the domain name. With all of this features, I decided to use it and mount the certificates into Nginx pods. It resolves the problem of update certificates from Let’s Encrypt.</p>

<p>For the other problem of exposing the services to Internet in a HA way, I want to use a more Kubernetes native way instead of setup Keepalived outside of the Kubernetes cluster. Kubernetes supports <a href="https://kubernetes.io/docs/tasks/access-application-cluster/create-external-load-balancer/">external load balancers</a>. But most of the load balancers it supports are from cloud. Then I found <a href="https://metallb.org/">MetalLB</a>, which supports creating a HA load balancer without special hardware in a bare metal cluster. I use it with <a href="https://metallb.org/concepts/layer2/">layer 2 mode</a>, which creates a virtual IP like keepalived and can failover to another node.</p>

<h2 id="deploy-services-with-code">Deploy Services with Code</h2>

<p>What I didn’t talk in the previous blog is, I define the deployment of my services as code instead yaml files. It gives lots of advantages: first, you can create models for your own deployment pattern so that you can avoid lots of redundant code. Traditionally it’s hard to define the deployment as code. There are lots of frameworks to do it but none of them is easy to use. But with Kubernetes, all you need is generating a resource object for Kubernetes to use at the end. You can construct it in any way with your favorite language, and either output a YAML or call Kubernetes API directly. It’s using a high level language instead of writing machine code directly. It’s much more elegant and the maintenance is much easier. Be aware: use a real language instead of some template language. Why limit your power to do things?</p>

<p>This approach works so well especially during this migration. For example, I abstracted all the storage layer for my services, so that when I migrated from GlusterFS to CephFS, I just need to change the storage class to define the CephFS volume, and the code for services don’t need to change much.</p>

<p>Hope you enjoy my experience of setting up a HA cluster. Happy hacking and have fun with your own cluster!</p>]]></content><author><name></name></author><category term="Kubernetes" /><category term="CephFS" /><category term="MetalLB" /><category term="k3s" /><category term="Infrastructure" /><category term="devops" /><summary type="html"><![CDATA[In a previous blog Infrastructure Setup for High Availability, I talked about how I setup a cluster infrastructure for high availability applications. I have made a few changes since then. This blog is to talk about them in details.]]></summary></entry><entry><title type="html">Update on RSS Brain to Find Related Articles with Machine Learning</title><link href="https://www.binwang.me/2023-11-14-Update-On-RSS-Brain-to-Find-Related-Articles-with-Machine-Learning.html" rel="alternate" type="text/html" title="Update on RSS Brain to Find Related Articles with Machine Learning" /><published>2023-11-14T00:00:00-05:00</published><updated>2023-11-14T00:00:00-05:00</updated><id>https://www.binwang.me/Update-On-RSS-Brain-to-Find-Related-Articles-with-Machine-Learning</id><content type="html" xml:base="https://www.binwang.me/2023-11-14-Update-On-RSS-Brain-to-Find-Related-Articles-with-Machine-Learning.html"><![CDATA[<p>In the previous blog about RSS, <a href="/2022-12-03-How-RSS-Brain-Shows-Related-Articles.html">How RSS Brain Shows Related Articles</a>, I talked about how RSS Brain finds the related articles. I’ve updated the algorithm recently. This blog is about the details about the update. The basic idea is to replace tf-idf algorithm with text embeddings to represent the articles as vectors, and use ElastcSearch to store and query those vectors.</p>

<h2 id="the-disadvantages-of-previous-algorithm">The Disadvantages of Previous Algorithm</h2>

<p>First let’s do a quick revisit on the algorithm before the update: it’s using tf-idf algorithm. Which is basically an algorithm to represent each document as a vector by using the words’ frequency in it. It’s an algorithm that is easy to understand, and works well enough in practice to power lots of searching engines for a long time. However, it has a few shortcomings:</p>

<p>First, it doesn’t understand the meaning of the word. A word can mean different things based on context, order, combinations and so on. Different words can also have the same meaning. Word frequency along doesn’t catch that.</p>

<p>Second, “word” needs to be defined. Which is a relatively easy task for languages like English, since it has a built-in word separator character (space). However, for languages like Chinese, there is no obvious way to separate the words. The performance of tf-idf algorithm largely depends on the performance of word separating algorithm, which itself is much more complex than tf-idf and often involves machine learning as well. Even for languages like English, in order to minimize the first disadvantage above, the words are usually broke down so that some similar words can be matched.</p>

<p>Last, which is an extension of the first disadvantage: it’s hard to do multi language matches. Word frequency along doesn’t know that different words in different languages can mean the same thing. Of course you can translate the document to other languages and index the translated documents, but it doesn’t scale well when you need to support more and more languages. And translation algorithms are usually much more complex than tf-idf, and mostly use machine learning too.</p>

<h2 id="word-and-document-embeddings">Word and Document Embeddings</h2>

<p>With the advancement of machine learning, a new method to represent words as vectors has been developed in the paper <a href="https://arxiv.org/abs/1301.3781">Efficient Estimation of Word Representations in Vector Space</a>. The vector is called word embedding. Then based on the idea, <a href="https://arxiv.org/abs/1405.4053">Distributed Representations of Sentences and Documents</a> explores representing paragraphs as a vectors. Without go into the details, the basic idea is to get a layer from neural network for a NLP task.</p>

<p>For example, if we have a neural network to predict the nth word given previous words, then we may have a neural network like this:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>word[1]   --&gt; vector[1]
word[2]   --&gt; vector[2]    --&gt; layer2 --&gt; ... -&gt; classifier -&gt; output
...
word[n-1] --&gt; vector[n-1]
</code></pre></div></div>

<p>Words are mapped to vectors at the first layer, with something like</p>

\[v = w * W + b\]

<p>Which \(v\) is the vector, \(w\) is the one-hot encoded word. And matrix \(W\) and \(b\) is the trained parameters. There are many other parameters in the later layers of the neural network but we don’t care. We only take \(W\) and \(b\) so that we can compute the vector for any word. With this method, the represented vectors can measure similarities between words by computing similarity of the vectors. Also surprisingly, quoted from the paper <a href="https://arxiv.org/abs/1301.3781">Efficient Estimation of Word Representations in Vector Space</a>: “To find a word that is similar to small in the same sense as biggest is similar to big, we can simply compute vector \(X = vector(biggest) − vector(big) + vector(small)\).” What a beautiful result!</p>

<p>I was aware of this research not long after it came out. I believe some commercial search engines started to use it since then. But the ecosystem like models, tools, databases really picked up since GPT3 came out. So recently, I decided to use it in RSS Brain because how easy to do it nowadays.</p>

<h2 id="select-a-model-to-use">Select a Model to Use</h2>

<p>The first step is to select a model to use. I think OpenAI may have the best model that is available to public. You cannot access the real model but there are APIs you can call to use the model. But I don’t like it for 2 reasons: First, I don’t like OpenAI as a company: it presents itself as a non-profit organization first with the goal to make AI accessible to everyone, then stopped publish models or even the algorithm details. Second, I don’t want vendor lock-in.</p>

<p>There is also Llama. But it’s not really a multilingual model. I see some attempts to train it on some other languages, but the result are not that good in my experience. The license of the model is not commercial friendly as well. And there is no easy to use API to get the embeddings.</p>

<p>At the end I found <a href="https://www.sbert.net/index.html">SentenceTransformers</a>. There are lots of <a href="https://www.sbert.net/docs/pretrained_models.html in the project">pretrained models</a>. After all I selected the model <code class="language-plaintext highlighter-rouge">paraphrase-multilingual-mpnet-base-v2</code> since it’s a multilingual model. But it’s called “sentence” transformers for a reason: there is a size limit on the length of document that you can feed in to the models. I ended up to just get the embeddings for the article title. I think it’s a good enough for my use case.</p>

<h2 id="implementation-details-for-model-server">Implementation Details for Model Server</h2>

<p>The library SentenceTransformer is very easy to use. However it’s implemented in Python so it needs a way to communicate with RSS Brain server, which is written in Scala. Since this is a computation heavy task, the first though is to have a buffer queue in between so that the Python program can process the articles in a speed it can handle. Kafka is a good choice for external task queue but I don’t think it worth the complexity to import another component into the system. So I created buffer queue at both end to avoid creating too many requests while maintain some parallelism. Here is what the whole architecture looks like:</p>

<p><img src="/static/images/2023-11-14-Update-On-RSS-Brain-to-Find-Related-Articles-with-Machine-Learning/article-embedding-arch.png" alt="embedding-arch" /></p>

<p>The green parts in the diagram means the workers in them can work concurrently. On the Scala side, it follows the pattern I experimented in <a href="/2023-08-27-Compare-Task-Processing-Approaches-in-Scala.html">Compare Task Processing Approaches in Scala</a>. On the Python side, it’s more tricky since Python’s async handling is far worth than Scala’s plain old Future, not to mention effect systems like Cats Effect. I may write another blog in the future about it.</p>

<p>The reason I go great detail into this relatively simple problem is that it represents a category of problems: problems that need Python to do some async work because of the library supports. For example, in the future, Python server may have more features like fetching Youtube transcriptions. The architecture to integrate it into RSS Brain would be the same.</p>

<h2 id="database-to-store-and-query-embeddings">Database to Store and Query Embeddings</h2>

<p>There are a few vector databases that can store vectors and query nearest vectors if given one. ElasticSearch added vector fields support at 7.0 and approximate nearest neighbor search (ANN) at 8.0. Since RSS Brain is already using ElasticSearch heavily for searching, I can just use it without add another database into the dependency. It also supports machine learning models so that you don’t need to insert the embedding vectors from the outside world, but I find it’s not as flexible.</p>

<p>Once the vectors are inserted into ElastiSearch, it’s just an API call to get the most similar documents. The details of vector insert and query are in the <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/knn-search.html">ElasticSearch KNN search document</a>. One tricky part is that even though ElasticSearch supports <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/knn-search.html#_combine_approximate_knn_with_other_features">combining ANN search with other features like term searches (tf-idf algorithm)</a> by using a boost factor, it doesn’t work well unless you are willing to tune it. That’s because the embedding vector and term vector mean different things, and the similarity score is not really comparable. So I ended up enable vector search only for finding related articles, instead of combining with term searches.</p>

<h2 id="result">Result</h2>

<p>It’s actually hard to have some metrics for the performance of finding related articles. I don’t believe metrics like click rate, since it doesn’t necessarily show the articles are related. I think the only way for me is to review the results manually and compute the score based on it. But I don’t think it has much value since supporting multiple language along would make it much better than the previous algorithm. But if you are using RSS Brain, you can see the results yourself and let me know what you think about the new algorithm!</p>]]></content><author><name></name></author><category term="RSS Brain" /><category term="Machine Learning" /><category term="Nerual Network" /><category term="Embeddings" /><category term="Python" /><summary type="html"><![CDATA[In the previous blog about RSS, How RSS Brain Shows Related Articles, I talked about how RSS Brain finds the related articles. I’ve updated the algorithm recently. This blog is about the details about the update. The basic idea is to replace tf-idf algorithm with text embeddings to represent the articles as vectors, and use ElastcSearch to store and query those vectors.]]></summary></entry><entry><title type="html">Add Index Sidebar to My Blog</title><link href="https://www.binwang.me/2023-11-10-Index-Sidebar-on-My-Blog.html" rel="alternate" type="text/html" title="Add Index Sidebar to My Blog" /><published>2023-11-10T00:00:00-05:00</published><updated>2023-11-10T00:00:00-05:00</updated><id>https://www.binwang.me/Index-Sidebar-on-My-Blog</id><content type="html" xml:base="https://www.binwang.me/2023-11-10-Index-Sidebar-on-My-Blog.html"><![CDATA[<p>In a previous blog <a href="/2021-10-31-Add-Index-to-My-Blog.html">Add Index to My Blog</a>, I talked about how I added an index page to my blog that put all the articles into categories. I always wanted the index to be a sidebar instead of a single page, but I guess I didn’t wrap my head around about how to implement so I gave up at last. But recently, when I started to use <a href="https://obsidian.md/">Obsidian</a> and checked some demos of <a href="https://obsidian.md/publish">Obsidian Publish</a>, I found having a sidebar is so useful and beautiful so I decide I should implement it.</p>

<p>You can see the result right now: if you are on a big screen device, the index is on the left side of the page. If you are on a small screen device like a mobile phone, it will show a menu button at the top left corner instead. Clicking it will take you to the index.</p>

<p>When I implement it, I want to keep it simple and stupid. That means:</p>

<ul>
  <li>I want to be as simple as possible as long as it has the function: show articles in nested categories.</li>
  <li>I want to use as little Javascript as possible so people can still use it with Javascript disabled.</li>
</ul>

<p>I found the design of Obsidian Publish is very good. So I copied lots of details from them with some modifications: I didn’t implement showing/hiding sub items when click on the index entry since I think it’s not necessary, and I like how it looks when all the articles are listed there: feels like I’ve written lots of things. The categories are sorted by alphabet order and the posts are ordered by publish date. I also added the publish year for each article entry: some articles can look outdated but if people noticed the published year they can understand the context.</p>

<p>Since I’m using Jeykyll, I can generate plain HTML when possible to avoid the usage of Javascript. So the sidebar is generated for each page instead of using Javascript to keep the sidebar and replace the article content on the fly. Javascript is only used for 2 features:</p>

<ol>
  <li>Remember the position of the sidebar when jump pages.</li>
  <li>Scroll the sidebar to show the entry for the current page if it’s not in the viewpoint.</li>
</ol>

<p>Both of the features are not that important so the sidebar is still usable without Javascript. Even for the menu button on small screens, it’s not popping up a dialog. It just jumps to a new static page that has all the index so no Javascript is needed.</p>

<p>The previous implementation of the index page uses recursive templates: Since the nested index is a tree, rendering the content in a recursive manner is a nature thought. However, I made that mistake to put the complex logic into the template engine. So this time, I traverse the tree with Ruby code and generates a list for the template to render. It has all the information like entry type, the depth of the entry and so on. It makes the template code much simpler so it’s easier to implement other features on top of it.</p>

<p>If you want to checkout the detailed implementation, go to my <a href="https://github.com/wb14123/blog">Github repo for the blog</a> and check <a href="https://github.com/wb14123/blog/blob/master/jekyll/_plugins/Index.rb"><code class="language-plaintext highlighter-rouge">jekyll/_plugins/Index.rb</code></a> and <a href="https://github.com/wb14123/blog/blob/master/jekyll/_includes/index_menu.html"><code class="language-plaintext highlighter-rouge">jekyll/_includes/index_menu.html</code></a>.</p>]]></content><author><name></name></author><category term="blog" /><category term="Jekyll" /><category term="Javascript" /><category term="desgin" /><summary type="html"><![CDATA[In a previous blog Add Index to My Blog, I talked about how I added an index page to my blog that put all the articles into categories. I always wanted the index to be a sidebar instead of a single page, but I guess I didn’t wrap my head around about how to implement so I gave up at last. But recently, when I started to use Obsidian and checked some demos of Obsidian Publish, I found having a sidebar is so useful and beautiful so I decide I should implement it.]]></summary></entry><entry><title type="html">How to Cleanup Ceph Filesystem for Deleted Kubernetes Persistent Volume</title><link href="https://www.binwang.me/2023-11-04-How-to-Cleanup-Ceph-Filesystem-for-Deleted-Kubernetes-Persistent-Volume.html" rel="alternate" type="text/html" title="How to Cleanup Ceph Filesystem for Deleted Kubernetes Persistent Volume" /><published>2023-11-04T00:00:00-04:00</published><updated>2023-11-04T00:00:00-04:00</updated><id>https://www.binwang.me/How-to-Cleanup-Ceph-Filesystem-for-Deleted-Kubernetes-Persistent-Volume</id><content type="html" xml:base="https://www.binwang.me/2023-11-04-How-to-Cleanup-Ceph-Filesystem-for-Deleted-Kubernetes-Persistent-Volume.html"><![CDATA[<p><a href="https://docs.ceph.com">Ceph</a> is a distributed file system. <a href="https://rook.io/">Rook</a> is a project to deploy it with Kubernetes. I recently replaced GlusterFS in my Kubernetes cluster with Ceph. I will write a blog (or a series of blogs) for the migration. But in this article, I will just talk about a problem I encountered, just in case I forget it.</p>

<p>Once Rook is deployed in Kubernetes, you can create a <a href="https://rook.io/docs/rook/v1.11/Storage-Configuration/Shared-Filesystem-CephFS/filesystem-storage/">Ceph Filesystem</a> and use it to <a href="https://kubernetes.io/docs/concepts/storage/persistent-volumes">persistent volume (PV)</a>. Each PV’s data will be stored in a folder in the filesystem. If the PV’s reclaiming policy is set to <a href="https://kubernetes.io/docs/concepts/storage/persistent-volumes/#retain">retain</a>, the data will not be deleted after the persistent volume is manually deleted. It’s safer in this way. But what could you do if you want to cleanup the data? Normally you should change the PV’s reclaim policy before you delete the PV, then Rook’s operator will auto reclaim the storage in Ceph. But what if you forget or didn’t know that (like me), and want to cleanup the data after?</p>

<p>First, we need to the folder/subvolume names in Ceph that store’s each PV’s data. We an get that by using <code class="language-plaintext highlighter-rouge">kubectl describe pv &lt;pv-name&gt;</code> and look for the field <code class="language-plaintext highlighter-rouge">subvolumeName</code>. But since the PV is deleted, we need to find the mappings for existing PVs and compare that with the folders/subvolumes in Ceph. This is the command to show all of the existing ones:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>kubectl get pv -o yaml | grep subvolumeName  | sort
</code></pre></div></div>

<p>Then we need to find all the existing folders/subvolumes in Ceph’s filesystem: Start a Ceph toolbox pod based on the <a href="https://rook.github.io/docs/rook/v1.11/Troubleshooting/ceph-toolbox/?h=toolbox">doc</a>. Then go into the pod and find the filesystem’s name first:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ceph fs ls
</code></pre></div></div>

<p>After getting the filesystem’s name, get all the subvolumegroup from it:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ceph fs subvolume ls &lt;fs-name&gt; csi | grep 'name' | sort
</code></pre></div></div>

<p>Compare this list with the list above, you should be able to find a subvolume that exists in Ceph but not shown in Kubernetes’ PV mapping. Use this command to check its info:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ceph fs subvolume info &lt;fs-name&gt; &lt;subvolume-name&gt; csi
</code></pre></div></div>

<p>If you are sure this is the folder you want to delete, use this command to delete it:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ceph fs subvolume rm &lt;fs-name&gt; &lt;subvolume-name&gt; csi
</code></pre></div></div>]]></content><author><name></name></author><category term="Kubernetes" /><category term="Ceph" /><category term="Distributed file system" /><summary type="html"><![CDATA[Ceph is a distributed file system. Rook is a project to deploy it with Kubernetes. I recently replaced GlusterFS in my Kubernetes cluster with Ceph. I will write a blog (or a series of blogs) for the migration. But in this article, I will just talk about a problem I encountered, just in case I forget it.]]></summary></entry><entry><title type="html">Linux Full Disk Encryption with Yubikey</title><link href="https://www.binwang.me/2023-10-22-Full-Disk-Encryption-with-Yubikey.html" rel="alternate" type="text/html" title="Linux Full Disk Encryption with Yubikey" /><published>2023-10-22T00:00:00-04:00</published><updated>2023-10-22T00:00:00-04:00</updated><id>https://www.binwang.me/Full-Disk-Encryption-with-Yubikey</id><content type="html" xml:base="https://www.binwang.me/2023-10-22-Full-Disk-Encryption-with-Yubikey.html"><![CDATA[<h2 id="background">Background</h2>

<p>As mentioned in a previous blog <a href="/2023-03-13-Infrastructure-Setup-for-High-Availability.html">Infrastructure Setup for High Availability</a>, I’ve setup a high available cluster that has 3 machines. But one of them is on my laptop. I feel like I need a dedicated machine for my personal usage, especially I’m planning some travels. So I need to remove the laptop from the cluster. Its disk space is also very limited. With migrating Gluster to Ceph (more blogs to come on that) and not be able to use a disk partition with Ceph’s encryption, I need another machine with more disks. So I repurposed another small form factor machine to join the cluster.</p>

<p>I want full disk encryption on it but I don’t want to input password every time it boots: this machine is put into a closet and it’s very inconvenient to plug/unplug keyboard and monitor. In another blog <a href="/2021-09-19-Personal-ZFS-Offsite-Online-Backup-Solution.html">Personal ZFS Offsite Backup Solution</a>, I talked about a solution to boot encrypted Linxu without input password by setting up TPM. However, old machines only have TPM 1.x chips instead of newer TPM 2.0 chips, which is very tricky to setup and  with very limited support from Linux distros. I don’t want to do it again if not necessary. The thread model is also different since this machine is supposed to be at my home all the time. So this time, I found a new solution to use Yubikey to decrypt disks: I just need to keep Yubikey plugged in during the boot process and press it at the proper time. I can also fallback to the password method if there is anything wrong with Yubikey decryption.</p>

<p>There are some great tutorials and wiki pages describe how to do it. I must give the credit to <a href="https://0pointer.net/blog/unlocking-luks2-volumes-with-tpm2-fido2-pkcs11-security-hardware-on-systemd-248.html">this article</a> that helped me a lot. But all of them are missing some details so I though it would be great to write down my setup so that it may help someone else. My setup is on Arch Linux but the steps should be portable to other Linux distros.</p>

<p><strong>Warning: the steps may make your system not be able to boot if not setup properly. Make sure to back it up or have a recovery CD available to fix it if things went south.</strong></p>

<h2 id="install-linux-with-luks2">Install Linux with LUKS2</h2>

<p>First we need to install Linux with our root partition encrypted. If you are using an installer, most likely there is an option to encryption the disk. If so, select that option and input a passphrase for it. Even though we are using Yubikey to decrypt the disks, it’s always good to have a passphrase to decrypt it in case something goes wrong. However, if your threat model needs a solution that doesn’t involve a passphrase, I believe you can remove it later after setup Yubikey, though I’ve never tried it myself.</p>

<p>Some installers will use LUKS1 instead of LUKS2 to encrypt the disk. Don’t worry, use <code class="language-plaintext highlighter-rouge">cryptsetup convert --type=LUKS2 &lt;device&gt;</code> to convert it to a LUKS2 setup after the OS is installed.</p>

<p>Note: do not encrypt boot partition. It usually doesn’t have sensitive information and encrypting it doesn’t prevent evil maid attack anyway. If you want it to be more secure, considering setup secure boot, which is also mentioned in my previous blog <a href="/2021-09-19-Personal-ZFS-Offsite-Online-Backup-Solution.html">Personal ZFS Offsite Backup Solution</a>.</p>

<h2 id="enroll-yubikey-to-key-slot">Enroll Yubikey to Key Slot</h2>

<p>We can enroll a FIDO2 (which is a protocol Yubikey supports) device by using <code class="language-plaintext highlighter-rouge">systemd-cryptenroll</code>.</p>

<p>Plug in the Yubikey. You can use this command first to list all the FIDO2 devices to make sure the Yubikey is recognized:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>systemd-cryptenroll --fido2-device=auto list
</code></pre></div></div>

<p>Note: You may need to install <code class="language-plaintext highlighter-rouge">libfido2</code>.</p>

<p>After confirm the Yubikey is recognized, use this command to enroll it:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>systemd-cryptenroll --fido2-device=auto &lt;disk-device&gt;
</code></pre></div></div>

<p>It will show hint about you may need to press the Yubikey during the process. So <strong>watch the Yubikey: when its LED flashes, press it to continue.</strong></p>

<h2 id="setup-crypttab">Setup crypttab</h2>

<p>Put a line like this into <code class="language-plaintext highlighter-rouge">/etc/crypttab.initramfs</code>. It will be copied to initramfs by mkinitcpio as <code class="language-plaintext highlighter-rouge">/etc/crypttab</code> so that your root partition can be decrypted before it is mounted:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>myvolume &lt;disk-device&gt; - fido2-device=auto
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">&lt;disk-device&gt;</code> can be something like <code class="language-plaintext highlighter-rouge">/dev/sda1</code> or using UUID format <code class="language-plaintext highlighter-rouge">UUID=&lt;disk-uuid&gt;</code>.</p>

<p>If it’s not root partition, you can put it in <code class="language-plaintext highlighter-rouge">/etc/crypttab</code> so it will be used after root partition is mounted.</p>

<h2 id="setup-mkinitcpio">Setup mkinitcpio</h2>

<p><code class="language-plaintext highlighter-rouge">mkinitcpio</code> is a tool to generate initramfs. <code class="language-plaintext highlighter-rouge">/etc/crypttab.initramfs</code> only works with it. So if your distro comes with other tools like <code class="language-plaintext highlighter-rouge">dracut</code>, you may need to uninstall it and install <code class="language-plaintext highlighter-rouge">mkinitcpio</code> instead.</p>

<p>Once making sure <code class="language-plaintext highlighter-rouge">mkinitcpio</code> is installed, we need to configure the hooks to make it read <code class="language-plaintext highlighter-rouge">crypttab</code> to decrypt the disks. We also need to make sure we are using systemd init instead of busybox init.</p>

<p>Open <code class="language-plaintext highlighter-rouge">/etc/mkinitcpio.conf</code>, and find the line with <code class="language-plaintext highlighter-rouge">HOOKS=(...)</code>. Refer to <a href="https://wiki.archlinux.org/title/Mkinitcpio#Common_hooks">this wiki page</a> about the common hooks and replace busybox hooks with systemd ones. For example, in my setup, I replaced <code class="language-plaintext highlighter-rouge">udev</code> with <code class="language-plaintext highlighter-rouge">systemd</code> and <code class="language-plaintext highlighter-rouge">keymap</code> with <code class="language-plaintext highlighter-rouge">sd-vconsole</code>. Then add <code class="language-plaintext highlighter-rouge">sd-encrypt</code> to the hooks. The order matters: usually it comes after <code class="language-plaintext highlighter-rouge">sd-vconsole</code>.</p>

<p>Then use <code class="language-plaintext highlighter-rouge">mkinitcpio -P</code> to regenerate initramfs images.</p>

<h2 id="test-and-finish">Test and Finish!</h2>

<p>Okay, now we have already setup everything. We can boot the system and test. Make sure Yubikey is plugged in before the boot. And watch for its LED light to flash and press it when it does! This little detail spent me lots of time to figure it out.</p>

<p>You can also use password to decrypt the disk <strong>without Yubikey plugged in</strong>. Wait it for 30 seconds and it will prompt you to input the password. The time can be configured in <code class="language-plaintext highlighter-rouge">/etc/crypttab</code> (or <code class="language-plaintext highlighter-rouge">/etc/crypttab.initramfs</code>) by setting up <a href="https://man.archlinux.org/man/crypttab.5">token-timeout=</a>.</p>]]></content><author><name></name></author><category term="Yubikey" /><category term="Linux" /><category term="Encryption" /><summary type="html"><![CDATA[Background]]></summary></entry><entry><title type="html">A Boring JVM Memory Profiling Story</title><link href="https://www.binwang.me/2023-09-30-A-Boring-JVM-Memory-Profiling-Story.html" rel="alternate" type="text/html" title="A Boring JVM Memory Profiling Story" /><published>2023-09-30T00:00:00-04:00</published><updated>2023-09-30T00:00:00-04:00</updated><id>https://www.binwang.me/A-Boring-JVM-Memory-Profiling-Story</id><content type="html" xml:base="https://www.binwang.me/2023-09-30-A-Boring-JVM-Memory-Profiling-Story.html"><![CDATA[<h2 id="background-of-memory-leakings">Background of Memory Leakings</h2>

<p>I encountered another memory leak problem recently. I’ve debugged a few of memory leak problems in the past, including <a href="https://github.com/splicemachine/spliceengine/pull/2260">the one</a> in Splice Machine, an open source distributed SQL engine based on HBase but was sadly discontinued. The memory leak problems are interesting because it’s challenging to find the root cause. However, I’ve never written a blog about it. Memory leak problems are not so usual, so when I encountered a new one, I kind of need to remember what tools I’ve used. So this time, even though not as interesting as some other memory leak problems I’ve debugged in the past, I decide to write it down as a note for my own reference in the future. The tool set I used this time is relatively simple. I guess I can write more when I use others in the future. This is more like a dev log instead of a tutorial. The “boring” in the title means it’s a pretty standard process and the problem is not that hard to find this time.</p>

<p>Most of the memory leak bugs are very easy to fix once found the root cause, but the part of finding the root cause is tricky. First of all, it’s hard to reproduce: sometime it only happens on production environment. Without knowing the cause, it’s hard to reproduce locally. Even it can be reproduced consistently, it may take some time to let the memory accumulate so the debugging loop can be time consuming sometimes. Last of all, unlike some other bugs that you have an exception and a nice stack trace to help you identify which code causes the problem, it’s almost impossible to find the root cause without the help of a profiler, which itself has challenging parts depending on the platform.</p>

<p>Luckily, JVM has good profilers. That’s one of the reasons Scala, a JVM based language, is my favorite language. (The criteria of a good production language for me is not only the language itself, but also the ecosystem like library, IDE and profilers. JVM based language makes lots of the criteria easy to meet.) This time I uses a very popular profiler <a href="https://www.ej-technologies.com/products/jprofiler/overview.html">JProfiler</a>. Other popular choices that I have used are <a href="https://visualvm.github.io/">VisulaVM</a> and <a href="https://www.oracle.com/java/technologies/jdk-mission-control.html">Java Msission Control</a>. But I found JProfiler is both powerful and easy to use. The only downside is you need to buy a license. It has free trail and open source license. So if you have an open source project or just need to use it for a few days, you can still use it for free.</p>

<h2 id="the-problem">The Problem</h2>

<p>Okay, enough of the background. Let’s dive into the memory leaking problem I encountered this time. As mentioned in the previous blog <a href="http://localhost:4001/2023-09-23-Migrate-Scala2Grpc-to-Cats-Effect-3.html">Migrate Scala2grpc to Cats Effect 3</a>, I migrated one of my side projects to Cats Effect 3 as well, with a lot of other dependencies. This side project is <a href="https://www.rssbrain.com/">RSS Brain</a>. There are two parts on the backend: one for serving client requests with gRPC and gRPC web, another one for fetching RSS feeds. The fetcher gets the RSS feeds that haven’t been fetched for a while from the database with the help of <a href="https://tpolecat.github.io/doobie/">doobie</a> and <a href="https://zio.dev/zio-quill/">quill</a>, and fetch them in parallel with the help of fs2 stream and Cats Effect.</p>

<p>After the mass upgrades, I looked into the metrics to make sure everything is okay. Then I found the fetcher’s memory starts to increase slowly. Looks like a memory leak problem to me. Here is the memory usage graph:</p>

<p><img src="/static/images/2023-09-30-A-Boring-JVM-Memory-Profiling-Story/memory-usage.png" alt="memory usage" /></p>

<p>Seems eventually the JVM will run out of memory but I didn’t wait for it. It’s good to try if force a full gc will reclaim the memory or not, in my case full gc doesn’t help much.</p>

<p>Another metrics to look at is the GC metrics. Only after I shipped the fix, I realized the GC didn’t look normal when there was this memory problem:</p>

<p><img src="/static/images/2023-09-30-A-Boring-JVM-Memory-Profiling-Story/gc.png" alt="gc" /></p>

<p>Before the blue line starts, GCs are all “Copy” and “MarkSweepCompact”, which means the memory are mostly being moved around instead of reclaimed. After the blue line starts, which was when the fix was shipped, we starts to see normal young and old generation GC.</p>

<p>So these metrics indicates that we may have a memory leak issue. Let’s starts to debug it.</p>

<h2 id="setup-profiler">Setup Profiler</h2>

<p>In this case I’m using JProfiler. But as I mentioned above, VisualVM or Java Mission Control should also be able to do the job.</p>

<p>JProfiler has a nice wizard to let you setup the profiler. In my case, since I run the service in Kubernetes, I need to select remote server profiling and go through the wizard. We are going to use <code class="language-plaintext highlighter-rouge">kubectl</code> to forward the debugging port to local, so that we can just use <code class="language-plaintext highlighter-rouge">localhost:8849</code> as the remote address. At the end of the setup wizard, it will prompt you to download the profiler agent and include it with a Java command line argument. Since the service is running in container, I added the following lines to the Dockerfile in order to include the agent in it:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>RUN apt update -y &amp;&amp; apt install -y wget
RUN cd /opt &amp;&amp; \
        wget -c 'https://download.ej-technologies.com/jprofiler/jprofiler_agent_linux-x86_14_0.tar.gz' &amp;&amp; \
        tar -xf jprofiler_agent_linux-x86_14_0.tar.gz
</code></pre></div></div>

<p>Also add this flag to Java command line when starting the service:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>-agentpath:/opt/jprofiler14/bin/linux-x64/libjprofilerti.so=port=8849,nowait
</code></pre></div></div>

<p>After the new container is deployed, we can port forward 8849 from the service to our localhost with kubectl:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>kubectl port-forward &lt;service-pod-name&gt; 8849:8849
</code></pre></div></div>

<h2 id="memory-comparison">Memory Comparison</h2>

<p>Since it’s a memory leaking problem, we want to find out what objects are increasing. First let’s restart the JVM, connect JProfiler to it and take a snapshot of all objects in live memory:</p>

<p><img src="/static/images/2023-09-30-A-Boring-JVM-Memory-Profiling-Story/objects-start.png" alt="objects-start" /></p>

<p>We can see <code class="language-plaintext highlighter-rouge">byte[]</code> takes the most memory but it doesn’t mean it’s responsible for memory leak, since we need to look at the increase of the memory.</p>

<p>So we need to wait for a while for the memory problem starts to happen. In my case, obvious memory increase can be occurred after the JVM run for about 12 hours. Normally if this is a work related thing, I may want to make it faster by increasing the work load. In this case, the code is fetching RSS feeds, so I could make the interval shorter so that it makes more requests. But since this is only a side project, I don’t need to continues working on it, and I also don’t quite like the idea to increase the requests to target RSS websites to increase their load. So I decide just let the JVM run during the night and take another look next day:</p>

<p><img src="/static/images/2023-09-30-A-Boring-JVM-Memory-Profiling-Story/objects-end.png" alt="objects-end" /></p>

<p>Okay, obviously <code class="language-plaintext highlighter-rouge">scala.collection.mutable.LinkedHashMap$LinkedEntry</code> increased a lot. But is there anything else? Conveniently, JProfiler has the feature to compare 2 snapshots. Just go to “Session” -&gt; “Start Center” -&gt; “Open Snapshots” -&gt; “Compare Multiple Snapshots”. After open those 2 snapshots, select both of them on the left and then compare memory:</p>

<p><img src="/static/images/2023-09-30-A-Boring-JVM-Memory-Profiling-Story/objects-compare.png" alt="objects-compare" /></p>

<p>We can see <code class="language-plaintext highlighter-rouge">LinkedEntry</code> indeed increased the most by instance count. However, if we sort by size, we fill find <code class="language-plaintext highlighter-rouge">byte[]</code> increased the most by memory size.</p>

<h2 id="a-false-root-cause">A False Root Cause</h2>

<p>Since <code class="language-plaintext highlighter-rouge">byte[]</code> increased the most by memory size, I’d like to start there. By using “Allocation Call Tree”, we can check which code allocates <code class="language-plaintext highlighter-rouge">byte[]</code> the most. After profiling for a while, we get the following result:</p>

<p><img src="/static/images/2023-09-30-A-Boring-JVM-Memory-Profiling-Story/allocation-tree-bytes.png" alt="allocation-tree-bytes" /></p>

<p>Okay, the top allocation goes to my own code <code class="language-plaintext highlighter-rouge">me.binwang.rss.parser.SourceParser</code>. It’s the class that parse the xml from RSS feeds. So I looked into it if it has any code that can cause memory leak and I found this:</p>

<pre><code class="language-Scala">object SourceParser {

  def parse(url: String, content: Resource[IO, InputStream]): IO[(Source, Seq[Try[FullArticle]])] = {
    content.use { c =&gt;
      // ...
      throw new RuntimeException(s"Error to parse source xml, unrecognized label $label")
      // ...
    }
  }
</code></pre>

<p>So there is an exception thrown in a <code class="language-plaintext highlighter-rouge">Resource.use</code>. <code class="language-plaintext highlighter-rouge">Resource.use</code> makes sure to cleanup the resource when the <code class="language-plaintext highlighter-rouge">use</code> scope is over. But what will happen if it throws an example in there? I thought it will cause <code class="language-plaintext highlighter-rouge">use</code> to not handle the cleanup properly. So I changed it to use <code class="language-plaintext highlighter-rouge">IO.raiseError</code> instead of throw it directly.</p>

<p>However, while I deploying the code, I thought I should really test it. So I wrote a piece of simple code to see whether <code class="language-plaintext highlighter-rouge">Resource</code> will still be cleaned up if there is any exception thrown in <code class="language-plaintext highlighter-rouge">use</code>, and the answer is yes. So this shouldn’t be the root cause. And the deployment result also confirms that: the memory kept increasing with this fix.</p>

<h2 id="the-real-root-cause">The Real Root Cause</h2>

<p>Maybe <code class="language-plaintext highlighter-rouge">byte[]</code> just happened to uses more memory because it’s parsing a large xml at that time. It’s okay that it isn’t the real root cause since we have another lead: <code class="language-plaintext highlighter-rouge">scala.collection.mutable.LinkedHashMap$LinkedEntry</code>. From the profiling, its allocation tree looks like this:</p>

<p><img src="/static/images/2023-09-30-A-Boring-JVM-Memory-Profiling-Story/allocation-tree-linkedlist.png" alt="allocation-tree-linkedlist" /></p>

<p>Okay, so seems most of them come from quill. quill is a library that compiles Scala DSL to SQL queries. It is fairly complex since it uses macros. I checked the code in the allocation tree and couldn’t find out what is wrong.</p>

<p>Then I tried to check the object reference to see which instances are pointed to the these LinkedEntry:</p>

<p><img src="/static/images/2023-09-30-A-Boring-JVM-Memory-Profiling-Story/object-refer.png" alt="object-refer" /></p>

<p>No surprise, they are basically all from quill as well. However, I couldn’t understand the internal AST represents of quill and not sure where are they coming from.</p>

<p>It’s time to search the Internet to see if there is any known issue in quill about memory leak. Maybe I didn’t have the right query, I didn’t find proper results from Internet.</p>

<p>After struggle for a while, I went to its Github repo to search “Memory leak” directly and found 3 issues. That’s good! And there is <a href="https://github.com/zio/zio-quill/issues/2484">one</a> describes the exact problem we have. If we see the allocation tree above, we can find there is a call from <code class="language-plaintext highlighter-rouge">NormalizeCaching</code> (at the bottom of the tree in the picture), which is the class that the issue describes. I guess I didn’t go that far enough to check this class. I’m glad someone else did and found the issue! Basically the root cause is there is a map in the caching doesn’t have any bound. So the cache triggered by dynamic queries never got expired and is growing more and more:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>private val cache = new ConcurrentHashMap[Ast, Ast] 
</code></pre></div></div>

<h2 id="fix-the-memory-leak">Fix the Memory Leak</h2>

<p>The issue is pretty old and is related to a core feature. I’m surprised it’s not fixed yet. As I said, once we found the root cause, the fix should be easy. We just need a way to make the cache expire. I replaced the cache implementation with Guava’s cache, and after the suggestion of maintainer changed it to <a href="https://github.com/ben-manes/caffeine">Caffeine</a>’s cache implementation. <a href="https://github.com/zio/zio-quill/pull/2878">Here is the PR</a>.</p>

<p>I built quill with the fix locally and tested with RSS Brain. The memory leak is indeed fixed! How exciting it is!</p>

<h2 id="conclusion">Conclusion</h2>

<p>Let’s review the process of fixing the memory leak in this case:</p>

<ul>
  <li>Setup profiler.</li>
  <li>Run full GC cannot resolve the memory issue.</li>
  <li>Compare the snapshots between when JVM first started and when the memory increases. See which classes increased most.</li>
  <li>Using allocation tree to find out which part of the code is creating the instances.</li>
  <li>Using references in heap walker to check which classes holds references of those instances.</li>
  <li>Check the identified code and classes.</li>
  <li>If it’s a third party library and we cannot find the root cause, check if the issue is reported. Otherwise report the issue.</li>
  <li>Fix the memory leak based on the root cause.</li>
</ul>]]></content><author><name></name></author><category term="Java" /><category term="JVM" /><category term="Memory Leak" /><category term="Scala" /><category term="JProfiler" /><category term="Profiling" /><summary type="html"><![CDATA[Background of Memory Leakings]]></summary></entry><entry><title type="html">Jekyll Plugin to Load Asciinema Recordings Locally</title><link href="https://www.binwang.me/2023-09-24-Jekyll-Plugin-to-Load-Asciicast-Locally.html" rel="alternate" type="text/html" title="Jekyll Plugin to Load Asciinema Recordings Locally" /><published>2023-09-24T00:00:00-04:00</published><updated>2023-09-24T00:00:00-04:00</updated><id>https://www.binwang.me/Jekyll-Plugin-to-Load-Asciicast-Locally</id><content type="html" xml:base="https://www.binwang.me/2023-09-24-Jekyll-Plugin-to-Load-Asciicast-Locally.html"><![CDATA[<p><a href="https://asciinema.org/">Asciinema</a> is a wonderful tool to record Linux terminal. It saves the records as a text format called Asciicast. However, it has a strong integration with its website. Especially if you want to embed the recordings into the web page use some simple JS code like this:</p>

<div class="language-html highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nt">&lt;script </span><span class="na">src=</span><span class="s">"https://asciinema.org/a/14.js"</span> <span class="na">id=</span><span class="s">"asciicast-14"</span> <span class="na">async</span><span class="nt">&gt;&lt;/script&gt;</span>
</code></pre></div></div>

<p>You need to share the recordings to Asciinema’s website and need to link an account with the recordings, otherwise they will be deleted after 7 days, which I just found out yesterday. I don’t want my blog to rely on some third party website for core content, so I need a way to load the recordings from my website itself.</p>

<p>Lucky, the <a href="https://github.com/asciinema/asciinema-player">Asciinema Javascript player</a> is open source and support to load recordings from a url out of box. First you need to import the CSS:</p>

<div class="language-html highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nt">&lt;link</span> <span class="na">rel=</span><span class="s">"stylesheet"</span> <span class="na">type=</span><span class="s">"text/css"</span> <span class="na">href=</span><span class="s">"/asciinema-player.css"</span> <span class="nt">/&gt;</span>
</code></pre></div></div>

<p>This is no big deal since this can be put in Jekyll’s template. Then you need some JS code like this:</p>

<div class="language-html highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nt">&lt;div</span> <span class="na">id=</span><span class="s">"demo"</span><span class="nt">&gt;&lt;/div&gt;</span>
 ...
<span class="nt">&lt;script </span><span class="na">src=</span><span class="s">"/asciinema-player.min.js"</span><span class="nt">&gt;&lt;/script&gt;</span>
<span class="nt">&lt;script&gt;</span>
  <span class="nx">AsciinemaPlayer</span><span class="p">.</span><span class="nf">create</span><span class="p">(</span><span class="dl">'</span><span class="s1">/demo.cast</span><span class="dl">'</span><span class="p">,</span> <span class="nb">document</span><span class="p">.</span><span class="nf">getElementById</span><span class="p">(</span><span class="dl">'</span><span class="s1">demo</span><span class="dl">'</span><span class="p">));</span>
<span class="nt">&lt;/script&gt;</span>
</code></pre></div></div>

<p>It’s a little bit too much for embedding a terminal recording in a blog. However, with the powerful Jekyll plugin system, We can write a plugin to make it simpler so that we can just use a tag to include it:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
{% asciicast &lt;id&gt; %}

</code></pre></div></div>

<p>Here is the implementation, it’s also in <a href="https://github.com/wb14123/blog/blob/master/jekyll/_plugins/Asciicast.rb">my blog’s Github repo</a>:</p>

<div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">module</span> <span class="nn">Jekyll</span>
  <span class="k">class</span> <span class="nc">RenderAsciicastTag</span> <span class="o">&lt;</span> <span class="no">Liquid</span><span class="o">::</span><span class="no">Tag</span>

    <span class="k">def</span> <span class="nf">initialize</span><span class="p">(</span><span class="n">tag_name</span><span class="p">,</span> <span class="n">text</span><span class="p">,</span> <span class="n">tokens</span><span class="p">)</span>
      <span class="k">super</span>
      <span class="vi">@text</span> <span class="o">=</span> <span class="n">text</span><span class="p">.</span><span class="nf">strip</span>
    <span class="k">end</span>

    <span class="k">def</span> <span class="nf">render</span><span class="p">(</span><span class="n">context</span><span class="p">)</span>
      <span class="s2">"&lt;div id=</span><span class="se">\"</span><span class="s2">cast-</span><span class="si">#{</span><span class="vi">@text</span><span class="si">}</span><span class="se">\"</span><span class="s2">&gt;&lt;/div&gt;"</span> <span class="p">\</span>
      <span class="s1">'&lt;script src="/static/js/asciinema-player.min.js"&gt;&lt;/script&gt;'</span> <span class="p">\</span>
      <span class="s2">"&lt;script&gt;AsciinemaPlayer.create('/static/asciicasts/</span><span class="si">#{</span><span class="vi">@text</span><span class="si">}</span><span class="s2">.cast', document.getElementById('cast-</span><span class="si">#{</span><span class="vi">@text</span><span class="si">}</span><span class="s2">'), {rows: 10, autoPlay: true});&lt;/script&gt;"</span>
    <span class="k">end</span>
  <span class="k">end</span>
<span class="k">end</span>

<span class="no">Liquid</span><span class="o">::</span><span class="no">Template</span><span class="p">.</span><span class="nf">register_tag</span><span class="p">(</span><span class="s1">'asciicast'</span><span class="p">,</span> <span class="no">Jekyll</span><span class="o">::</span><span class="no">RenderAsciicastTag</span><span class="p">)</span>
</code></pre></div></div>

<p>It will find the recordings under <code class="language-plaintext highlighter-rouge">/static/asciicasts/{id}.cast</code> and load from there.</p>

<p>Put this file under <code class="language-plaintext highlighter-rouge">_plugins</code> and happy hacking!</p>]]></content><author><name></name></author><category term="Jekyll" /><category term="Blog" /><category term="command line" /><category term="Asciicast" /><summary type="html"><![CDATA[Asciinema is a wonderful tool to record Linux terminal. It saves the records as a text format called Asciicast. However, it has a strong integration with its website. Especially if you want to embed the recordings into the web page use some simple JS code like this:]]></summary></entry><entry><title type="html">Migrate Scala2grpc to Cats Effect 3</title><link href="https://www.binwang.me/2023-09-23-Migrate-Scala2Grpc-to-Cats-Effect-3.html" rel="alternate" type="text/html" title="Migrate Scala2grpc to Cats Effect 3" /><published>2023-09-23T00:00:00-04:00</published><updated>2023-09-23T00:00:00-04:00</updated><id>https://www.binwang.me/Migrate-Scala2Grpc-to-Cats-Effect-3</id><content type="html" xml:base="https://www.binwang.me/2023-09-23-Migrate-Scala2Grpc-to-Cats-Effect-3.html"><![CDATA[<p><a href="https://github.com/wb14123/scala2grpc">Scala2grpc</a> is a library and SBT plugin I wrote so that you can integrate gRPC to Scala code in a non-invasive way. In a previous <a href="/2022-05-02-A-Library-to-Make-It-Easier-to-Use-Scala-with-GRPC.html">blog post</a>, I talked about the motivation behind it.</p>

<p>The library requires each service method to return Cats Effect’s <code class="language-plaintext highlighter-rouge">IO</code> or fs2 stream. However, it’s still using Cats Effect 2.x version. There are big changes in Cats Effect 3 and almost all up to date libraries already support it. So it’s time to migrate it to Cats Effect 3 as well.</p>

<h2 id="replace-akka-grpc-with-fs2-grpc">Replace Akka gRPC with fs2-grpc</h2>

<p>This library was using <a href="https://doc.akka.io/docs/akka-grpc/current/index.html">akka-grpc</a>. But I want to replace it for a few reasons:</p>

<ul>
  <li>It uses <a href="https://github.com/krasserm/streamz">streamz</a> to convert between Akka streams and fs2 streams. This library doesn’t support Cats Effect 3 and hasn’t been updated for a while. This is the biggest reason that I need to migrate from akka immediately.</li>
  <li>Akka changed its open source license to a very expensive one which I didn’t know at the time writing this library. Even the license doesn’t cost anything if the revenue doesn’t reach a certain point, I don’t want it to be a liability.</li>
  <li>It’s good to have a gRPC library that supports for Cats Effect and fs2 streams natively.</li>
</ul>

<p>So in the newer version, I replaced Akka gRPC with <a href="https://github.com/typelevel/fs2-grpc">fs2-grpc</a>, a library under Typelevel umbrella and natively supports Cats Effect and fs2. The document is not as good and I spent quite some time to figure out how to actually use it, but I’m happy it finally worked out.</p>

<h2 id="add-hooks-to-grpc-calls">Add Hooks to gRPC Calls</h2>

<p>In the previous version of Scala2grpc, there is a feature to log every request. But it is a pretty hacky implementation: I just throw the logging logic into the generated code. Since this version is a breaking change, it’s a good opportunity to revisit the approach and see how to add generic hooks before and after each gRPC calls.</p>

<p>My implementation wraps the gRPC response into a context in the generated code. The context includes the response with type of <code class="language-plaintext highlighter-rouge">IO</code> or <code class="language-plaintext highlighter-rouge">fs2.Stream</code>. Because of the referential transparency, you can take the response and add hooks before or after it. More detailed document is in <a href="https://github.com/wb14123/scala2grpc#4-optional-define-custom-grpc-hook">this section of readme</a>.</p>

<h2 id="non-invasive-nature-of-the-library">Non-invasive Nature of the Library</h2>

<p>The migration brings lots of breaking changes, so it is a good test for the non-invasive nature of the library. I have 2 side projects that are using this library and I migrated one of them recently. Since it’s also using Cats Effect, there are some migration steps unrelated to this library. But regarding of the related parts, the migration process is very smooth: I don’t need to change any implementation code of the services. The generated gPRC protocol files are also not changed either. The only thing I need to change is the single object that implements <code class="language-plaintext highlighter-rouge">GRPCGenerator</code> to <a href="https://github.com/wb14123/scala2grpc#2-create-an-object-to-implement-grpcgenerator">pass in some new parameters</a>. It is impossible if I used akka gRPC directly and changed it to fs2-grpc since their interface are all different.</p>

<p>I’m so happy with the result: it adds gRPC to pure Scala code so easily without ever touch it. It saves me so much time to build a service and keeps the code clean at the same time. It continue to be a must have for my future Scala gRPC projects.</p>]]></content><author><name></name></author><category term="Programming" /><category term="Scala" /><category term="gRPC" /><category term="Cats" /><category term="Functional Programming" /><summary type="html"><![CDATA[Scala2grpc is a library and SBT plugin I wrote so that you can integrate gRPC to Scala code in a non-invasive way. In a previous blog post, I talked about the motivation behind it.]]></summary></entry><entry><title type="html">Build a Linux Virtual Machine for Windows Apps</title><link href="https://www.binwang.me/2023-09-01-Build-a-Linux-Virtual-Machine-for-Windows-Apps.html" rel="alternate" type="text/html" title="Build a Linux Virtual Machine for Windows Apps" /><published>2023-09-01T00:00:00-04:00</published><updated>2023-09-01T00:00:00-04:00</updated><id>https://www.binwang.me/Build-a-Linux-Virtual-Machine-for-Windows-Apps</id><content type="html" xml:base="https://www.binwang.me/2023-09-01-Build-a-Linux-Virtual-Machine-for-Windows-Apps.html"><![CDATA[<h2 id="background">Background</h2>

<p>Linux is great. However sometimes you just need to run some Windows only applications to collaborate with other people, especially if it’s impossible to let the other party to change the software. Luckily I rarely run into that situation in the past 10+ years. The only recent exceptions I can remember are filling some government forms (which uses pdf with XFA form. Yes Firefox can fill that now but it’s still incompatible with Adobe Reader from time to time), use IM and video meeting software with a previous Chinese client for some consultant work.</p>

<p>Even it’s rarely used, it’s handy to have a VM to run Windows applications. But Windows is becoming more and more bloat, adding more and more tracking and ads, basically more holistic to users. The only good parts in Windows XP and Windows 7 have long gone. Currently I have a Windows 10 VM, but I’m not sure if I ever want to login to Windows 11 if Windows 10’s life is end. So it’s good to have a backup plan to run Windows apps without Windows. Practise reasons aside, it’s just fun to play with Linux distros. Linux and its desktop environments are so diverse and configurable, I spent such a great time to explore what are the possibilities.</p>

<p>There is <a href="https://www.winehq.org/">Wine</a> to run Windows applications on Linux. It’s not perfect. Some apps need to be tweaked a lot in order to run with wine and some are just nearly impossible. Even the software can be run with wine, I don’t want to run it on my OS since wine is just a compatibility layer, not a sandbox. Which means the typical malware like behaviours in Windows applications are still effective under Wine. So I need to run it in a virtual machine. It also gives us an opportunity to select a distro to focus more on this specific task.</p>

<p>I have tried a few distros in the last few days. At the end I find <a href="https://www.deepin.org">Deepin Linux</a> is the best one for this use case. Especially you want to run Chinese Windows apps.</p>

<h2 id="a-little-history-of-deepin">A Little History of Deepin</h2>

<p>Deepin’s root is in Windows. It first started as a Windows online forum and then started to customize and piracy Windows XP. The year was 2006. Almost no one bought Windows in China back in the days. I don’t know if business or even Universities ever bought Windows licenses or not, but even they do, it’s a very common practise to install piracy Windows in those environment because the popular ones are so user friendly. Computer sellers would ask the buyers if they want to change the stock Windows to a piracy one, and most of the time they do. Ironically, the only time I’ve inputted a (legitimately obtained) Windows key is when I was working at Redhat and setting up a Windows server for testing Samba and nfs. The popular piracy versions are really impressive: the installation is fast and easy, they are more beautiful, they include things like system backup and recovery, they have common drivers pre-installed and application to find drivers (not like the driver finder on Windows, this one actually works), the system was cut down to a very small size and so on. However, if it sounds sketchy to you, you are not wrong. Even though the user experience maybe superior, there is no shortage of back doors and things like that. The popular versions even have their own more sketchy piracy versions. However, that era is wild west for computer security and just one more vulnerability didn’t really matter that much in my mind.</p>

<p>Anyway, Deepin was one of the most popular among them. But things didn’t last for long. Around 2008, the year China hosted its first Olympic Game, the person behind a popular piracy version got arrested. Even the common practise of using piracy Windows in China lasted a long time after that, the big ones felt the risk and stopped making them. Some of them started to make Linux distros instead. Again, Deepin became one of the most popular. <a href="https://en.wikipedia.org/wiki/YLMF_Computer_Technology_Co.,_Ltd.">雨林沐风 (YLMF)</a> is another very popular one which is in famous of its clean and beautify theme in the Windows piracy era. It started to make Linux distro (<a href="https://en.wikipedia.org/wiki/StartOS">YLMF OS</a>) around the same time. It is the first Linux distro I’ve ever used and introduced the whole world of Linux to me.</p>

<p>It’s no wonder Deepin Linux has good support for Windows applications: Windows users are its earliest user base. It’s still true nowadays: even with some failed attempts, Chinese government never stopped exploring to use Linux instead of Windows on government devices. After these years, because of factors like applications are more web based instead of native, and the better experience of Linux desktop, Chinese government actually replaced a large amount of their devices with Linux. From what I know, they are using <a href="https://en.wikipedia.org/wiki/Ubuntu_Kylin">Ubuntu Kylin</a> instead of Deepin or UOS (commercial version of Deepin), but the market is large enough to motivate Deepin to continue maintaining Windows app supports.</p>

<h2 id="deepin-linux-101">Deepin Linux 101</h2>

<p>We’ve talked enough history. Let’s look at Deepin Linux at nowadays. It has it’s own desktop environment called DDE and includes lots of its own apps like browser, video player, mail client and so on. But it’s not my taste and the DE is pretty resource hungry on my machine. Luckily, Deepin is based on Debian stable, so you can basically customize to whatever you like using Debian packages, which we will do later.</p>

<p>The main thing we want in Deepin Linux is its app store. It has lots of Windows applications supported by default. Deepin actually has its own wine version deepin-wine to support those Windows apps better. No matter what tweaks we are going to do with the system, make sure app store works after that.</p>

<p>It also ships with Android support with UEngine, which is a fork of Anbox. There are some officially supported Android apps in the package repo but seems they are not findable in app store. You can use <code class="language-plaintext highlighter-rouge">apt search uengine</code> to find them in terminal. I’ve never had good experience with Android in VM and this time it’s no exception: I tried to install an app from apt and it couldn’t start because of uengine startup timeout. I’m not sure if it will be better on a physical machine but I don’t bother to try it.</p>

<p>Overall, I have double feelings about Deepin. On one hand, it’s pretty impressive on the technical side about what they have done and the community they’ve built. On the other hand, it always feels a little bit sketchy. Even after the Windows piracy era, the Linux distro is still less trustworthy in my mind because of some telemetry its app store collects, not straightforward removable stock apps, the connection (or the intention to connect) with Chinese government and so on. In addition of all the Windows apps I’m going to install, I will not have any personal or important data on it.</p>

<p>After understanding the basics of Deepin Linux, let’s go ahead to install and tweak it. To have a taste of what it will look like, let me show a screenshot of my setup:</p>

<p><img src="/static/images/2023-08-31-Build-a-Linux-VM-for-Windows-Apps/screenshot.png" alt="screnshot" /></p>

<h2 id="installation">Installation</h2>

<p>The installation is pretty straightforward, but make sure to make these tweaks:</p>

<ul>
  <li>During the installation, it will detect that you are in a VM and prompt to use “performance” mode. Make sure to select it so that it will be faster. Even though we will replace the DE later so I don’t think it matters that much, but it doesn’t hurt anyway.</li>
  <li>By default it will create a recovery partition, which is a waste of storage since we are using a VM. We can take snapshots through the VM software if we backup and recovery. So make sure to manually partition the file system and not using recovery partition.</li>
</ul>

<h2 id="replace-dde-with-xfce">Replace DDE with XFCE</h2>

<p>As I said, I don’t like the default DDE Deepin ships. And with limited time I don’t find it’s very configurable as well. So we will replace it with the less resource hungry and highly customizable XFCE. In order to install XFCE, run this in the terminal:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>sudo apt install xfce4 xfce4-goodies
</code></pre></div></div>

<p>Then logout and select <code class="language-plaintext highlighter-rouge">xfce</code> in the login screen.</p>

<h2 id="configure-lightdm">Configure lightdm</h2>

<p>Deepin is using <code class="language-plaintext highlighter-rouge">lightdm</code> as its display manager. To match our simple xfce feeling, I’d like to change the login screen to a simpler and reto look. Open <code class="language-plaintext highlighter-rouge">/etc/ligthdm/lightdm.conf</code> and apply these changes:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>- greeter-session=lightdm-deepin-greeter
+ greeter-session=lightdm-gtk-greeter
- user-session=deepin
+ user-sesion=xfce
</code></pre></div></div>

<h2 id="install-windows-95-theme">Install Windows 95 theme</h2>

<p>Another important reason of choosing XFCE the <a href="https://github.com/grassmunk/Chicago95">Chicago95 theme</a>, which makes XFCE looks like Windows 95. If we are having an OS for running Windows programs, what’s a better look than Windows 95/98/2000 era theme?</p>

<p>Go to <a href="https://github.com/grassmunk/Chicago95">Chicago95’s Github repo</a> and follow the instructions to install it. Since it’s made for XUbuntu, which is based on Ubuntu which is in turn based on Debian, the installation script works perfectly. After installation, read the popped up txt file so tweak remaining things to make it more Windows 95 like if you want.</p>

<p>If you also want to make the login screen Windows 95 like, you need to use <code class="language-plaintext highlighter-rouge">lightdm-webkit-greeter</code> instead of the <code class="language-plaintext highlighter-rouge">lightdm-gtk-greeter</code> above and change the theme. See <a href="https://github.com/grassmunk/Chicago95/tree/5670fde8ce33b33d37622b888278aa9cdbe5eea2/Lightdm/Chicago95">the doc</a> for more details. However, <code class="language-plaintext highlighter-rouge">lightdm-webkit-greeter</code> is not in Debian or Deepin’s package repo by default and I find the trouble to install it manually doesn’t worth it, so I didn’t make the change.</p>

<p>For Firefox, there is a <a href="https://addons.mozilla.org/en-US/firefox/addon/windows-98-se/?utm_source=addons.mozilla.org&amp;utm_medium=referral&amp;utm_content=search">Windows 98 SE</a> theme I find fit into the system theme the best.</p>

<h2 id="other-xfce-tweaks">Other XFCE tweaks</h2>

<ul>
  <li>Disable compositor in Settings -&gt; Window Manager Tweaks -&gt; Compositor. Some windows will have a black frame after this, so enable/disable it based on your preference.</li>
  <li>I’d also like to disable auto session save:
    <ul>
      <li>Uncheck all the boxes in Settings -&gt; Session and Startup -&gt; General (I find it doesn’t prompt and auto save if <code class="language-plaintext highlighter-rouge">prompt on logout</code> is checked)</li>
      <li>Remove all the existing sessions: <code class="language-plaintext highlighter-rouge">rm -r ~/.cache/sessions/*</code></li>
    </ul>
  </li>
</ul>

<h2 id="remove-stock-deepin-apps">Remove Stock Deepin Apps</h2>

<p>There are lots of stock apps made by Deepin. Even though I like the effort, I still prefer the familiar ones and the ones XFCE has. So I need to uninstall the stock apps. However, you cannot uninstall them through Deepin’s app store, so we need to use <code class="language-plaintext highlighter-rouge">apt</code> to find and remove them.</p>

<p>Use <code class="language-plaintext highlighter-rouge">apt search deepin | grep installed</code> to find installed deepin packages and remove the ones you don’t want. Then use <code class="language-plaintext highlighter-rouge">sudo apt autoremove</code> and <code class="language-plaintext highlighter-rouge">sudo apt autoclean</code> to cleanup the not needed dependencies. Make sure app store is still working after this since it’s the whole point of using Deepin.</p>

<h2 id="disable-deepin-services">Disable Deepin Services</h2>

<p>I didn’t remove all the deepin related packages since some of them are needed by the App Store. However, I don’t think some of them are needed to run as deamon even if I left them on the machine. So type <code class="language-plaintext highlighter-rouge">systemctl status deepin-</code> and press tab for autocomplete to see the systemd services related to deepin, and use <code class="language-plaintext highlighter-rouge">systemctl disable &lt;service&gt;</code> to disable the ones you don’t need.</p>]]></content><author><name></name></author><category term="Linux" /><category term="Windows" /><category term="Virtual Machine" /><category term="Deepin" /><category term="Wine" /><summary type="html"><![CDATA[Background]]></summary></entry><entry><title type="html">Compare Task Processing Approaches in Scala</title><link href="https://www.binwang.me/2023-08-27-Compare-Task-Processing-Approaches-in-Scala.html" rel="alternate" type="text/html" title="Compare Task Processing Approaches in Scala" /><published>2023-08-27T00:00:00-04:00</published><updated>2023-08-27T00:00:00-04:00</updated><id>https://www.binwang.me/Compare-Task-Processing-Approaches-in-Scala</id><content type="html" xml:base="https://www.binwang.me/2023-08-27-Compare-Task-Processing-Approaches-in-Scala.html"><![CDATA[<p><em>All the source code mentioned in this blog can be found in <a href="https://github.com/wb14123/scala-stream-demo">my Github repo</a>.</em></p>

<h2 id="task-processing">Task Processing</h2>

<p>There is a common problem in computer science and I’ve met it again recently: how to generate and process tasks efficiently? Use my recent project <a href="https://www.rssbrain.com">RSS Brain</a> as an example: it needs to find the RSS feeds that haven’t been updated for a while in a database, and fetch the newest data from network.</p>

<p>The easiest way to do it is producing and consuming the tasks in a sequence, for example:</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">feeds</span> <span class="k">=</span> <span class="nf">getPendingFeeds</span><span class="o">()</span> <span class="c1">// produce the tasks</span>
<span class="nv">feeds</span><span class="o">.</span><span class="py">foreach</span><span class="o">(</span><span class="n">fetchFromNetwork</span><span class="o">)</span> <span class="c1">// consume the dtasks</span>
</code></pre></div></div>

<p>However, it is unnecessarily slow. Network request doesn’t take lots of CPU and we can send multiple requests at the same time. Even if <code class="language-plaintext highlighter-rouge">fetchFromNetwork</code> is a CPU bound task, it can be parallelized if there are multiple CPU cores on a machine.</p>

<p>In this article, we will explore ways to do it more efficiently with <a href="https://typelevel.org/cats-effect/">Cats Effect</a> and <a href="https://fs2.io">FS2</a> in a functional programming fashion.</p>

<p><em>You may wonder why not using AKKA stream? Other than it’s using a different programming paradigm (not functional programming), it’s also because <a href="https://www.lightbend.com/blog/why-we-are-changing-the-license-for-akka">AKKA has changed its license</a> with a ridiculous price.</em></p>

<h2 id="introducing-cats-effect-and-fs2">Introducing Cats Effect and FS2</h2>

<p>To make <code class="language-plaintext highlighter-rouge">processTask</code> async, there is <code class="language-plaintext highlighter-rouge">Future</code> in Scala’s standard library. However, the side effect will happen when you create a <code class="language-plaintext highlighter-rouge">Future</code> instance. For example:</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">processTask</span><span class="o">(</span><span class="n">task</span><span class="k">:</span> <span class="kt">Task</span><span class="o">)</span><span class="k">:</span> <span class="kt">Future</span><span class="o">[</span><span class="kt">Unit</span><span class="o">]</span> <span class="k">=</span> <span class="nc">Future</span><span class="o">(</span><span class="nf">println</span><span class="o">(</span><span class="n">task</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">runTask1</span> <span class="k">=</span> <span class="nf">processTask</span><span class="o">(</span><span class="n">task1</span><span class="o">)</span> <span class="c1">// this will start the async task</span>
</code></pre></div></div>

<p>I assume the readers have a basic understanding of functional programming, so I’ll not explain why we want to avoid side effects. While Scala is not a pure functional language, a popular Scala library <a href="https://typelevel.org/cats-effect/">Cats Effect</a> provides convenient ways to wrap side effects. With the help of its <code class="language-plaintext highlighter-rouge">IO</code> type, we can define an async task like this:</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">processTask</span><span class="o">(</span><span class="n">task</span><span class="k">:</span> <span class="kt">Task</span><span class="o">)</span><span class="k">:</span> <span class="kt">IO</span><span class="o">[</span><span class="kt">Unit</span><span class="o">]</span> <span class="k">=</span> <span class="nc">IO</span><span class="o">(</span><span class="nf">println</span><span class="o">(</span><span class="n">task</span><span class="o">))</span>

<span class="c1">// this will not start the task, so no side effect</span>
<span class="k">val</span> <span class="nv">runTask1</span> <span class="k">=</span> <span class="nf">processTask</span><span class="o">(</span><span class="n">task1</span><span class="o">)</span>

<span class="c1">// out of pure functional world and starts the side effect</span>
<span class="nv">runTask1</span><span class="o">.</span><span class="py">unsafeRunSync</span><span class="o">()</span>
</code></pre></div></div>

<p>Then there is <a href="https://fs2.io">fs2</a> that is a stream library that can be used with cats effect. It will be very handy when resolving our problem as we can see later.</p>

<p><em>Cat Effect has some big changes in version 3.x. In this article, we are using version 2.x. But I may upgrade the version in the future.</em></p>

<h2 id="testing-setup">Testing Setup</h2>

<p>In order to test which approach is the best under different scenarios, we need some basic setup. In <a href="https://github.com/wb14123/scala-stream-demo/blob/master/src/main/scala/TestRunner.scala">TestRunner.scala</a>, I defined some functions to generate tasks. Here are their signatures:</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// Produce a sequence of tasks represented by `Int`</span>
<span class="k">def</span> <span class="nf">produce</span><span class="o">(</span><span class="n">start</span><span class="k">:</span> <span class="kt">Int</span><span class="o">,</span> <span class="n">end</span><span class="k">:</span> <span class="kt">Int</span><span class="o">)</span><span class="k">:</span> <span class="kt">IO</span><span class="o">[</span><span class="kt">Seq</span><span class="o">[</span><span class="kt">Int</span><span class="o">]]</span>

<span class="c1">// Process a task</span>
<span class="k">def</span> <span class="nf">consume</span><span class="o">(</span><span class="n">x</span><span class="k">:</span> <span class="kt">Int</span><span class="o">)</span><span class="k">:</span> <span class="kt">IO</span><span class="o">[</span><span class="kt">Unit</span><span class="o">]</span>

<span class="c1">// Produce tasks as a stream</span>
<span class="k">def</span> <span class="nf">def</span> <span class="nf">produceStream</span><span class="o">(</span><span class="n">start</span><span class="k">:</span> <span class="kt">Int</span><span class="o">,</span> <span class="n">end</span><span class="k">:</span> <span class="kt">Double</span><span class="o">)</span><span class="k">:</span> <span class="kt">fs2.Stream</span><span class="o">[</span><span class="kt">IO</span>, <span class="kt">Int</span><span class="o">]</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">produce</code> simply produces tasks as <code class="language-plaintext highlighter-rouge">int</code>, and <code class="language-plaintext highlighter-rouge">consume</code> just print characters. In each of the functions, I use <code class="language-plaintext highlighter-rouge">IO.sleep</code> to create some delay to simulate the real world non-blocking IO. They also print characters <code class="language-plaintext highlighter-rouge">P</code> (produce) or <code class="language-plaintext highlighter-rouge">C</code> (consume) (based on the width of terminal, some of the <code class="language-plaintext highlighter-rouge">C</code> outputs may be skipped to fit the width) when being invoked, so that we can have an intuitive view of how quick tasks are produced and consumed.</p>

<p>Then there is <a href="https://github.com/wb14123/scala-stream-demo/blob/master/src/main/scala/TestConfig.scala">TestConfig.scala</a> for configuring the test:</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">trait</span> <span class="nc">TestConfig</span> <span class="o">{</span>
  <span class="k">val</span> <span class="nv">testName</span><span class="k">:</span> <span class="kt">String</span>
  <span class="k">val</span> <span class="nv">produceDelay</span><span class="k">:</span> <span class="kt">FiniteDuration</span>
  <span class="k">val</span> <span class="nv">minConsumeDelayMillis</span><span class="k">:</span> <span class="kt">Long</span>
  <span class="k">val</span> <span class="nv">maxConsumeDelayMillis</span><span class="k">:</span> <span class="kt">Long</span>
  <span class="k">val</span> <span class="nv">batchSize</span> <span class="k">=</span> <span class="mi">100</span>  <span class="c1">// consume batch size</span>
  <span class="k">val</span> <span class="nv">totalSize</span> <span class="k">=</span> <span class="mi">1000</span> <span class="c1">// how many tasks to generate</span>
<span class="o">}</span>
</code></pre></div></div>

<p>By setting up produce and consume delays, we can test scenarios when producer is slower, consumer is slower, or producer and consumer speed is almost the same. Here are the configurations we are going to use in <a href="https://github.com/wb14123/scala-stream-demo/blob/master/src/main/scala/Main.scala">Main.scala</a></p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">configs</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span>
  <span class="k">new</span> <span class="nc">TestConfig</span> <span class="o">{</span>
    <span class="k">override</span> <span class="k">val</span> <span class="nv">testName</span><span class="k">:</span> <span class="kt">String</span> <span class="o">=</span> <span class="s">"slow-producer"</span>
    <span class="k">override</span> <span class="k">val</span> <span class="nv">produceDelay</span><span class="k">:</span> <span class="kt">FiniteDuration</span> <span class="o">=</span> <span class="mf">1000.</span><span class="n">millis</span>
    <span class="k">override</span> <span class="k">val</span> <span class="nv">minConsumeDelayMillis</span><span class="k">:</span> <span class="kt">Long</span> <span class="o">=</span> <span class="mi">10</span>
    <span class="k">override</span> <span class="k">val</span> <span class="nv">maxConsumeDelayMillis</span><span class="k">:</span> <span class="kt">Long</span> <span class="o">=</span> <span class="mi">100</span>
  <span class="o">},</span>
  <span class="k">new</span> <span class="nc">TestConfig</span> <span class="o">{</span>
    <span class="k">override</span> <span class="k">val</span> <span class="nv">testName</span><span class="k">:</span> <span class="kt">String</span> <span class="o">=</span> <span class="s">"balanced"</span>
    <span class="k">override</span> <span class="k">val</span> <span class="nv">produceDelay</span><span class="k">:</span> <span class="kt">FiniteDuration</span> <span class="o">=</span> <span class="mf">1005.</span><span class="n">millis</span>
    <span class="k">override</span> <span class="k">val</span> <span class="nv">minConsumeDelayMillis</span><span class="k">:</span> <span class="kt">Long</span> <span class="o">=</span> <span class="mi">10</span>
    <span class="k">override</span> <span class="k">val</span> <span class="nv">maxConsumeDelayMillis</span><span class="k">:</span> <span class="kt">Long</span> <span class="o">=</span> <span class="mi">2000</span>
  <span class="o">},</span>
  <span class="k">new</span> <span class="nc">TestConfig</span> <span class="o">{</span>
    <span class="k">override</span> <span class="k">val</span> <span class="nv">testName</span><span class="k">:</span> <span class="kt">String</span> <span class="o">=</span> <span class="s">"slow-consumer"</span>
    <span class="k">override</span> <span class="k">val</span> <span class="nv">produceDelay</span><span class="k">:</span> <span class="kt">FiniteDuration</span> <span class="o">=</span> <span class="mf">10.</span><span class="n">millis</span>
    <span class="k">override</span> <span class="k">val</span> <span class="nv">minConsumeDelayMillis</span><span class="k">:</span> <span class="kt">Long</span> <span class="o">=</span> <span class="mi">10</span>
    <span class="k">override</span> <span class="k">val</span> <span class="nv">maxConsumeDelayMillis</span><span class="k">:</span> <span class="kt">Long</span> <span class="o">=</span> <span class="mi">1000</span>
  <span class="o">}</span>
<span class="o">)</span>
</code></pre></div></div>

<h2 id="approach-1-batch-consuming">Approach 1: Batch Consuming</h2>

<p>The first approach is to make the consuming side parallel. We can consume a batch of tasks concurrently, like in <a href="https://github.com/wb14123/scala-stream-demo/blob/master/src/main/scala/BatchIOApp.scala">BatchIOApp.scala</a>.</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">loop</span><span class="o">(</span><span class="n">start</span><span class="k">:</span> <span class="kt">Int</span><span class="o">)</span><span class="k">:</span> <span class="kt">IO</span><span class="o">[</span><span class="kt">Unit</span><span class="o">]</span> <span class="k">=</span> <span class="o">{</span>
  <span class="nf">if</span> <span class="o">(</span><span class="n">start</span> <span class="o">&gt;=</span> <span class="nv">config</span><span class="o">.</span><span class="py">totalSize</span><span class="o">)</span> <span class="o">{</span>
    <span class="nv">IO</span><span class="o">.</span><span class="py">unit</span>
  <span class="o">}</span> <span class="k">else</span> <span class="o">{</span>
    <span class="nf">produce</span><span class="o">(</span><span class="n">start</span><span class="o">,</span> <span class="n">start</span> <span class="o">+</span> <span class="nv">config</span><span class="o">.</span><span class="py">batchSize</span><span class="o">)</span>
      <span class="o">.</span><span class="py">flatMap</span><span class="o">{</span><span class="nv">_</span><span class="o">.</span><span class="py">map</span><span class="o">(</span><span class="n">consume</span><span class="o">).</span><span class="py">parSequence</span><span class="o">}</span>
      <span class="o">.</span><span class="py">flatMap</span><span class="o">(</span><span class="k">_</span> <span class="k">=&gt;</span> <span class="nf">loop</span><span class="o">(</span><span class="n">start</span> <span class="o">+</span> <span class="nv">config</span><span class="o">.</span><span class="py">batchSize</span><span class="o">))</span>
  <span class="o">}</span>
<span class="o">}</span>
</code></pre></div></div>

<p>However, this only makes a batch of tasks run in parallel. It needs to wait the whole batch to be finished in order to start next batch. This is very obvious when we run this approach and see the output of characters (download <a href="https://github.com/wb14123/scala-stream-demo">Github repo</a> and run <code class="language-plaintext highlighter-rouge">sbt "run -n BatchIOApp"</code>). See how it paused after each batch even when consumer is slower than producer:</p>

<div id="cast-tmpg4x5_bn7-ascii"></div>
<script src="/static/js/asciinema-player.min.js"></script>
<script>AsciinemaPlayer.create('/static/asciicasts/tmpg4x5_bn7-ascii.cast', document.getElementById('cast-tmpg4x5_bn7-ascii'), {rows: 10, autoPlay: true});</script>

<h2 id="approach-2-use-blocking-queue-to-buffer-tasks">Approach 2: Use Blocking Queue to Buffer Tasks</h2>

<p>We need a way to let producers not waiting for consumers, and also let consumers not wait for a batch to finish in order to start next batch. A very common solution is to use a queue between producers and consumers. Producers put tasks into the queue, and consumers get tasks for the queue. If the queue is thread safe, then both producers and consumers can work on their own without care about each other. In order to not let producer put unlimited tasks into the queue to blowup the memory, we need the queue to have a capacity. When the queue is full, the producer should be blocked. And when the queue is empty, the consumers should be blocked as well.</p>

<p>In Java, <code class="language-plaintext highlighter-rouge">BlockingQueue</code> meets our requirements. We can use an implementation <code class="language-plaintext highlighter-rouge">LinkedBlockingQueue</code>. However, <code class="language-plaintext highlighter-rouge">BlockingQueue</code> will block the whole thread instead of a single <code class="language-plaintext highlighter-rouge">IO</code>. Let’s not worry about it for now and see how to use a queue to implement producing and consuming in parallel. The implementation is in <a href="https://github.com/wb14123/scala-stream-demo/blob/master/src/main/scala/BlockingQueueApp.scala">BlockingQueueApp.scala</a>:</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="k">val</span> <span class="nv">queue</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">LinkedBlockingQueue</span><span class="o">[</span><span class="kt">Option</span><span class="o">[</span><span class="kt">Int</span><span class="o">]](</span><span class="nv">config</span><span class="o">.</span><span class="py">batchSize</span> <span class="o">*</span> <span class="mi">2</span><span class="o">)</span>

<span class="k">override</span> <span class="k">def</span> <span class="nf">work</span><span class="o">()</span><span class="k">:</span> <span class="kt">IO</span><span class="o">[</span><span class="kt">Unit</span><span class="o">]</span> <span class="k">=</span> <span class="o">{</span>
  <span class="nc">Seq</span><span class="o">(</span>
    <span class="o">(</span><span class="nf">produceStream</span><span class="o">(</span><span class="mi">0</span><span class="o">).</span><span class="py">map</span><span class="o">(</span><span class="nc">Some</span><span class="o">(</span><span class="k">_</span><span class="o">))</span> <span class="o">++</span> <span class="nv">fs2</span><span class="o">.</span><span class="py">Stream</span><span class="o">.</span><span class="py">emit</span><span class="o">(</span><span class="nc">None</span><span class="o">))</span>
			<span class="o">.</span><span class="py">evalMap</span><span class="o">(</span><span class="n">x</span> <span class="k">=&gt;</span> <span class="nc">IO</span><span class="o">(</span><span class="nv">queue</span><span class="o">.</span><span class="py">put</span><span class="o">(</span><span class="n">x</span><span class="o">))).</span><span class="py">compile</span><span class="o">.</span><span class="py">drain</span><span class="o">,</span>
    <span class="nf">dequeueStream</span><span class="o">().</span><span class="py">unNoneTerminate</span><span class="o">.</span><span class="py">parEvalMap</span><span class="o">(</span><span class="nv">config</span><span class="o">.</span><span class="py">batchSize</span><span class="o">)(</span><span class="n">consume</span><span class="o">).</span><span class="py">compile</span><span class="o">.</span><span class="py">drain</span><span class="o">,</span>
  <span class="o">).</span><span class="py">parSequence</span><span class="o">.</span><span class="py">map</span><span class="o">(</span><span class="k">_</span> <span class="k">=&gt;</span> <span class="o">())</span>
<span class="o">}</span>

<span class="k">private</span> <span class="k">def</span> <span class="nf">dequeueStream</span><span class="o">()</span><span class="k">:</span> <span class="kt">fs2.Stream</span><span class="o">[</span><span class="kt">IO</span>, <span class="kt">Option</span><span class="o">[</span><span class="kt">Int</span><span class="o">]]</span> <span class="k">=</span> <span class="o">{</span>
  <span class="nv">fs2</span><span class="o">.</span><span class="py">Stream</span><span class="o">.</span><span class="py">eval</span><span class="o">(</span><span class="nc">IO</span><span class="o">(</span><span class="nv">queue</span><span class="o">.</span><span class="py">take</span><span class="o">()))</span> <span class="o">++</span> <span class="nf">dequeueStream</span><span class="o">()</span>
<span class="o">}</span>
</code></pre></div></div>

<p>Here we have two IOs run in parallel with <code class="language-plaintext highlighter-rouge">parSequence</code>: the first one creates a task stream by <code class="language-plaintext highlighter-rouge">produceStream</code>, and append <code class="language-plaintext highlighter-rouge">None</code> at the end so that the consumer knows it should end processing. Another stream <code class="language-plaintext highlighter-rouge">dequeueStream</code> gets the tasks from the queue then consumes it in parallel with <code class="language-plaintext highlighter-rouge">parEvalmap(config.batchSize)(consume)</code>.</p>

<p>When run it with <code class="language-plaintext highlighter-rouge">sbt "run -n BlockingQueueApp"</code>, we can see it’s much faster when the consumer is faster or has the same speed as the producer. Especially when the consumer is slow, it prints multiple <code class="language-plaintext highlighter-rouge">P</code> at first, which means the producers doesn’t wait all the consumers to finish in order to produce tasks.</p>

<div id="cast-tmp6dx2heu_-ascii"></div>
<script src="/static/js/asciinema-player.min.js"></script>
<script>AsciinemaPlayer.create('/static/asciicasts/tmp6dx2heu_-ascii.cast', document.getElementById('cast-tmp6dx2heu_-ascii'), {rows: 10, autoPlay: true});</script>

<p>Back to the blocking the whole thread problem: it doesn’t seem to be a problem in this case, right? It’s only because we are lucky! In this setup, we are using two fixed threads as the thread pool of running IO in <code class="language-plaintext highlighter-rouge">Main.scala</code>:</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">private</span> <span class="k">val</span> <span class="nv">executor</span> <span class="k">=</span> <span class="nv">Executors</span><span class="o">.</span><span class="py">newFixedThreadPool</span><span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="o">(</span><span class="n">r</span><span class="k">:</span> <span class="kt">Runnable</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="o">{</span>
  <span class="k">val</span> <span class="nv">back</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Thread</span><span class="o">(</span><span class="n">r</span><span class="o">)</span>
  <span class="nv">back</span><span class="o">.</span><span class="py">setDaemon</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>
  <span class="n">back</span>
<span class="o">})</span>

<span class="k">implicit</span> <span class="k">override</span> <span class="k">def</span> <span class="nf">executionContext</span><span class="k">:</span> <span class="kt">ExecutionContext</span> <span class="o">=</span> <span class="nv">ExecutionContext</span><span class="o">.</span><span class="py">fromExecutor</span><span class="o">(</span><span class="n">executor</span><span class="o">)</span>

<span class="k">implicit</span> <span class="k">override</span> <span class="k">def</span> <span class="nf">timer</span><span class="k">:</span> <span class="kt">Timer</span><span class="o">[</span><span class="kt">IO</span><span class="o">]</span> <span class="k">=</span> <span class="nv">IO</span><span class="o">.</span><span class="py">timer</span><span class="o">(</span><span class="n">executionContext</span><span class="o">)</span>

<span class="k">implicit</span> <span class="k">override</span> <span class="k">def</span> <span class="nf">contextShift</span><span class="k">:</span> <span class="kt">ContextShift</span><span class="o">[</span><span class="kt">IO</span><span class="o">]</span> <span class="k">=</span> <span class="nv">IO</span><span class="o">.</span><span class="py">contextShift</span><span class="o">(</span><span class="n">executionContext</span><span class="o">)</span>
</code></pre></div></div>

<p>If 2 consumers with empty queue happens to be scheduled on these 2 threads separately, it will block. If we change our <code class="language-plaintext highlighter-rouge">BlockingQueueApp</code> to the code in <a href="https://github.com/wb14123/scala-stream-demo/blob/master/src/main/scala/RealBlockingQueueApp.scala">RealBlockingQueueApp</a>:</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">override</span> <span class="k">def</span> <span class="nf">work</span><span class="o">()</span><span class="k">:</span> <span class="kt">IO</span><span class="o">[</span><span class="kt">Unit</span><span class="o">]</span> <span class="k">=</span> <span class="o">{</span>
  <span class="nc">Seq</span><span class="o">(</span>
    <span class="nf">dequeueStream</span><span class="o">().</span><span class="py">unNoneTerminate</span><span class="o">.</span><span class="py">parEvalMap</span><span class="o">(</span><span class="nv">config</span><span class="o">.</span><span class="py">batchSize</span><span class="o">)(</span><span class="n">consume</span><span class="o">).</span><span class="py">compile</span><span class="o">.</span><span class="py">drain</span><span class="o">,</span>
    <span class="nf">dequeueStream</span><span class="o">().</span><span class="py">unNoneTerminate</span><span class="o">.</span><span class="py">parEvalMap</span><span class="o">(</span><span class="nv">config</span><span class="o">.</span><span class="py">batchSize</span><span class="o">)(</span><span class="n">consume</span><span class="o">).</span><span class="py">compile</span><span class="o">.</span><span class="py">drain</span><span class="o">,</span>
    <span class="o">(</span><span class="nf">produceStream</span><span class="o">(</span><span class="mi">0</span><span class="o">).</span><span class="py">map</span><span class="o">(</span><span class="nc">Some</span><span class="o">(</span><span class="k">_</span><span class="o">))</span> <span class="o">++</span> <span class="nv">fs2</span><span class="o">.</span><span class="py">Stream</span><span class="o">.</span><span class="py">emit</span><span class="o">(</span><span class="nc">None</span><span class="o">)).</span><span class="py">evalMap</span><span class="o">(</span><span class="n">x</span> <span class="k">=&gt;</span> <span class="nc">IO</span><span class="o">(</span><span class="nv">queue</span><span class="o">.</span><span class="py">put</span><span class="o">(</span><span class="n">x</span><span class="o">))).</span><span class="py">compile</span><span class="o">.</span><span class="py">drain</span><span class="o">,</span>
  <span class="o">).</span><span class="py">parSequence</span><span class="o">.</span><span class="py">map</span><span class="o">(</span><span class="k">_</span> <span class="k">=&gt;</span> <span class="o">())</span>
<span class="o">}</span>
</code></pre></div></div>

<p>Here we started two dequeue stream at first. Now the whole program will block when run it with <code class="language-plaintext highlighter-rouge">sbt "run -b"</code> .</p>

<p>The lesson learned here is that there is a big risk if any operation blocks the whole thread in cats effect. Even it doesn’t block the whole program, it may make a whole thread unavailable.</p>

<p>Actually in <a href="https://typelevel.org/cats-effect/docs/thread-model">Cats Effect’s thread model</a>, there is another thread pool for blocking tasks if we mark it explicitly. In <a href="https://github.com/wb14123/scala-stream-demo/blob/master/src/main/scala/AsyncConsole.scala">AsyncConsole.scala</a>, I use this exact block mode to run console output so that it won’t effect other non blocking IO operations:</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">asyncPrintln</span><span class="o">(</span><span class="n">s</span><span class="k">:</span> <span class="kt">String</span><span class="o">)(</span>
    <span class="k">implicit</span> <span class="n">cs</span><span class="k">:</span> <span class="kt">ContextShift</span><span class="o">[</span><span class="kt">IO</span><span class="o">],</span> <span class="n">blocker</span><span class="k">:</span> <span class="kt">Blocker</span><span class="o">)</span><span class="k">:</span> <span class="kt">IO</span><span class="o">[</span><span class="kt">Unit</span><span class="o">]</span> <span class="k">=</span> <span class="nv">blocker</span><span class="o">.</span><span class="py">blockOn</span><span class="o">(</span><span class="nc">IO</span><span class="o">(</span><span class="nf">println</span><span class="o">(</span><span class="n">s</span><span class="o">)))</span>
</code></pre></div></div>

<p>However, if a thread is blocked in this pool, it will start another thread for the next operation. Based on the document, there is no limit on how many threads will be created. So if the producer is much slower than consumer, there will be more and more consume operations blocked on dequeue, so it will generate a large amount of threads, which is not ideal and eventually even will blow up the memory.</p>

<h2 id="approach-3-use-cats-effect-friendly-queue">Approach 3: Use Cats Effect Friendly Queue</h2>

<p>What if we have a queue that only block the dequeue <code class="language-plaintext highlighter-rouge">IO</code> when empty instead of blocking the whole thread? Luckily, FS2 provides such a queue. (Cats Effect 3.x also provides such a queue). The implementation is basically the same as above (code in <a href="https://github.com/wb14123/scala-stream-demo/blob/master/src/main/scala/StreamQueueApp.scala">StreamQueueApp.scala</a>):</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">fs2.concurrent.Queue</span>

<span class="k">def</span> <span class="nf">work</span><span class="o">()</span><span class="k">:</span> <span class="kt">IO</span><span class="o">[</span><span class="kt">Unit</span><span class="o">]</span> <span class="k">=</span> <span class="o">{</span>
  <span class="k">for</span> <span class="o">{</span>
    <span class="n">queue</span> <span class="k">&lt;-</span> <span class="nv">Queue</span><span class="o">.</span><span class="py">bounded</span><span class="o">[</span><span class="kt">IO</span>, <span class="kt">Option</span><span class="o">[</span><span class="kt">Int</span><span class="o">]](</span><span class="nv">config</span><span class="o">.</span><span class="py">batchSize</span> <span class="o">*</span> <span class="mi">2</span><span class="o">)</span>
    <span class="k">_</span> <span class="k">&lt;-</span> <span class="nc">Seq</span><span class="o">(</span>
      <span class="o">(</span><span class="nf">produceStream</span><span class="o">(</span><span class="mi">0</span><span class="o">).</span><span class="py">map</span><span class="o">(</span><span class="nc">Some</span><span class="o">(</span><span class="k">_</span><span class="o">))</span> <span class="o">++</span> <span class="nv">fs2</span><span class="o">.</span><span class="py">Stream</span><span class="o">.</span><span class="py">emit</span><span class="o">(</span><span class="nc">None</span><span class="o">)).</span><span class="py">through</span><span class="o">(</span><span class="nv">queue</span><span class="o">.</span><span class="py">enqueue</span><span class="o">).</span><span class="py">compile</span><span class="o">.</span><span class="py">drain</span><span class="o">,</span>
      <span class="nv">queue</span><span class="o">.</span><span class="py">dequeue</span><span class="o">.</span><span class="py">unNoneTerminate</span><span class="o">.</span><span class="py">parEvalMap</span><span class="o">(</span><span class="nv">config</span><span class="o">.</span><span class="py">batchSize</span><span class="o">)(</span><span class="n">consume</span><span class="o">).</span><span class="py">compile</span><span class="o">.</span><span class="py">drain</span><span class="o">,</span>
    <span class="o">).</span><span class="py">parSequence</span>
  <span class="o">}</span> <span class="nf">yield</span> <span class="o">()</span>
<span class="o">}</span>
</code></pre></div></div>

<p>Run <code class="language-plaintext highlighter-rouge">sbt "run -n StreamAppQueue"</code> to see how it performs.</p>

<h2 id="approach-4-use-fs2-stream-directly">Approach 4: Use FS2 Stream Directly</h2>

<p>FS2 actually provides some advanced stream operations that makes it possible to combine the producing stream and consume stream, like the code in <a href="https://github.com/wb14123/scala-stream-demo/blob/master/src/main/scala/StreamApp.scala">StreamApp.scala</a>:</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">produceStream</span><span class="o">(</span><span class="mi">0</span><span class="o">).</span><span class="py">parEvalMap</span><span class="o">(</span><span class="nv">config</span><span class="o">.</span><span class="py">batchSize</span><span class="o">)(</span><span class="n">consume</span><span class="o">).</span><span class="py">compile</span><span class="o">.</span><span class="py">drain</span>
</code></pre></div></div>

<p>Here we map <code class="language-plaintext highlighter-rouge">consume</code> in parallel on <code class="language-plaintext highlighter-rouge">produce</code> stream. However, if you try to run <code class="language-plaintext highlighter-rouge">sbt "run -n StreamApp"</code> vs <code class="language-plaintext highlighter-rouge">sbt "run -n StreamQueueApp"</code>, you will find this is slower than before. This is because <code class="language-plaintext highlighter-rouge">produceStream</code> will give the next batch when the downstream asks. If we can prepare at least one batch before the downstream is free, we can save more time. Luckily, it’s very easy to do in fs2. As we can see in <a href="https://github.com/wb14123/scala-stream-demo/blob/master/src/main/scala/PrefetchStreamApp.scala">PrefetchStreamApp.scala</a>, we can add <code class="language-plaintext highlighter-rouge">prefetch</code> after the <code class="language-plaintext highlighter-rouge">produceStream</code>:</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">produceStream</span><span class="o">(</span><span class="mi">0</span><span class="o">).</span><span class="py">prefetch</span><span class="o">.</span><span class="py">parEvalMap</span><span class="o">(</span><span class="nv">config</span><span class="o">.</span><span class="py">batchSize</span><span class="o">)(</span><span class="n">consume</span><span class="o">).</span><span class="py">compile</span><span class="o">.</span><span class="py">drain</span>
</code></pre></div></div>

<p>It will prefetch a <a href="https://fs2.io/#/guide?id=chunks">chunk</a> of elements. Use <code class="language-plaintext highlighter-rouge">prefetchN</code> if you want to prefetch N chunks.</p>

<p>Then run this with <code class="language-plaintext highlighter-rouge">sbt "run -n PrefetchStreamApp"</code>, you will find the performance is similar as the queued approach.</p>

<p>Actually if you check the source code of <code class="language-plaintext highlighter-rouge">prefetch</code>, you will find the implementation is almost the same as ours:</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">prefetch</span><span class="o">[</span><span class="kt">F2</span><span class="o">[</span><span class="kt">x</span><span class="o">]</span> <span class="k">&gt;:</span> <span class="kt">F</span><span class="o">[</span><span class="kt">x</span><span class="o">]</span><span class="kt">:</span> <span class="kt">Concurrent</span><span class="o">]</span><span class="k">:</span> <span class="kt">Stream</span><span class="o">[</span><span class="kt">F2</span>, <span class="kt">O</span><span class="o">]</span> <span class="k">=</span> <span class="n">prefetchN</span><span class="o">[</span><span class="kt">F2</span><span class="o">](</span><span class="mi">1</span><span class="o">)</span>

<span class="k">def</span> <span class="nf">prefetchN</span><span class="o">[</span><span class="kt">F2</span><span class="o">[</span><span class="kt">x</span><span class="o">]</span> <span class="k">&gt;:</span> <span class="kt">F</span><span class="o">[</span><span class="kt">x</span><span class="o">]</span><span class="kt">:</span> <span class="kt">Concurrent</span><span class="o">](</span><span class="n">n</span><span class="k">:</span> <span class="kt">Int</span><span class="o">)</span><span class="k">:</span> <span class="kt">Stream</span><span class="o">[</span><span class="kt">F2</span>, <span class="kt">O</span><span class="o">]</span> <span class="k">=</span>
  <span class="nv">Stream</span><span class="o">.</span><span class="py">eval</span><span class="o">(</span><span class="nv">Queue</span><span class="o">.</span><span class="py">bounded</span><span class="o">[</span><span class="kt">F2</span>, <span class="kt">Option</span><span class="o">[</span><span class="kt">Chunk</span><span class="o">[</span><span class="kt">O</span><span class="o">]]](</span><span class="n">n</span><span class="o">)).</span><span class="py">flatMap</span> <span class="o">{</span> <span class="n">queue</span> <span class="k">=&gt;</span>
    <span class="nv">queue</span><span class="o">.</span><span class="py">dequeue</span><span class="o">.</span><span class="py">unNoneTerminate</span>
      <span class="o">.</span><span class="py">flatMap</span><span class="o">(</span><span class="nv">Stream</span><span class="o">.</span><span class="py">chunk</span><span class="o">(</span><span class="k">_</span><span class="o">))</span>
      <span class="o">.</span><span class="py">concurrently</span><span class="o">(</span><span class="nv">chunks</span><span class="o">.</span><span class="py">noneTerminate</span><span class="o">.</span><span class="py">covary</span><span class="o">[</span><span class="kt">F2</span><span class="o">].</span><span class="py">through</span><span class="o">(</span><span class="nv">queue</span><span class="o">.</span><span class="py">enqueue</span><span class="o">))</span>
  <span class="o">}</span>
</code></pre></div></div>

<h2 id="approach-5-make-producers-run-in-parallel">Approach 5: Make Producers Run in Parallel</h2>

<p>We’ve made it runs in parallel between consumers, also between consumers and producers. But we haven’t made producers run in parallel yet. With the queue, its very easy to do, just start multiple <code class="language-plaintext highlighter-rouge">IO</code>s for <code class="language-plaintext highlighter-rouge">produceStream.through(queue.enqueue)</code>. <a href="https://github.com/wb14123/scala-stream-demo/blob/master/src/main/scala/ConcurrentProducerQueueApp.scala">ConcurrentProduceQueueApp.scala</a> is an example:</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">private</span> <span class="k">val</span> <span class="nv">counter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">AtomicInteger</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span>

<span class="k">override</span> <span class="k">def</span> <span class="nf">work</span><span class="o">()</span><span class="k">:</span> <span class="kt">IO</span><span class="o">[</span><span class="kt">Unit</span><span class="o">]</span> <span class="k">=</span> <span class="o">{</span>
  <span class="k">for</span> <span class="o">{</span>
    <span class="n">queue</span> <span class="k">&lt;-</span> <span class="nv">Queue</span><span class="o">.</span><span class="py">bounded</span><span class="o">[</span><span class="kt">IO</span>, <span class="kt">Int</span><span class="o">](</span><span class="nv">config</span><span class="o">.</span><span class="py">batchSize</span> <span class="o">*</span> <span class="mi">2</span><span class="o">)</span>
    <span class="k">_</span> <span class="k">&lt;-</span> <span class="nc">Seq</span><span class="o">(</span>
      <span class="nf">produceStream</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="nv">config</span><span class="o">.</span><span class="py">totalSize</span> <span class="o">/</span> <span class="mi">2</span><span class="o">).</span><span class="py">through</span><span class="o">(</span><span class="nv">queue</span><span class="o">.</span><span class="py">enqueue</span><span class="o">).</span><span class="py">compile</span><span class="o">.</span><span class="py">drain</span><span class="o">,</span>
      <span class="nf">produceStream</span><span class="o">(</span><span class="nv">config</span><span class="o">.</span><span class="py">totalSize</span> <span class="o">/</span> <span class="mi">2</span><span class="o">,</span> <span class="nv">config</span><span class="o">.</span><span class="py">totalSize</span><span class="o">).</span><span class="py">through</span><span class="o">(</span><span class="nv">queue</span><span class="o">.</span><span class="py">enqueue</span><span class="o">).</span><span class="py">compile</span><span class="o">.</span><span class="py">drain</span><span class="o">,</span>
      <span class="nv">queue</span><span class="o">.</span><span class="py">dequeue</span><span class="o">.</span><span class="py">parEvalMap</span><span class="o">(</span><span class="nv">config</span><span class="o">.</span><span class="py">batchSize</span><span class="o">)</span> <span class="o">{</span> <span class="n">x</span> <span class="k">=&gt;</span>
        <span class="nf">consume</span><span class="o">(</span><span class="n">x</span><span class="o">).</span><span class="py">map</span> <span class="o">{</span> <span class="k">_</span> <span class="k">=&gt;</span>
          <span class="nf">if</span> <span class="o">(</span><span class="nv">counter</span><span class="o">.</span><span class="py">incrementAndGet</span><span class="o">()</span> <span class="o">&gt;=</span> <span class="nv">config</span><span class="o">.</span><span class="py">totalSize</span><span class="o">)</span> <span class="o">{</span>
            <span class="nc">None</span>
          <span class="o">}</span> <span class="k">else</span> <span class="o">{</span>
            <span class="nc">Some</span><span class="o">()</span>
          <span class="o">}</span>
        <span class="o">}</span>
      <span class="o">}.</span><span class="py">unNoneTerminate</span><span class="o">.</span><span class="py">compile</span><span class="o">.</span><span class="py">drain</span><span class="o">,</span>
    <span class="o">).</span><span class="py">parSequence</span>
  <span class="o">}</span> <span class="nf">yield</span> <span class="o">()</span>
<span class="o">}</span>
</code></pre></div></div>

<p>It has 2 concurrent producers but in theory you can create as many as you want, just be careful with the parameters of <code class="language-plaintext highlighter-rouge">produceStream</code>.</p>

<p>If you run this with <code class="language-plaintext highlighter-rouge">sbt "run -n ConcurrentProduceQueueApp"</code>, you can find the performance is much better with slower producer. However, with the help of fs2 library, we can make the code cleaner without depends on any queue explicitly. Here is what I did in <a href="https://github.com/wb14123/scala-stream-demo/blob/master/src/main/scala/ConcurrentProducerApp.scala">ConcurrentProducerApp.scala</a>:</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">work</span><span class="o">()</span><span class="k">:</span> <span class="kt">IO</span><span class="o">[</span><span class="kt">Unit</span><span class="o">]</span> <span class="k">=</span> <span class="o">{</span>
  <span class="nv">fs2</span><span class="o">.</span><span class="py">Stream</span><span class="o">.</span><span class="py">emits</span><span class="o">(</span><span class="nc">Range</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="n">produceParallelism</span><span class="o">))</span>
    <span class="o">.</span><span class="py">map</span><span class="o">(</span><span class="n">batch</span> <span class="k">=&gt;</span> <span class="nf">produceStream</span><span class="o">(</span>
      <span class="n">batch</span> <span class="o">*</span> <span class="nv">config</span><span class="o">.</span><span class="py">totalSize</span> <span class="o">/</span> <span class="n">produceParallelism</span><span class="o">,</span>
      <span class="o">(</span><span class="n">batch</span> <span class="o">+</span> <span class="mi">1</span><span class="o">)</span> <span class="o">*</span> <span class="nv">config</span><span class="o">.</span><span class="py">totalSize</span> <span class="o">/</span> <span class="nv">produceParallelism</span><span class="o">.</span><span class="py">toDouble</span><span class="o">))</span>
    <span class="o">.</span><span class="py">parJoin</span><span class="o">(</span><span class="n">produceParallelism</span><span class="o">)</span>
    <span class="o">.</span><span class="py">prefetch</span>
    <span class="o">.</span><span class="py">parEvalMap</span><span class="o">(</span><span class="nv">config</span><span class="o">.</span><span class="py">batchSize</span><span class="o">)(</span><span class="n">consume</span><span class="o">).</span><span class="py">compile</span><span class="o">.</span><span class="py">drain</span>
<span class="o">}</span>
</code></pre></div></div>

<p>Here we use <code class="language-plaintext highlighter-rouge">parJoin</code> to join multiple producer stream at the same time.</p>

<h2 id="more">More</h2>

<p>All the approaches above other than the first one uses a queue either implicitly or explicitly. However, under high parallelism and load, every job operating on a single queue may makes this queue a bottleneck. In this case, there is a <a href="https://en.wikipedia.org/wiki/Work_stealing">work stealing</a> algorithm that each consumers can has its own queue, and whenever a consumer’s queue is empty, it steal some tasks from another one. But it’s a little bit complex and unnecessary if the load is not so high, so I will not cover it in this article.</p>

<h2 id="test-results">Test Results</h2>

<p>Now let’s run all the approaches and compare the performance with <code class="language-plaintext highlighter-rouge">sbt "run -n"</code>. Here are the results:</p>

<table>
  <thead>
    <tr>
      <th> </th>
      <th>slow producer</th>
      <th>balanced</th>
      <th>slow consumer</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>BatchIO</td>
      <td>11086.078637 ms</td>
      <td>29912.377578 ms</td>
      <td>10015.51878 ms</td>
    </tr>
    <tr>
      <td>BlockingQueue</td>
      <td>10190.038753 ms</td>
      <td>14195.228189 ms</td>
      <td>6495.333179 ms</td>
    </tr>
    <tr>
      <td>StreamQueue</td>
      <td>10138.016643 ms</td>
      <td>14458.443122 ms</td>
      <td>6418.078377 ms</td>
    </tr>
    <tr>
      <td>Stream</td>
      <td>10356.178562 ms</td>
      <td>15655.697826 ms</td>
      <td>6560.111697 ms</td>
    </tr>
    <tr>
      <td>PrefetchStream</td>
      <td>10141.110634 ms</td>
      <td>14578.362136 ms</td>
      <td>6376.628036 ms</td>
    </tr>
    <tr>
      <td>ConcurrentProduceresQueue</td>
      <td>5187.442452 ms</td>
      <td>14395.321922 ms</td>
      <td>6576.538821 ms</td>
    </tr>
    <tr>
      <td>ConcurrentProducer</td>
      <td>5198.723825 ms</td>
      <td>14544.247312 ms</td>
      <td>6418.078377 ms</td>
    </tr>
  </tbody>
</table>

<p>We can see approaches that parallelize all the parts win the performance game.</p>]]></content><author><name></name></author><category term="Scala" /><category term="concurrent" /><category term="cats" /><category term="cats-effect" /><category term="fs2" /><category term="queue" /><category term="stream" /><summary type="html"><![CDATA[All the source code mentioned in this blog can be found in my Github repo.]]></summary></entry><entry><title type="html">Upgrade Kubernetes from 1.23 to 1.24</title><link href="https://www.binwang.me/2023-05-22-Upgrade-Kubernetes-from-1.23-to-1.24.html" rel="alternate" type="text/html" title="Upgrade Kubernetes from 1.23 to 1.24" /><published>2023-05-22T00:00:00-04:00</published><updated>2023-05-22T00:00:00-04:00</updated><id>https://www.binwang.me/Upgrade-Kubernetes-from-1.23-to-1.24</id><content type="html" xml:base="https://www.binwang.me/2023-05-22-Upgrade-Kubernetes-from-1.23-to-1.24.html"><![CDATA[<p>In the <a href="/2023-03-13-Infrastructure-Setup-for-High-Availability.html">last blog post</a>, I introduced using Kubernetes to setup high available infrastructure. I had that setup a long time ago. I did the long overdue upgrade for Kubernetes from 1.23 to 1.24 recently. Since GlusterFS is <a href="https://github.com/kubernetes/kubernetes/pull/111485">deprecated</a>(though not removed) in 1.25, I have no plans to continue the upgrade without exploring alternative storage options.</p>

<p>There is a big change from 1.23 to 1.24 as well, namely, <a href="https://kubernetes.io/blog/2022/03/31/ready-for-dockershim-removal/">Docker Engine support has been removed</a>. I migrated the container engine to containerd. But the process is not without pain. I need to search different sources to fix the issues. So I list my upgrade steps so that if anyone has the same issue, this may help.</p>

<p>My Kubernetes cluster is set up locally with <code class="language-plaintext highlighter-rouge">kubeadm</code>. There is an <a href="https://v1-24.docs.kubernetes.io/docs/tasks/administer-cluster/kubeadm/kubeadm-upgrade/">official upgrade guide</a> for kubeadm to upgrade from 1.23 to 1.24, but it doesn’t mention any steps to remove Docker and setup containerd. So here are the steps I took:</p>

<ol>
  <li>Add <code class="language-plaintext highlighter-rouge">--container-runtime-endpoint</code> option to kubelet. The way I did it is adding <code class="language-plaintext highlighter-rouge">KUBELET_ARGS="--container-runtime-endpoint=/run/containerd/containerd.sock"</code> to <code class="language-plaintext highlighter-rouge">/etc/kubernetes/kublet.env</code>. Without this, Kubelet will fail to start.</li>
  <li>Remove <code class="language-plaintext highlighter-rouge">--network-plugin=cni</code> from  <code class="language-plaintext highlighter-rouge">/var/lib/kubelet/kubeadm-flags.env</code>.</li>
  <li>Add the following configuration in <code class="language-plaintext highlighter-rouge">/etc/crictl.yaml</code>, otherwise kubeadm will not be able to pull needed images:
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>runtime-endpoint: unix:///run/containerd/containerd.sock
image-endpoint: unix:///run/containerd/containerd.sock
timeout: 10
debug: false
</code></pre></div>    </div>
  </li>
  <li>Configure <code class="language-plaintext highlighter-rouge">SystemdCgroup</code> permission for containerd. Otherwise kube-apiserver will always be restarted because of “sandbox environment changes” (see more in <a href="https://github.com/kubernetes/kubernetes/issues/110177">Github issue</a>):
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>sudo mkdir -p /etc/containerd/
containerd config default | sudo tee /etc/containerd/config.toml
sudo sed -i 's/SystemdCgroup \= false/SystemdCgroup \= true/g' /etc/containerd/config.toml
sudo systemctl restart containerd
</code></pre></div>    </div>
  </li>
  <li>Follow the <a href="https://v1-24.docs.kubernetes.io/docs/tasks/administer-cluster/kubeadm/kubeadm-upgrade/">official upgrade guide</a>.</li>
  <li>After the upgrade, remember to restart Docker so that the old containers started by Docker will be stopped.</li>
</ol>]]></content><author><name></name></author><category term="Kubernetes" /><category term="container" /><category term="Docker" /><category term="Linux" /><summary type="html"><![CDATA[In the last blog post, I introduced using Kubernetes to setup high available infrastructure. I had that setup a long time ago. I did the long overdue upgrade for Kubernetes from 1.23 to 1.24 recently. Since GlusterFS is deprecated(though not removed) in 1.25, I have no plans to continue the upgrade without exploring alternative storage options.]]></summary></entry><entry><title type="html">Infrastructure Setup for High Availability</title><link href="https://www.binwang.me/2023-03-13-Infrastructure-Setup-for-High-Availability.html" rel="alternate" type="text/html" title="Infrastructure Setup for High Availability" /><published>2023-03-13T00:00:00-04:00</published><updated>2023-03-13T00:00:00-04:00</updated><id>https://www.binwang.me/Infrastructure-Setup-for-High-Availability</id><content type="html" xml:base="https://www.binwang.me/2023-03-13-Infrastructure-Setup-for-High-Availability.html"><![CDATA[<p><em>See <a href="/2023-11-28-Introduce-K3s-CephFS-and-MetalLB-to-My-High-Avaliable-Cluster.html">Introduce K3s, CephFS and MetalLB to My High Avaliable Cluster</a> for updates on this setup.</em></p>

<p>Cloud is popular these days. But sometimes we just want to host something small, maybe just an open source service for family and friends, or some self-built service that we are still experimenting on. In this case, the cloud can be expensive. We can just throw a few nodes at home and run it at a very low cost. But you don’t want the service down when some nodes failed, at least the service should be available when you upgrade and reboot the nodes because it can happen very frequently. In this article, I will talk about how to build high available infrastructure so that the service can be alive even when some nodes are down.</p>

<h2 id="what-is-high-availability">What is High Availability?</h2>

<p>Availability means a service is alive and can serve traffic. High availability (HA) means when some components of the system are down, the service is still alive. The failed components can be in different layers: it can be a region, a DC, a network, or some nodes. In this article, I’ll only talk about things including and above node level, since region and network are usually out of control for a small infrastructure setup. That means you can host the service on multiple machines, and it should still be alive even when some of the machines are down. This is the most useful case of HA in the case anyway since nodes can be down frequently because of OS or software updates.</p>

<p>Before I start with the real setup, I want to clear some myths about HA first. Maybe you’ve heard of the famous CAP theorem, which says only two of the three properties can be met at the same time: consistency, availability, and partition tolerance. Lots of people misinterpret it as a HA system that will sacrifice consistency during a failure. It is not true: the type of partition that makes you must choose between consistency and availability is very rare. In most well-designed HA systems, you can have both as long as more than half of the nodes are alive (alive also means reachable from clients). And HA doesn’t necessarily mean it prioritizes availability over consistency either: it just means it can handle more failure cases when keeping both consistency and availability. When there is a failure it cannot handle, it can choose to keep consistency and make the service unavailable. This is the type of HA I’m going to introduce in this setup.</p>

<p>So to make it clear, the HA goal in this setup is to make the services still alive without sacrificing consistency when we lose less than half of the nodes (either it’s partitioned from the network or actually dead).</p>

<h2 id="ha-setup">HA Setup</h2>

<p>As said before, the HA needs multiple nodes in case of some nodes are down. The setup in this article can tolerate less than half of the node loss. So if you want to have a HA that can handle 1 node loss, the whole system needs at least 3 nodes. There are lots of cheap used machines on the market that have enough power to host many open source services.</p>

<p>The HA setup has multiple layers and we will use different tools for each of the layers:</p>

<ul>
  <li>Compute: Kubernetes</li>
  <li>Storage: GlusterFk</li>
  <li>Database: Cockroach DB</li>
  <li>Network Ingress: Cloudflare Tunnel</li>
</ul>

<p>Here is an overview of the setup:</p>

<p><img src="/static/images/2023-03-13-Infrastructure-Setup-for-High-Availability/HA-self-hosted.png" alt="overview" /></p>

<p><em>Update at 2023-11-28: updated the diagram to include Keepalived.</em></p>

<p>Let’s talk about each of them in detail.</p>

<h2 id="compute-kubernetes">Compute: Kubernetes</h2>

<p><a href="https://kubernetes.io/">Kubernetes</a> is a container orchestration system. Think of it as Docker but across machines. You define what you want to run in the format of YAML or Json, including how much CPU, memory, and storage to use, then Kubernetes will find a node that fits your needs to run your container. It also tries to keep the current system state that meets your definition. For example, if there is a node failed and your service’s container is on it, Kubernetes will try to find another node to start the container so that the state meets the definition. So if the service itself doesn’t have any state between restarts, you get HA for free using Kubernetes.</p>

<p>I must have some warnings about using Kubernetes. It’s a complex project that is used by many big players. It’s not very easy to set up, maintain or upgrade. You need lots of knowledge to make it work. It has so many open issues that your particular needs are most likely not prioritized. While it’s open source so that you can modify the code to meet your use case, and I’ve had good experience contributing code in the early days, the recent experience is not so good anymore: you may need to attend some discussions to push your change instead of async online discussion. That is a lot for a causal contributor. So I end up maintaining a custom branch of Kubernetes with the changes I need locally, which is also a lot for average users.</p>

<p>Even though Kubernetes is heavy, I still think it’s a good tool even for small deployments since it’s already the industry standard. If you want to dedicate the maintenance of the Kubernetes cluster to a third party in the future, you can find lots of providers very easily. And you can just migrate your services to a different cluster without much effort since you’ve already defined the deployment in a language that any Kubernetes cluster can understand.</p>

<p>If you decide Kubernetes is the way to go, Kubernetes can be deployed with Kubeadm. Here is the <a href="https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/">official document</a> about how to deploy a Kubernetes cluster. Make sure to finish the <a href="https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/high-availability/">HA setup</a> so that Kubernetes can survive even if some nodes are down.</p>

<p>Because of the nature of multiple nodes, every time the service restarts, the container can end on a different machine. So if your service needs to store anything on a disk, the data can get lost if you use the local disk of the machine. There are a few solutions for this:</p>

<ul>
  <li>Just don’t store data on a disk:
    <ul>
      <li>Store it in a database instead. But this is not an option for a service we don’t write and control.</li>
      <li>Send the files to another system. For example, you can send all the logs to something like Elastic Search so that it’s acceptable to lose logs after the container is restarted.</li>
      <li>Use <a href="https://kubernetes.io/docs/concepts/configuration/configmap/">ConfigMaps</a> for configuration files so that you can access them on any machine.</li>
    </ul>
  </li>
  <li>Bind the service to a specific node so that the container will run on that machine all the time. This needs the service itself to have HA built in so that when that node fails, the containers on the other nodes can still serve traffic. We will see an example of this in Cockroach DB setup.</li>
  <li>The last option is to use a distributed storage system that can be accessed from every machine. We will use GlusterFS for it in this setup.</li>
</ul>

<h2 id="storage-glusterfs">Storage: GlusterFS</h2>

<p><strong>WARNING: Gluster integration for Kubernetes has been removed since Kubernetes 1.26. You can use CephFS instead. Or check <a href="https://github.com/kadalu/kadalu/">Kadulu</a> if you still want to use GlusterFS.</strong></p>

<p><a href="https://www.gluster.org/">Gluster</a> is a distributed storage system. Once you created a GlusterFS volume, you can mount it to a machine just like NFS. The difference is the volume is backed by multiple machines so if even one of the machines fails, the volume is still usable. Kubernetes could mount a GlusterFS volume for containers as well. Sadly, Kubernetes has removed this support since version 1.26. But I’ve had this setup for a while and is still using an older version of Kubernetes, so I’ll still list GlusterFS as a solution here. The documents are still available for older versions. <a href="https://v1-24.docs.kubernetes.io/docs/concepts/storage/volumes/#glusterfs">Here is an example for Kubernetes 1.24</a>. You can select “versions” on the upper right to match your Kubernetes installation. CephFS is another distributed storage system, but it’s less user-friendly than GlusterFS in my opinion since the setup is more complex and it’s harder to mount it locally and explore it like a normal Linux file system. <a href="https://github.com/kadalu/kadalu/">Kadulu</a> seems to be another option if you still want to use GlusterFS, but I’ve never used it and I’m not sure if it’s production ready or not.</p>

<p>See <a href="https://docs.gluster.org/en/latest/Install-Guide/Overview/#what-is-gluster-without-making-me-learn-an-extra-glossary-of-terminology">the official install guide</a> for how to install Gluster and set it up. Most of the Linux distros already have the Gluster in the repo so you can install it by the package manager, and configure it based on the official document. Be aware you need to reserve a separate partition just for Gluster.</p>

<p>When creating a Gluster volume for use with Kubernetes, make sure to create it with at least 3 replicas so that you have HA for this volume. One of the replicas can be “<a href="https://docs.gluster.org/en/v3/Administrator%20Guide/arbiter-volumes-and-quorum/">arbiter</a>”, which means it’s only used for checking consistency and doesn’t store any actual data. So the data is only duplicated across 2 machines instead of 3 to save some space. Here is an example command to create such a volume:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>sudo gluster volume create &lt;volume-name&gt; replica 3 arbiter 1 &lt;host1&gt;:&lt;glusterfs-path&gt; &lt;host2&gt;:&lt;glusterfs-path&gt; &lt;host3&gt;:&lt;glusterfs-path&gt;
</code></pre></div></div>

<h2 id="database-cockroachdb">Database: CockroachDB</h2>

<p>Even though we can make persistent work with distributed storage, it’s better to avoid it if possible because of the setup complexity and performance impact. (This is more of the case of a self-hosted solution, distributed storage from cloud providers is very easy to use, and is also used by the VM so there is no difference in performance). We’ve listed some options above. In this section, we will look at how to create a database for the services to use so that they don’t need to store data on disks.</p>

<p>Here I will use CockroachDB as an example. But this introduction should help you to set up other similar systems like Elastic Search. Cockroach DB is a distributed database that is compatible with PostgreSQL. It’s built with HA in mind, so it has good guarantees and is easy to set up. I’ve checked lots of HA solutions for PostgreSQL and all of them have less guarantee (lots of them have no information about the consistency and availability level they provide, and I found them half-baked with a closer look) while are much harder to set up. I’ve written <a href="/2018-07-29-A-Review-on-Spanner-and-Open-Source-Implementations.html">a blog about Spanner that also talks about Cockroach DB</a> if you are interested in more details. Overall I have a good impression of it: the tech writings are solid, and the support is nice: when I have an issue and report it in the forum, the response is usually very quick and useful even though I’m just a free user.</p>

<p>CockroachDB has <a href="https://www.cockroachlabs.com/docs/stable/kubernetes-overview.html">an official document</a> about how to install it on Kubernetes. It’s using <a href="https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/">StatefulSets</a>. Here is <a href="https://raw.githubusercontent.com/cockroachdb/cockroach/master/cloud/kubernetes/cockroachdb-statefulset.yaml">one of the configurations it uses</a>. However, I still find there are too many limitations in StatefulSets so I deployed it in my own way:</p>

<ul>
  <li>Each CockroachDB instance is in its own StatefulSets with only 1 replica.</li>
  <li>Each of the instances is bound to the physical node with <a href="https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/">PodAffinity</a>. So that each instance will only ever run on a specific host. In this way, we can just use the local disk as the storage because it will never run on a different host.</li>
  <li>Each CockroachDB instance has its own <a href="https://kubernetes.io/docs/concepts/services-networking/service/">service</a> defined so that they can communicate with each other.</li>
  <li>Copy the parameters from the official configuration and adjust them based on your use case.</li>
</ul>

<p>With a setup like this, it’s like installing CockroachDB on physical nodes but managed by Kubernetes. You don’t need to worry about distributed storage. When a node fails, a CockroachDB instance will also fail. But since CockroachDB itself has HA enabled, the whole CockroachDB cluster is still alive. Here is an example of the Kubernetes resources in my setup:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># Pods

NAME                READY   STATUS    RESTARTS   AGE
pod/cockroach01-0   1/1     Running   1          4d11h
pod/cockroach02-0   1/1     Running   5          4d11h
pod/cockroach03-0   1/1     Running   0          4d11h

# StatefulSet

NAME          READY   AGE
cockroach01   1/1     298d
cockroach02   1/1     298d
cockroach03   1/1     298d

# Service

NAME                              TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)                          AGE
service/cockroach01-cockroachdb   ClusterIP   None           &lt;none&gt;        26257/TCP,8080/TCP               298d
service/cockroach02-cockroachdb   ClusterIP   None           &lt;none&gt;        26257/TCP,8080/TCP               298d
service/cockroach03-cockroachdb   ClusterIP   None           &lt;none&gt;        26257/TCP,8080/TCP               298d
service/cockroachdb               ClusterIP   10.96.70.142   &lt;none&gt;        26257/TCP,8080/TCP               269d
service/cockroachdb-public        NodePort    10.108.23.98   &lt;none&gt;        26257:30005/TCP,8080:30006/TCP   269d
</code></pre></div></div>

<p>You can see there is a separate StatefulSet for each of the CockroachDB instances, and a service for each of them for internal communications (with the name pattern <code class="language-plaintext highlighter-rouge">cockroach**-cockroachdb</code>). Service <code class="language-plaintext highlighter-rouge">cockroachdb</code> is for the use in Kubernetes cluster, and service <code class="language-plaintext highlighter-rouge">cockroachdb-public</code> is used by the service outside of the Kubernetes cluster (can be disabled if not needed) so that you can see the dashboard from your browser.</p>

<p>It may seem to have more Kubernetes definitions to write with such a method. But remember, while Kubernetes accepts YAML or Json format, how to prepare the definition can be flexible: you can use your favorite programming language to construct the definition and pass it to Kubernetes with a <a href="https://kubernetes.io/docs/reference/using-api/client-libraries/">client library</a>.</p>

<p>The upgrade of CockroachDB is very easy as well. Make sure to check the official release notes and upgrade guides first, but normally the upgrade is just to patch each of the StatefulSet with a newer version of Docker image, for example:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># run this command for every stateful set

kubectl patch statefulset cockroach01 \
--type='json' \
-p='[{"op": "replace", "path": "/spec/template/spec/containers/0/image", "value":"cockroachdb/cockroach:v22.2.5"}]'
</code></pre></div></div>

<h2 id="network-ingress">Network Ingress</h2>

<p>Once we have everything deployed in the cluster, the last step is to expose our service to the public Internet so that everyone can use it. Here we list two options based on the use case.</p>

<h3 id="cloudflare-tunnel">Cloudflare Tunnel</h3>

<p><a href="https://developers.cloudflare.com/cloudflare-one/connections/connect-apps/">Cloudflare Tunnel</a> is basically a reverse proxy that forwards the traffic from the public Internet to your service. There is a daemon called cloudflared running in Kubernetes. Cloudflare will forward the traffic from clients to cloudflared and cloudflared will forward the traffic to the actual service. Check <a href="https://developers.cloudflare.com/cloudflare-one/tutorials/many-cfd-one-tunnel/">this doc</a> to see how it works with Kubernetes.</p>

<p>The upside of Cloudflare tunnel is that you don’t need to open any port to the public Internet at all. So it’s safer because there is no way to access your service without going to Cloudflare first. Cloudflare also provide some tools to mediate attacks like DDoS.</p>

<p>The downside is it depends on a third-party provider. And it can see all the traffic. It only supports limited protocols. So if you want to avoid Cloudflare seeing your traffic or have a protocol that is not supported, you need a more generic way to do it.</p>

<h3 id="nodeport-with-virtual-ip-and-dynamic-dns">NodePort with Virtual IP and Dynamic DNS</h3>

<p>We need to really open a port to the Internet without something like Cloudflare Tunnel. First, we need to open a port on our nodes, this can be done by defining <a href="https://kubernetes.io/docs/concepts/services-networking/service/#type-nodeport">NodePort</a> in Kubernetes’ service.</p>

<p>Once we have the port opened on the nodes, we need to open it to the Internet. How to do it depends on the Internet provider. Usually, you should be able to set up a port mapping from the router to an internal IP for a node. However, to make the setup HA, we shouldn’t map the port just to a single node since that single node can be down, we can set up Keepalived so that there is a virtual IP that always maps to a live node. If you’ve <a href="https://github.com/kubernetes/kubeadm/blob/main/docs/ha-considerations.md#options-for-software-load-balancing">set up HA for Kubernetes with Keepalived and HAProxy</a>, you should be already familiar with how to set it up.</p>

<p>When you open a NodePort, make sure you’ve configured all the protections like authentication and encryption since beyond that it’s public Internet and anyone can access it.
You may want to run Nginx or HAProxy in the Kubernetes cluster, use it as a reverse proxy and only expose it to the Internet so that it’s safer and you have more control over the public traffic.</p>

<p>The client also needs a way to find the IP address of your network. Depending on the Internet provider, the IP address can change from time to time. So we need dynamic DNS to bind the changing IP to a fixed DNS. <a href="https://github.com/ddclient/ddclient">ddclient</a> can do it automatically and supports lots of domain name providers.</p>

<p>After all of this, your service is open to the public Internet and can be accessed by anyone. But if desired, you can still use Cloudflare DNS with proxy enabled, so that the client will send requests to Cloudflare first and you can get protections from Cloudflare. In this case, since the SSL is terminated inside the Kubernetes cluster, Cloudflare will not be able to see the actual payload of the traffic.</p>]]></content><author><name></name></author><category term="Kubernetes" /><category term="GlusterFS" /><category term="CockroachDB" /><category term="tech" /><category term="high availability" /><summary type="html"><![CDATA[See Introduce K3s, CephFS and MetalLB to My High Avaliable Cluster for updates on this setup.]]></summary></entry></feed>