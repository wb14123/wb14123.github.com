<!DOCTYPE html>

<html>
  <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title> A Boring JVM Memory Profiling Story |  Bin Wang - My Personal Blog</title>
    <link rel="stylesheet" href="/static/css/default.css" type="text/css" />
    <link rel="stylesheet" href="/static/css/asciinema-player.css" type="text/css" />

		<!--
    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
      ga('create', 'UA-52904500-1', 'auto');
      ga('send', 'pageview');
    </script>
		-->

		<!-- Matomo -->
		<script>
		  var _paq = window._paq = window._paq || [];
		  /* tracker methods like "setCustomDimension" should be called before "trackPageView" */
		  _paq.push(['trackPageView']);
		  _paq.push(['enableLinkTracking']);
		  (function() {
		    var u="//matomo.rssbrain.com/";
		    _paq.push(['setTrackerUrl', u+'matomo.php']);
		    _paq.push(['setSiteId', '2']);
		    var d=document, g=d.createElement('script'), s=d.getElementsByTagName('script')[0];
		    g.async=true; g.src=u+'matomo.js'; s.parentNode.insertBefore(g,s);
		  })();
		</script>
		<!-- End Matomo Code -->


  </head>

  <body>
    <header id="page_header">
      <nav id="page_nav">
        <ul>
             <li><a href="/">Home</a></li>
             <li><a href="/index_page.html">Index</a></li>
             <li><a href="/snippets">Snippets</a></li>
             <li><a href="https://www.goodreads.com/review/list/103708630-bin?shelf=read" target="_blank">Read</a></li>
             <li><a href="/travel.html">Travel</a></li>
             <li><a href="/search.html">Search</a></li>
             <li><a href="/about.html">About</a></li>
             <li><a href="/feed.xml">RSS</a></li>
       </ul>
      </nav>

    </header>

    <section id="page_content">
      <div id="content_table">
  <h3>Table of Contents</h3><ol class="toc"><li><a href="#background-of-memory-leakings">Background of Memory Leakings</a></li><li><a href="#the-problem">The Problem</a></li><li><a href="#setup-profiler">Setup Profiler</a></li><li><a href="#memory-comparison">Memory Comparison</a></li><li><a href="#a-false-root-cause">A False Root Cause</a></li><li><a href="#the-real-root-cause">The Real Root Cause</a></li><li><a href="#fix-the-memory-leak">Fix the Memory Leak</a></li><li><a href="#conclusion">Conclusion</a></li></ol>
</div>

<div id="article_content" class="">
<article id="post">
  <header>
    <h1>A Boring JVM Memory Profiling Story</h1>
    
      <p class="description">Posted on 30 Sep 2023, tagged <code>Java</code><code>JVM</code><code>Memory Leak</code><code>Scala</code><code>JProfiler</code><code>Profiling</code></p>
    
  </header>

  <h2 id="background-of-memory-leakings">Background of Memory Leakings</h2>

<p>I encountered another memory leak problem recently. I’ve debugged a few of memory leak problems in the past, including <a href="https://github.com/splicemachine/spliceengine/pull/2260">the one</a> in Splice Machine, an open source distributed SQL engine based on HBase but was sadly discontinued. The memory leak problems are interesting because it’s challenging to find the root cause. However, I’ve never written a blog about it. Memory leak problems are not so usual, so when I encountered a new one, I kind of need to remember what tools I’ve used. So this time, even though not as interesting as some other memory leak problems I’ve debugged in the past, I decide to write it down as a note for my own reference in the future. The tool set I used this time is relatively simple. I guess I can write more when I use others in the future. This is more like a dev log instead of a tutorial. The “boring” in the title means it’s a pretty standard process and the problem is not that hard to find this time.</p>

<p>Most of the memory leak bugs are very easy to fix once found the root cause, but the part of finding the root cause is tricky. First of all, it’s hard to reproduce: sometime it only happens on production environment. Without knowing the cause, it’s hard to reproduce locally. Even it can be reproduced consistently, it may take some time to let the memory accumulate so the debugging loop can be time consuming sometimes. Last of all, unlike some other bugs that you have an exception and a nice stack trace to help you identify which code causes the problem, it’s almost impossible to find the root cause without the help of a profiler, which itself has challenging parts depending on the platform.</p>

<p>Luckily, JVM has good profilers. That’s one of the reasons Scala, a JVM based language, is my favorite language. (The criteria of a good production language for me is not only the language itself, but also the ecosystem like library, IDE and profilers. JVM based language makes lots of the criteria easy to meet.) This time I uses a very popular profiler <a href="https://www.ej-technologies.com/products/jprofiler/overview.html">JProfiler</a>. Other popular choices that I have used are <a href="https://visualvm.github.io/">VisulaVM</a> and <a href="https://www.oracle.com/java/technologies/jdk-mission-control.html">Java Msission Control</a>. But I found JProfiler is both powerful and easy to use. The only downside is you need to buy a license. It has free trail and open source license. So if you have an open source project or just need to use it for a few days, you can still use it for free.</p>

<h2 id="the-problem">The Problem</h2>

<p>Okay, enough of the background. Let’s dive into the memory leaking problem I encountered this time. As mentioned in the previous blog <a href="http://localhost:4001/2023-09-23-Migrate-Scala2Grpc-to-Cats-Effect-3.html">Migrate Scala2grpc to Cats Effect 3</a>, I migrated one of my side projects to Cats Effect 3 as well, with a lot of other dependencies. This side project is <a href="https://www.rssbrain.com/">RSS Brain</a>. There are two parts on the backend: one for serving client requests with gRPC and gRPC web, another one for fetching RSS feeds. The fetcher gets the RSS feeds that haven’t been fetched for a while from the database with the help of <a href="https://tpolecat.github.io/doobie/">doobie</a> and <a href="https://zio.dev/zio-quill/">quill</a>, and fetch them in parallel with the help of fs2 stream and Cats Effect.</p>

<p>After the mass upgrades, I looked into the metrics to make sure everything is okay. Then I found the fetcher’s memory starts to increase slowly. Looks like a memory leak problem to me. Here is the memory usage graph:</p>

<p><img src="/static/images/2023-09-30-A-Boring-JVM-Memory-Profiling-Story/memory-usage.png" alt="memory usage" /></p>

<p>Seems eventually the JVM will run out of memory but I didn’t wait for it. It’s good to try if force a full gc will reclaim the memory or not, in my case full gc doesn’t help much.</p>

<p>Another metrics to look at is the GC metrics. Only after I shipped the fix, I realized the GC didn’t look normal when there was this memory problem:</p>

<p><img src="/static/images/2023-09-30-A-Boring-JVM-Memory-Profiling-Story/gc.png" alt="gc" /></p>

<p>Before the blue line starts, GCs are all “Copy” and “MarkSweepCompact”, which means the memory are mostly being moved around instead of reclaimed. After the blue line starts, which was when the fix was shipped, we starts to see normal young and old generation GC.</p>

<p>So these metrics indicates that we may have a memory leak issue. Let’s starts to debug it.</p>

<h2 id="setup-profiler">Setup Profiler</h2>

<p>In this case I’m using JProfiler. But as I mentioned above, VisualVM or Java Mission Control should also be able to do the job.</p>

<p>JProfiler has a nice wizard to let you setup the profiler. In my case, since I run the service in Kubernetes, I need to select remote server profiling and go through the wizard. We are going to use <code>kubectl</code> to forward the debugging port to local, so that we can just use <code>localhost:8849</code> as the remote address. At the end of the setup wizard, it will prompt you to download the profiler agent and include it with a Java command line argument. Since the service is running in container, I added the following lines to the Dockerfile in order to include the agent in it:</p>

<div class="language-plaintext highlighter-coderay"><div class="CodeRay">
  <div class="code"><pre><span class="line-numbers"><a href="#n1" name="n1">1</a></span>RUN apt update -y &amp;&amp; apt install -y wget
<span class="line-numbers"><a href="#n2" name="n2">2</a></span>RUN cd /opt &amp;&amp; \
<span class="line-numbers"><a href="#n3" name="n3">3</a></span>        wget -c 'https://download.ej-technologies.com/jprofiler/jprofiler_agent_linux-x86_14_0.tar.gz' &amp;&amp; \
<span class="line-numbers"><a href="#n4" name="n4">4</a></span>        tar -xf jprofiler_agent_linux-x86_14_0.tar.gz
</pre></div>
</div>
</div>

<p>Also add this flag to Java command line when starting the service:</p>

<div class="language-plaintext highlighter-coderay"><div class="CodeRay">
  <div class="code"><pre><span class="line-numbers"><a href="#n1" name="n1">1</a></span>-agentpath:/opt/jprofiler14/bin/linux-x64/libjprofilerti.so=port=8849,nowait
</pre></div>
</div>
</div>

<p>After the new container is deployed, we can port forward 8849 from the service to our localhost with kubectl:</p>

<div class="language-plaintext highlighter-coderay"><div class="CodeRay">
  <div class="code"><pre><span class="line-numbers"><a href="#n1" name="n1">1</a></span>kubectl port-forward &lt;service-pod-name&gt; 8849:8849
</pre></div>
</div>
</div>

<h2 id="memory-comparison">Memory Comparison</h2>

<p>Since it’s a memory leaking problem, we want to find out what objects are increasing. First let’s restart the JVM, connect JProfiler to it and take a snapshot of all objects in live memory:</p>

<p><img src="/static/images/2023-09-30-A-Boring-JVM-Memory-Profiling-Story/objects-start.png" alt="objects-start" /></p>

<p>We can see <code>byte[]</code> takes the most memory but it doesn’t mean it’s responsible for memory leak, since we need to look at the increase of the memory.</p>

<p>So we need to wait for a while for the memory problem starts to happen. In my case, obvious memory increase can be occurred after the JVM run for about 12 hours. Normally if this is a work related thing, I may want to make it faster by increasing the work load. In this case, the code is fetching RSS feeds, so I could make the interval shorter so that it makes more requests. But since this is only a side project, I don’t need to continues working on it, and I also don’t quite like the idea to increase the requests to target RSS websites to increase their load. So I decide just let the JVM run during the night and take another look next day:</p>

<p><img src="/static/images/2023-09-30-A-Boring-JVM-Memory-Profiling-Story/objects-end.png" alt="objects-end" /></p>

<p>Okay, obviously <code>scala.collection.mutable.LinkedHashMap$LinkedEntry</code> increased a lot. But is there anything else? Conveniently, JProfiler has the feature to compare 2 snapshots. Just go to “Session” -&gt; “Start Center” -&gt; “Open Snapshots” -&gt; “Compare Multiple Snapshots”. After open those 2 snapshots, select both of them on the left and then compare memory:</p>

<p><img src="/static/images/2023-09-30-A-Boring-JVM-Memory-Profiling-Story/objects-compare.png" alt="objects-compare" /></p>

<p>We can see <code>LinkedEntry</code> indeed increased the most by instance count. However, if we sort by size, we fill find <code>byte[]</code> increased the most by memory size.</p>

<h2 id="a-false-root-cause">A False Root Cause</h2>

<p>Since <code>byte[]</code> increased the most by memory size, I’d like to start there. By using “Allocation Call Tree”, we can check which code allocates <code>byte[]</code> the most. After profiling for a while, we get the following result:</p>

<p><img src="/static/images/2023-09-30-A-Boring-JVM-Memory-Profiling-Story/allocation-tree-bytes.png" alt="allocation-tree-bytes" /></p>

<p>Okay, the top allocation goes to my own code <code>me.binwang.rss.parser.SourceParser</code>. It’s the class that parse the xml from RSS feeds. So I looked into it if it has any code that can cause memory leak and I found this:</p>

<div class="language-Scala highlighter-coderay"><div class="CodeRay">
  <div class="code"><pre><span class="line-numbers"> <a href="#n1" name="n1">1</a></span>object SourceParser {
<span class="line-numbers"> <a href="#n2" name="n2">2</a></span>
<span class="line-numbers"> <a href="#n3" name="n3">3</a></span>  def parse(url: String, content: Resource[IO, InputStream]): IO[(Source, Seq[Try[FullArticle]])] = {
<span class="line-numbers"> <a href="#n4" name="n4">4</a></span>    content.use { c =&gt;
<span class="line-numbers"> <a href="#n5" name="n5">5</a></span>      // ...
<span class="line-numbers"> <a href="#n6" name="n6">6</a></span>      throw new RuntimeException(s&quot;Error to parse source xml, unrecognized label $label&quot;)
<span class="line-numbers"> <a href="#n7" name="n7">7</a></span>      // ...
<span class="line-numbers"> <a href="#n8" name="n8">8</a></span>    }
<span class="line-numbers"> <a href="#n9" name="n9">9</a></span>  }
</pre></div>
</div>
</div>

<p>So there is an exception thrown in a <code>Resource.use</code>. <code>Resource.use</code> makes sure to cleanup the resource when the <code>use</code> scope is over. But what will happen if it throws an example in there? I thought it will cause <code>use</code> to not handle the cleanup properly. So I changed it to use <code>IO.raiseError</code> instead of throw it directly.</p>

<p>However, while I deploying the code, I thought I should really test it. So I wrote a piece of simple code to see whether <code>Resource</code> will still be cleaned up if there is any exception thrown in <code>use</code>, and the answer is yes. So this shouldn’t be the root cause. And the deployment result also confirms that: the memory kept increasing with this fix.</p>

<h2 id="the-real-root-cause">The Real Root Cause</h2>

<p>Maybe <code>byte[]</code> just happened to uses more memory because it’s parsing a large xml at that time. It’s okay that it isn’t the real root cause since we have another lead: <code>scala.collection.mutable.LinkedHashMap$LinkedEntry</code>. From the profiling, its allocation tree looks like this:</p>

<p><img src="/static/images/2023-09-30-A-Boring-JVM-Memory-Profiling-Story/allocation-tree-linkedlist.png" alt="allocation-tree-linkedlist" /></p>

<p>Okay, so seems most of them come from quill. quill is a library that compiles Scala DSL to SQL queries. It is fairly complex since it uses macros. I checked the code in the allocation tree and couldn’t find out what is wrong.</p>

<p>Then I tried to check the object reference to see which instances are pointed to the these LinkedEntry:</p>

<p><img src="/static/images/2023-09-30-A-Boring-JVM-Memory-Profiling-Story/object-refer.png" alt="object-refer" /></p>

<p>No surprise, they are basically all from quill as well. However, I couldn’t understand the internal AST represents of quill and not sure where are they coming from.</p>

<p>It’s time to search the Internet to see if there is any known issue in quill about memory leak. Maybe I didn’t have the right query, I didn’t find proper results from Internet.</p>

<p>After struggle for a while, I went to its Github repo to search “Memory leak” directly and found 3 issues. That’s good! And there is <a href="https://github.com/zio/zio-quill/issues/2484">one</a> describes the exact problem we have. If we see the allocation tree above, we can find there is a call from <code>NormalizeCaching</code> (at the bottom of the tree in the picture), which is the class that the issue describes. I guess I didn’t go that far enough to check this class. I’m glad someone else did and found the issue! Basically the root cause is there is a map in the caching doesn’t have any bound. So the cache triggered by dynamic queries never got expired and is growing more and more:</p>

<div class="language-plaintext highlighter-coderay"><div class="CodeRay">
  <div class="code"><pre><span class="line-numbers"><a href="#n1" name="n1">1</a></span>private val cache = new ConcurrentHashMap[Ast, Ast] 
</pre></div>
</div>
</div>

<h2 id="fix-the-memory-leak">Fix the Memory Leak</h2>

<p>The issue is pretty old and is related to a core feature. I’m surprised it’s not fixed yet. As I said, once we found the root cause, the fix should be easy. We just need a way to make the cache expire. I replaced the cache implementation with Guava’s cache, and after the suggestion of maintainer changed it to <a href="https://github.com/ben-manes/caffeine">Caffeine</a>’s cache implementation. <a href="https://github.com/zio/zio-quill/pull/2878">Here is the PR</a>.</p>

<p>I built quill with the fix locally and tested with RSS Brain. The memory leak is indeed fixed! How exciting it is!</p>

<h2 id="conclusion">Conclusion</h2>

<p>Let’s review the process of fixing the memory leak in this case:</p>

<ul>
  <li>Setup profiler.</li>
  <li>Run full GC cannot resolve the memory issue.</li>
  <li>Compare the snapshots between when JVM first started and when the memory increases. See which classes increased most.</li>
  <li>Using allocation tree to find out which part of the code is creating the instances.</li>
  <li>Using references in heap walker to check which classes holds references of those instances.</li>
  <li>Check the identified code and classes.</li>
  <li>If it’s a third party library and we cannot find the root cause, check if the issue is reported. Otherwise report the issue.</li>
  <li>Fix the memory leak based on the root cause.</li>
</ul>

</article>

<footer id="post_footer">
  <table><tr>
    
      <td id="prev"><a href="/2023-09-24-Jekyll-Plugin-to-Load-Asciicast-Locally.html">Prev: Jekyll Plugin to Load Asciinema Recordings Locally</a></td>
    
    
      <td id="next"><a href="/2023-10-22-Full-Disk-Encryption-with-Yubikey.html" id="next">Next: Linux Full Disk Encryption with Yubikey</a></td>
    
  </tr></table>
</footer>

<section id="comment">
  <div id="disqus_thread"></div>
  <script type="text/javascript">
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = 'crazy-hot-ice'; // required: replace example with your forum shortname
    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = 'https://' + disqus_shortname + '.disqus.com/embed.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  <a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</section>



<!-- MathJax -->
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>

</div>

    </section>

    <footer id="page_footer">
      Copyright @ 2008 - 2023 Bin Wang
      <a rel="license" href="https://creativecommons.org/licenses/by-nc-sa/3.0/deed.en_US"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-sa/3.0/88x31.png" /></a><br />This work is licensed under a <a rel="license" href="https://creativecommons.org/licenses/by-nc-sa/3.0/deed.en_US">Creative Commons Attribution-NonCommercial-ShareAlike 3.0 Unported License</a>.
    </footer>
  </body>
</html>
